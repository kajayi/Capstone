{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62f2556-270d-4b92-9caf-89f14d3c3eeb",
   "metadata": {
    "id": "d62f2556-270d-4b92-9caf-89f14d3c3eeb"
   },
   "source": [
    "# CAPSTONE\n",
    "Kehinde Ajayi\n",
    "\n",
    "Initial modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-Yv9EpgCcFF7",
   "metadata": {
    "executionInfo": {
     "elapsed": 10770,
     "status": "ok",
     "timestamp": 1652294793744,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "-Yv9EpgCcFF7"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "\n",
    "# # https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
    "# project_id = 'capstone2022-349201'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2EZDJpfccE-l",
   "metadata": {
    "id": "2EZDJpfccE-l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "A8pKyGmAcE2i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1652296982609,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "A8pKyGmAcE2i",
    "outputId": "5b934431-5918-4712-d999-e0bd7e4ae8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kajayi/Capstone/ka_capstone/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CZ3vyfzGcEtS",
   "metadata": {
    "id": "CZ3vyfzGcEtS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Du6tPloksUW5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27703,
     "status": "ok",
     "timestamp": 1652292339746,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "Du6tPloksUW5",
    "outputId": "3fa94cfe-dda8-4c17-ecea-7145b586c187"
   },
   "outputs": [],
   "source": [
    "## check if notebook is running on Colab--if so, run appropriate installs and mount Google Drive\n",
    "# https://stackoverflow.com/questions/53581278/test-if-notebook-is-running-on-google-colab\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  # install RDKit and DeepChem\n",
    "  !pip install rdkit-pypi --pre deepchem\n",
    "  # mount Google Drive\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3a83b56-f2a3-436c-be62-7250fe60e5fb",
   "metadata": {
    "executionInfo": {
     "elapsed": 8635,
     "status": "ok",
     "timestamp": 1652292348370,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "c3a83b56-f2a3-436c-be62-7250fe60e5fb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import sys\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "from deepchem.models import GraphConvModel\n",
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "\n",
    "from scipy.sparse import coo_matrix  #yes\n",
    "from scipy.sparse import csr_matrix  #yes\n",
    "\n",
    "from sklearn.utils import check_consistent_length, column_or_1d, assert_all_finite\n",
    "from sklearn.utils.multiclass import unique_labels, type_of_target \n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, RocCurveDisplay, ConfusionMatrixDisplay, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56f313d-27f5-411e-a191-ce8284226794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 00:52:39.659592: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-21 00:52:39.659642: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (first-one): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8212c66d-6a32-4873-aed4-4d6b43788da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022.03.2'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdkit.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "huUo_K78_B5C",
   "metadata": {
    "id": "huUo_K78_B5C"
   },
   "source": [
    "## Functions and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e67e1cc-8937-49ed-8655-c8aa7b759fdf",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1652292348372,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "2e67e1cc-8937-49ed-8655-c8aa7b759fdf"
   },
   "outputs": [],
   "source": [
    "# workaround for bug where molecular structure does not print with dataframe\n",
    "# https://github.com/rdkit/rdkit/issues/2673\n",
    "def show(df):\n",
    "    return HTML(df.to_html(notebook=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fDD6705-fWPG",
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1652292348373,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "fDD6705-fWPG"
   },
   "outputs": [],
   "source": [
    "# check if notebook is running on Colab and set path for data file \n",
    "\n",
    "def get_home_path():\n",
    "  if 'google.colab' in str(get_ipython()):\n",
    "    file_path = '/content/drive/MyDrive/GA/Capstone/ka_capstone'\n",
    "  else:\n",
    "    file_path = '..'\n",
    "  \n",
    "  return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mhITzL35G5m9",
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1652288655877,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "mhITzL35G5m9"
   },
   "outputs": [],
   "source": [
    "# GCN model\n",
    "\n",
    "def generate_gcnn_model(n_tasks=1, mode='classification'):\n",
    "    \"\"\"Instantiates a Graph Convolution model.\n",
    "\n",
    "    Args:\n",
    "        param1: The first parameter.\n",
    "        param2: The second parameter.\n",
    "\n",
    "    Returns:\n",
    "        The return value. True for success, False otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    model = GraphConvModel(1, batch_size=batch_size,\n",
    "                         graph_conv_layers=[128, 128],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         model_dir=f'{get_home_path()}/models')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19943902-27d5-486a-978b-ad74a5245501",
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1652288655879,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "19943902-27d5-486a-978b-ad74a5245501"
   },
   "outputs": [],
   "source": [
    "# view all columns in dataframe\n",
    "pd.set_option('display.max.columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32e11201-1765-4373-b311-89b1d72101be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(modelx, hist, save_dir):\n",
    "    \n",
    "    modelx.restore(model_dir=save_dir)\n",
    "    print('Training set score:', modelx.evaluate(train_dataset, metrics))\n",
    "    print('Validation set score:', modelx.evaluate(valid_dataset, metrics))\n",
    "    print('Test set score:', modelx.evaluate(test_dataset, metrics))\n",
    "\n",
    "    \n",
    "    modelx.restore(model_dir=f'{save_dir}/callbacks')\n",
    "    print('Best validation set score:', modelx.evaluate(valid_dataset, metrics))\n",
    "\n",
    "    print(f'Loss? = {hist}')\n",
    "\n",
    "    pred = [x.flatten() for x in modelx.predict(valid_dataset)]\n",
    "\n",
    "    cm = confusion_matrix(valid_dataset.y, [round(x[1]) for x in pred])\n",
    "    print(cm)\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # specificity\n",
    "    print(f'Specificity = {round(tn/(tn+fp), 4)}')\n",
    "\n",
    "    # 1- specificity\n",
    "    print(f'FPR = {round(fp/(tn+fp), 4)}')\n",
    "\n",
    "    # sensitivity\n",
    "    print(f'Recall/TPR = {round(tp/(tp+fn), 4)}')\n",
    "\n",
    "    print(f'Precision = {round(tp/(tp+fp), 4)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0db1c6-4362-48bc-82f6-6ca498763c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## code adapted from Scikit-learn's confusion_matrix function\n",
    "\n",
    "# def _cust_check_targets(y_true, y_pred):\n",
    "#     \"\"\"Check that y_true and y_pred belong to the same classification task.\n",
    "#     This converts multiclass or binary types to a common shape, and raises a\n",
    "#     ValueError for a mix of multilabel and multiclass targets, a mix of\n",
    "#     multilabel formats, for the presence of continuous-valued or multioutput\n",
    "#     targets, or for targets of different lengths.\n",
    "#     Column vectors are squeezed to 1d, while multilabel formats are returned\n",
    "#     as CSR sparse label indicators.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     y_true : array-like\n",
    "#     y_pred : array-like\n",
    "#     Returns\n",
    "#     -------\n",
    "#     type_true : one of {'multilabel-indicator', 'multiclass', 'binary'}\n",
    "#         The type of the true target data, as output by\n",
    "#         ``utils.multiclass.type_of_target``.\n",
    "#     y_true : array or indicator matrix\n",
    "#     y_pred : array or indicator matrix\n",
    "#     \"\"\"\n",
    "#     check_consistent_length(y_true, y_pred)\n",
    "#     type_true = type_of_target(y_true)\n",
    "#     type_pred = type_of_target(y_pred)\n",
    "\n",
    "#     y_type = {type_true, type_pred}\n",
    "#     if y_type == {\"binary\", \"multiclass\"}:\n",
    "#         y_type = {\"multiclass\"}\n",
    "\n",
    "#     if len(y_type) > 1:\n",
    "#         raise ValueError(\n",
    "#             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n",
    "#                 type_true, type_pred\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     # We can't have more than one value on y_type => The set is no more needed\n",
    "#     y_type = y_type.pop()\n",
    "\n",
    "#     # No metrics support \"multiclass-multioutput\" format\n",
    "#     if y_type not in [\"binary\", \"multiclass\", \"multilabel-indicator\"]:\n",
    "#         raise ValueError(\"{0} is not supported\".format(y_type))\n",
    "\n",
    "#     if y_type in [\"binary\", \"multiclass\"]:\n",
    "#         y_true = column_or_1d(y_true)\n",
    "#         y_pred = column_or_1d(y_pred)\n",
    "#         if y_type == \"binary\":\n",
    "#             try:\n",
    "#                 unique_values = np.union1d(y_true, y_pred)\n",
    "#             except TypeError as e:\n",
    "#                 # We expect y_true and y_pred to be of the same data type.\n",
    "#                 # If `y_true` was provided to the classifier as strings,\n",
    "#                 # `y_pred` given by the classifier will also be encoded with\n",
    "#                 # strings. So we raise a meaningful error\n",
    "#                 raise TypeError(\n",
    "#                     \"Labels in y_true and y_pred should be of the same type. \"\n",
    "#                     f\"Got y_true={np.unique(y_true)} and \"\n",
    "#                     f\"y_pred={np.unique(y_pred)}. Make sure that the \"\n",
    "#                     \"predictions provided by the classifier coincides with \"\n",
    "#                     \"the true labels.\"\n",
    "#                 ) from e\n",
    "#             if len(unique_values) > 2:\n",
    "#                 y_type = \"multiclass\"\n",
    "\n",
    "#     if y_type.startswith(\"multilabel\"):\n",
    "#         y_true = csr_matrix(y_true)\n",
    "#         y_pred = csr_matrix(y_pred)\n",
    "#         y_type = \"multilabel-indicator\"\n",
    "\n",
    "#     return y_type, y_true, y_pred\n",
    "\n",
    "\n",
    "\n",
    "# def cust_confusion_matrix(\n",
    "#     y_true, y_pred, *, labels=None, sample_weight=None, normalize=None\n",
    "# ):\n",
    "#     \"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "#     By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
    "#     is equal to the number of observations known to be in group :math:`i` and\n",
    "#     predicted to be in group :math:`j`.\n",
    "#     Thus in binary classification, the count of true negatives is\n",
    "#     :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
    "#     :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
    "#     Read more in the :ref:`User Guide <confusion_matrix>`.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     y_true : array-like of shape (n_samples,)\n",
    "#         Ground truth (correct) target values.\n",
    "#     y_pred : array-like of shape (n_samples,)\n",
    "#         Estimated targets as returned by a classifier.\n",
    "#     labels : array-like of shape (n_classes), default=None\n",
    "#         List of labels to index the matrix. This may be used to reorder\n",
    "#         or select a subset of labels.\n",
    "#         If ``None`` is given, those that appear at least once\n",
    "#         in ``y_true`` or ``y_pred`` are used in sorted order.\n",
    "#     sample_weight : array-like of shape (n_samples,), default=None\n",
    "#         Sample weights.\n",
    "#         .. versionadded:: 0.18\n",
    "#     normalize : {'true', 'pred', 'all'}, default=None\n",
    "#         Normalizes confusion matrix over the true (rows), predicted (columns)\n",
    "#         conditions or all the population. If None, confusion matrix will not be\n",
    "#         normalized.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     C : ndarray of shape (n_classes, n_classes)\n",
    "#         Confusion matrix whose i-th row and j-th\n",
    "#         column entry indicates the number of\n",
    "#         samples with true label being i-th class\n",
    "#         and predicted label being j-th class.\n",
    "#     See Also\n",
    "#     --------\n",
    "#     ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n",
    "#         given an estimator, the data, and the label.\n",
    "#     ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n",
    "#         given the true and predicted labels.\n",
    "#     ConfusionMatrixDisplay : Confusion Matrix visualization.\n",
    "#     References\n",
    "#     ----------\n",
    "#     .. [1] `Wikipedia entry for the Confusion matrix\n",
    "#            <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
    "#            (Wikipedia and other references may use a different\n",
    "#            convention for axes).\n",
    "#     Examples\n",
    "#     --------\n",
    "#     >>> from sklearn.metrics import confusion_matrix\n",
    "#     >>> y_true = [2, 0, 2, 2, 0, 1]\n",
    "#     >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
    "#     >>> confusion_matrix(y_true, y_pred)\n",
    "#     array([[2, 0, 0],\n",
    "#            [0, 0, 1],\n",
    "#            [1, 0, 2]])\n",
    "#     >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "#     >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "#     >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "#     array([[2, 0, 0],\n",
    "#            [0, 0, 1],\n",
    "#            [1, 0, 2]])\n",
    "#     In the binary case, we can extract true positives, etc as follows:\n",
    "#     >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "#     >>> (tn, fp, fn, tp)\n",
    "#     (0, 2, 1, 1)\n",
    "#     \"\"\"\n",
    "#     y_type, y_true, y_pred = _cust_check_targets(y_true, y_pred)\n",
    "#     if y_type not in (\"binary\", \"multiclass\"):\n",
    "#         raise ValueError(\"%s is not supported\" % y_type)\n",
    "\n",
    "#     if labels is None:\n",
    "#         labels = unique_labels(y_true, y_pred)\n",
    "#     else:\n",
    "#         labels = np.asarray(labels)\n",
    "#         n_labels = labels.size\n",
    "#         if n_labels == 0:\n",
    "#             raise ValueError(\"'labels' should contains at least one label.\")\n",
    "#         elif y_true.size == 0:\n",
    "#             return np.zeros((n_labels, n_labels), dtype=int)\n",
    "#         elif len(np.intersect1d(y_true, labels)) == 0:\n",
    "#             raise ValueError(\"At least one label specified must be in y_true\")\n",
    "\n",
    "#     if sample_weight is None:\n",
    "#         sample_weight = np.ones(y_true.shape[0], dtype=np.int64)\n",
    "#     else:\n",
    "#         sample_weight = np.asarray(sample_weight)\n",
    "\n",
    "#     check_consistent_length(y_true, y_pred, sample_weight)\n",
    "\n",
    "#     if normalize not in [\"true\", \"pred\", \"all\", None]:\n",
    "#         raise ValueError(\"normalize must be one of {'true', 'pred', 'all', None}\")\n",
    "\n",
    "#     n_labels = labels.size\n",
    "#     # If labels are not consecutive integers starting from zero, then\n",
    "#     # y_true and y_pred must be converted into index form\n",
    "#     need_index_conversion = not (\n",
    "#         labels.dtype.kind in {\"i\", \"u\", \"b\"}\n",
    "#         and np.all(labels == np.arange(n_labels))\n",
    "#         and y_true.min() >= 0\n",
    "#         and y_pred.min() >= 0\n",
    "#     )\n",
    "#     if need_index_conversion:\n",
    "#         label_to_ind = {y: x for x, y in enumerate(labels)}\n",
    "#         y_pred = np.array([label_to_ind.get(x, n_labels + 1) for x in y_pred])\n",
    "#         y_true = np.array([label_to_ind.get(x, n_labels + 1) for x in y_true])\n",
    "\n",
    "#     # intersect y_pred, y_true with labels, eliminate items not in labels\n",
    "#     ind = np.logical_and(y_pred < n_labels, y_true < n_labels)\n",
    "#     if not np.all(ind):\n",
    "#         y_pred = y_pred[ind]\n",
    "#         y_true = y_true[ind]\n",
    "#         # also eliminate weights of eliminated items\n",
    "#         sample_weight = sample_weight[ind]\n",
    "\n",
    "#     # Choose the accumulator dtype to always have high precision\n",
    "#     if sample_weight.dtype.kind in {\"i\", \"u\", \"b\"}:\n",
    "#         dtype = np.int64\n",
    "#     else:\n",
    "#         dtype = np.float64\n",
    "\n",
    "#     cm = coo_matrix(\n",
    "#         (sample_weight, (y_true, y_pred)),\n",
    "#         shape=(n_labels, n_labels),\n",
    "#         dtype=dtype,\n",
    "#     ).toarray()\n",
    "\n",
    "#     with np.errstate(all=\"ignore\"):\n",
    "#         if normalize == \"true\":\n",
    "#             cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "#         elif normalize == \"pred\":\n",
    "#             cm = cm / cm.sum(axis=0, keepdims=True)\n",
    "#         elif normalize == \"all\":\n",
    "#             cm = cm / cm.sum()\n",
    "#         cm = np.nan_to_num(cm)\n",
    "\n",
    "#     return cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21XFoWzVGxcZ",
   "metadata": {
    "id": "21XFoWzVGxcZ"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mxbkjrNpkzy8",
   "metadata": {
    "executionInfo": {
     "elapsed": 20191,
     "status": "ok",
     "timestamp": 1652288817619,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "mxbkjrNpkzy8"
   },
   "outputs": [],
   "source": [
    "    \n",
    "# read hERG data into dataframe \n",
    "herg_df = pd.read_csv(f'{get_home_path()}/data/interim/herg_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2BT2CzWX6Q3R",
   "metadata": {
    "id": "2BT2CzWX6Q3R"
   },
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8oitueImGJ2Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1652288817627,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "8oitueImGJ2Q",
    "outputId": "aeec6226-6919-431c-b8cb-c966d20856de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pubchem_SID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>hERG_at_1uM</th>\n",
       "      <th>hERG_at_10uM</th>\n",
       "      <th>herg_inhibitor</th>\n",
       "      <th>mw</th>\n",
       "      <th>logP</th>\n",
       "      <th>PSA</th>\n",
       "      <th>H_bond_donors</th>\n",
       "      <th>H_bond_acceptors</th>\n",
       "      <th>num_heteroatoms</th>\n",
       "      <th>total_num_rings</th>\n",
       "      <th>aromatic_rings</th>\n",
       "      <th>num_rotatable_bonds</th>\n",
       "      <th>num_stereocenters</th>\n",
       "      <th>formal_charge</th>\n",
       "      <th>SMILES_length</th>\n",
       "      <th>ro5_violations</th>\n",
       "      <th>adjacency_matrix</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132554</th>\n",
       "      <td>47194915</td>\n",
       "      <td>O=c1oc2ccccc2n1Cc1cccc(C(F)(F)F)c1</td>\n",
       "      <td>4.8772</td>\n",
       "      <td>-9.86412</td>\n",
       "      <td>0</td>\n",
       "      <td>293.244</td>\n",
       "      <td>3.66160</td>\n",
       "      <td>35.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n...</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246388</th>\n",
       "      <td>7965435</td>\n",
       "      <td>O=C(Nc1ccccc1F)C1CCCN(S(=O)(=O)c2cccc3cccnc23)C1</td>\n",
       "      <td>2.7917</td>\n",
       "      <td>1.36368</td>\n",
       "      <td>0</td>\n",
       "      <td>413.474</td>\n",
       "      <td>3.41330</td>\n",
       "      <td>79.37</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138028</th>\n",
       "      <td>49828138</td>\n",
       "      <td>Cc1cc(C(=O)NC2CCC(C)CC2)c(C)o1</td>\n",
       "      <td>7.3915</td>\n",
       "      <td>12.46638</td>\n",
       "      <td>0</td>\n",
       "      <td>235.327</td>\n",
       "      <td>3.20494</td>\n",
       "      <td>42.24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n [1 0 1 ...</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58110</th>\n",
       "      <td>24824071</td>\n",
       "      <td>CCOc1ccc(/C=N/NC(=O)CNC(=O)c2ccc(S(=O)(=O)N3CC...</td>\n",
       "      <td>14.4227</td>\n",
       "      <td>11.70228</td>\n",
       "      <td>0</td>\n",
       "      <td>474.539</td>\n",
       "      <td>0.98630</td>\n",
       "      <td>126.40</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0 1 0 ... 0 0 0]\\n [1 0 1 ... 0 0 0]\\n [0 1 ...</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263364</th>\n",
       "      <td>49728119</td>\n",
       "      <td>COc1cc(OC)cc(C(=O)N2CCCC(c3nc(-c4ccc(C)o4)no3)...</td>\n",
       "      <td>16.2872</td>\n",
       "      <td>-9.34562</td>\n",
       "      <td>0</td>\n",
       "      <td>397.431</td>\n",
       "      <td>3.67502</td>\n",
       "      <td>90.83</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pubchem_SID                                             SMILES  \\\n",
       "132554     47194915                 O=c1oc2ccccc2n1Cc1cccc(C(F)(F)F)c1   \n",
       "246388      7965435   O=C(Nc1ccccc1F)C1CCCN(S(=O)(=O)c2cccc3cccnc23)C1   \n",
       "138028     49828138                     Cc1cc(C(=O)NC2CCC(C)CC2)c(C)o1   \n",
       "58110      24824071  CCOc1ccc(/C=N/NC(=O)CNC(=O)c2ccc(S(=O)(=O)N3CC...   \n",
       "263364     49728119  COc1cc(OC)cc(C(=O)N2CCCC(c3nc(-c4ccc(C)o4)no3)...   \n",
       "\n",
       "        hERG_at_1uM  hERG_at_10uM  herg_inhibitor       mw     logP     PSA  \\\n",
       "132554       4.8772      -9.86412               0  293.244  3.66160   35.14   \n",
       "246388       2.7917       1.36368               0  413.474  3.41330   79.37   \n",
       "138028       7.3915      12.46638               0  235.327  3.20494   42.24   \n",
       "58110       14.4227      11.70228               0  474.539  0.98630  126.40   \n",
       "263364      16.2872      -9.34562               0  397.431  3.67502   90.83   \n",
       "\n",
       "        H_bond_donors  H_bond_acceptors  num_heteroatoms  total_num_rings  \\\n",
       "132554              0                 3                6                3   \n",
       "246388              1                 4                8                4   \n",
       "138028              1                 2                3                2   \n",
       "58110               2                 7               11                3   \n",
       "263364              0                 7                8                4   \n",
       "\n",
       "        aromatic_rings  num_rotatable_bonds  num_stereocenters  formal_charge  \\\n",
       "132554               3                    2                  0              0   \n",
       "246388               3                    4                  1              0   \n",
       "138028               1                    2                  0              0   \n",
       "58110                2                    9                  0              0   \n",
       "263364               3                    5                  1              0   \n",
       "\n",
       "        SMILES_length  ro5_violations  \\\n",
       "132554             34               0   \n",
       "246388             48               0   \n",
       "138028             30               0   \n",
       "58110              58               0   \n",
       "263364             51               0   \n",
       "\n",
       "                                         adjacency_matrix     label  \n",
       "132554  [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n...  inactive  \n",
       "246388  [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  inactive  \n",
       "138028  [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n [1 0 1 ...  inactive  \n",
       "58110   [[0 1 0 ... 0 0 0]\\n [1 0 1 ... 0 0 0]\\n [0 1 ...  inactive  \n",
       "263364  [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  inactive  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "herg_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2WlTbF7rKX3c",
   "metadata": {
    "id": "2WlTbF7rKX3c"
   },
   "source": [
    "### Create dataset for Graph Convolutional NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wfUzREFlxW4y",
   "metadata": {
    "id": "wfUzREFlxW4y"
   },
   "source": [
    "**From Duvenaud:**  \n",
    "\n",
    "Experimental setup -  Our pipeline takes as input the SMILES [30] string encoding of each\n",
    "molecule, which is then converted into a graph using RDKit [20]. We also used RDKit to produce\n",
    "the extended circular fingerprints used in the baseline. Hydrogen atoms were treated implicitly.  \n",
    "\n",
    "In our convolutional networks, the initial atom and bond features were chosen to be similar to those\n",
    "used by ECFP: Initial atom features concatenated a one-hot encoding of *the atom’s element, its\n",
    "degree, the number of attached hydrogen atoms, and the implicit valence, and an aromaticity indicator.* The bond features were a concatenation of whether the bond type was single, double, triple,\n",
    "or aromatic, whether the bond was conjugated, and whether the bond was part of a ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "-48hhKClKk28",
   "metadata": {
    "id": "-48hhKClKk28"
   },
   "outputs": [],
   "source": [
    "## load dataset if it exists and create it if it doesn't\n",
    "try:\n",
    "    # load saved dataset\n",
    "    dataset = dc.data.DiskDataset('../data/processed/ConvMolFeatures')\n",
    "except ValueError:\n",
    "    # create dataset\n",
    "    dataset_file = f'{get_home_path()}/data/interim/herg_data.csv'\n",
    "    tasks = ['herg_inhibitor']\n",
    "    featurizer = dc.feat.ConvMolFeaturizer()\n",
    "    loader = dc.data.CSVLoader(tasks=tasks,\n",
    "                               feature_field='SMILES',\n",
    "                               featurizer=featurizer)\n",
    "    dataset = loader.create_dataset(dataset_file, f'{get_home_path()}/data/processed/ConvMolFeatures', shard_size=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6NiW3cgDCEmX",
   "metadata": {
    "id": "6NiW3cgDCEmX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DiskDataset X.shape: (306865,), y.shape: (306865, 1), w.shape: (306865, 1), task_names: ['herg_inhibitor']>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "x7gmNfUhKk05",
   "metadata": {
    "id": "x7gmNfUhKk05"
   },
   "outputs": [],
   "source": [
    "# split dataset into training, validation, and testing sets\n",
    "splitter = dc.splits.RandomStratifiedSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mGznJwRqKXco",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1651616129847,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "mGznJwRqKXco",
    "outputId": "2fc90fa0-5501-45a2-a635-5c1b26f32f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (306865,), y.shape: (306865, 1), w.shape: (306865, 1), task_names: ['herg_inhibitor']>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8M5DQ7xdYEQS",
   "metadata": {
    "id": "8M5DQ7xdYEQS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "568d4f5c-a038-4cb7-b871-4b31bca807b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc.utils.data_utils.save_to_disk(dataset, filename='../data/processed/deepchem_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aDAuMIi-Kkx_",
   "metadata": {
    "id": "aDAuMIi-Kkx_"
   },
   "outputs": [],
   "source": [
    "# define metrics used to evaluate model\n",
    "metrics = [dc.metrics.Metric(dc.metrics.matthews_corrcoef, np.mean, mode='classification'), dc.metrics.Metric(dc.metrics.accuracy_score, np.mean, mode='classification'), dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode='classification')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "KgVKjtS9YEKF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1651612757137,
     "user": {
      "displayName": "K Ajayi",
      "userId": "14355577383255450167"
     },
     "user_tz": 240
    },
    "id": "KgVKjtS9YEKF",
    "outputId": "f11c9df9-9f6e-4118-b762-07079df48ccd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/processed/ConvMolFeatures'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afe8bedc-cc74-43b6-9713-4781edebeb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACWCAIAAADCEh9HAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO2deVyU1f7HP8PMALIoi6CyyCYqkGCSC4HLNRS1IS1E7VeklXGrm5NaN0y9jfeWiak11ctbWN4al1JaLCA33AoJ9w0pVGIRTAQEBGRnzu+PgxPCiMMw8zyznPerP+g5M8/zoYbPnHO+yxEQQsBgMBgMbbHgWwCDwWAYN8xGGQwGo1cwG2UwGIxewWyUwWAwegWzUQaDAQANDQ18SzBWmI0yGGZNWVnZli1b5syZ4+rqum7dul9//ZVvRcaHgCU8MRjmBiHk9OnTKSkpaWlpZ8+epRcFAgEhxM/P79y5c3Z2dvwqNC6YjTIY5kJDQ0NmZmZqaur3339fUlJCL9rY2EyePDk6OnratGmzZ88+efJkfHx8UlISv1KNC2ajDIaJU15evmfPnrS0tD179tTV1dGLgwcPnjZtmkQimTp1qpWVFb34+++/h4aGNjQ0pKamSiQS/iQbGcxGGQzTJCcnJy0tLTU19ddff1X9mQcGBsbGxkZHR48aNUogEHR91wcffLB06VIXF5fs7OwBAwZwK9lYYTbKYJgOjY2NR48eTU1N3bVrV3FxMb3Yp0+f8PBwiUQye/Zsd3f37u+gVCqnTJly6NChmTNn/vDDD/qXbAowG2UwjB7Vsn3v3r21tbX0oqura1RUVHR09PTp03sUMrp27dqIESOqqqq++OKLBQsW6EWxacFslMEwVlTL9qysLKVSSS8GBgZGR0dLJJLw8HC1y3ZN2Lp16zPPPGNnZ3fu3Dk/Pz/dSTZNmI0yGMZE75ftGjJ37tzk5OSIiIgjR44IhUKd3NNUYTbKYBgBFRUVu3fvTktL27dvX01NDb3o4uIybdo0LZbtmlBVVRUcHFxSUrJu3brXX39dtzc3MZiNMhiGS35+fmpq6jfffKPzZTuAurq6/fv3R0VF2draqn1Benp6VFSUpaXliRMngoODtX6QycNslMEwLFpbW48dO5aWlrZr167Lly/Ti9bW1hERERKJJCYmxsPDozf3v3r16t69e1NTU9PT05uamnbt2jVr1qx7vfjll1/+5JNPgoKCTp06ZW1t3ZvnmjAivgUwGAwAqKioSEtLo8t2VZL8oEGDJBKJRCKJjIy0sbHR+uZKpfLUqVO0+vP8+fP0olAoDA8PV+Xeq2X9+vUHDx7MyclZtWpVYmKi1gJMGzYbZTD4p76+/uOPP162bBn9V9Wy/eGHH7aw0L5/kKr687vvvrt27Rq9qKr+jI6OHjRo0H1vcvr06bCwsLa2tkOHDk2cOFFrMSYMs1EGg3/S0tKio6NdXV3//e9/P/roo56enr25W1lZ2d69eztVf3p5eUVFRXWq/tSQt9566+233/bx8ck+f97W3r432kwStqhnMPinpaUFQHh4+Isvvqj1TbpWf1pYWISGhkokkm6qPzXhrbfe+uXIkccFApvFi7F5s9YKTRVmowwG/zQ3NwOwtLTs6Ru7b9okkUjc3Nx6L08kEh1OShKEhuKXX/DYY5g5s/f3NCWYjTIY/ENtVCwWa/h6zZs26QpBQADWroVUioULMXYsBg7U7f2NGmajDAb/0EX9fWej2jVt0hmvvII9e7BnD+LjkZKixwcZG8xGGQz+6X5Rf/ny5ffffz8tLU0Vbbe1tZ0yZQrNheKunZ1AgM8/x4gRSE3F559j4UKOnmvwMBtlMPiHzkbvtahvaGig7ei1btqkM9zcsGkTZs/G4sWYOBH+/jxoMDyYjd5FZmbmtm3bdu7c6duBQYMGubm5BQQE9Cb/WVNycqBQ4Nw5VFWhf3+MG4fnnkPv0l8Yhk/3s9GQkJD169dPnjz5wQcf5FaXOmJiMG8eduzAggX45RewriUsb7QjNTU1Xl5e9fX19DPdCaFQ6Obm5uPj4+3t7ePjo/rB3d1dZ/1v3n0Xb70FkQjjxsHVFVev4tQpiMX47DM8/bRuHsEwSNasWbN8+fJly5atWbOGby0aUF2NkBBcvYo1a3CnZMCcYbPRv/j000+rq6snTpy4devWwsLCgoKCgoKCwsJC+nNJSUlxcXFxcfEvv/zS8V1isdjT09PHx+fL0aM97Ozg7Q1vb/j4YNAg9Gi//6uvsGIFwsKQnAxV0XR2Nh57DAsWwNcXDz+su9+VYVhoGGIyFBwcsHkzpk7FW28hMhIPPcS3IJ5hNtpOU1PThx9+CODNN9/09PT09PQcP358xxe0tLSUl5dfv349/26KioroD/2Li3GnkQQAWFrCwwO+vvD1xaBBcHNr/9nHR429trVhxQr07Ytdu9AxYjBiBL79FqNHY+VKHDqkt9+ewTPd740aIpGReOUVfPwx5s/HqVPo04dvQXzCbLSdL7744s8//wwJCZk6daraF4jFYjc3Nzc3t9DQ0I7Xm5qa6IxVWFyMvDwUFqKgAIWFKCtDfj7y8zvfyNYWPj7w8WmftHp7IyoKOTkoLMQzz6Br1DU0FGPH4sgRVFbCyUlnvzDDkNA6/Z5P3nsPhw/j4kWsXIkNG/hWwyfMRgGgra1tw4YNAFasWNHTzDsrK6thw4YNGzas80BTE65da3dS1T9//onr13HxIi5e/OuV1dW4cAHAPRdHo0fj2DFkZ4M1hjBRepp+bxBYW0OhwLhxkMvx6KOYPJlvQbzBbBQAdu7cmZeX5+fn98QTT+jsplZW7av4TlRXo7Dwr0lraSn69UN1NQA4Oqq/lbMzAFRW6kwbw8Awsr1RFaNGYeVKyGSYPx8XLtzzA2zqMBsFgPXr1wNYtmwZF2fOODhg5EiMHHnXRVq6py5DAACamgCANc01XYxyUU9Zvhx79uDYMSxeDIWCbzX8oH0rQ5Php59+Onv2rLu7e1xcHG8iaGi+sFD9aEEBAJY9asIYX4hJhUgEhQK2tvj667tCrOYEs1HQnt5Lly7VeTeHHhAWBqEQ+/apGWpuxsGDcHZGQADnshgcYcSzUQBDh+J//0NWFoYO5VsKP5j7oj4jI+Po0aNOTk4vvPBC19HCwkKRSNTLo280YsAAzJqF775DcjLmzLlraO1alJdjxQpWLmLCGGWIqSMdP7SEIDsbBQVobYW7O0JDYby/l2aY+2yUTkUXLVpkr66nd0JCgp+f386dO7mQIpdj4EA88wxWrcLvv6OqCmfO4B//gEyGESOwfDkXGhg8Yawhpq6kpMDfHyEhmDULs2cjLAwDB+KDD2Da1ZLEjDl//rxAILCxsSkrK+s6mpeXJxQKxWLx1atXORL0xx8kMpIAf/1jYUH+7/9IZSVHAhg8MX36dAC7d+/mW0jv+OorYmFBvLzI5s3k8mVSWEi+/56EhhKAvPYa3+L0iFkv6tesWUMIiY+Pd3Fx6TqamJjY1tb23HPP9fJgnB7g64v0dBQW4vRpVFXBxQVhYXB15ejpDP4w4hCTiqoqvPgiXFyQlQXVSXleXpg2DRMn4v33MXs2xo3jVaK+MF8bzc/P//bbb8Vi8ZIlS7qOlpaWbtu2TSgUvv7661wro1X5AJqbcfEis1FzwLhDTJSvvkJNDWQydDpttE8frF2LyZORlGSqNmq+e6Pvvfdea2trXFzc4MGDu46uW7eusbExJiZmKI/BRx8fhIaiqIg3AQyuMPoQE4DMTAAID1czNGECbGzaX2CKmKmN3rhxY8uWLRYWFq+99lrX0crKys8++wzAG2+8wbm0DgQFAcC5c3xqYHCCKYSY6IF6Xl5qhoRCeHqiuJhjRZxhpja6YcOGhoaGxx9/PDAwsOvoxx9/XFtbO23atE5dSLiG9ug9e5ZPDQxOMIVFfUsLgHu2ehKL0dpqqvF6c7TRW7dubdq0CcAydR1n6+vrN27ceK9RTqEFo2w2agaYwqKeth+7c8hzZyoq4OTUsw68xoM52ujHH39869atKVOmPKSuo9KmTZvKy8vHjh07kfd2Smw2ajaYwqI+JAQALl1SM1RcjNLSzn0kTAizs9H6+vqPPvoI95hstrS0fPDBBwBWrFjBtbKuDB0KOztcvYqKCr6lMPSLKSzqY2IA4PPP1Qx98gkAzJ7NqR4OMTsb3bx5c3l5+ejRoyera4+4devWq1evBgQEPProo9xr64yFBR54AEB7N1KG6WIKeaOhoYiJwZ49WLkSra1/Xd+2DevXIzAQPLb+0TPmlTfa0tJC2zMvV1dbqVQqVaMWFobxBfPggzh2DGfPmnNPXHPAFGajADZvRmUlVq+GQoHwcFha4swZ5OTA3x8//mjCnR4Nwyy44quvvioqKho+fPhjjz3WdXTXrl2//fbb4MGD586dy7029bAok3lgCiEmAP364cAB7NyJiAjk5eH8efj64r//xYULGDKEb3H6hO9qVO5QKpVBQUEAFAqF2hfQiNPGjRs5FtYdJ04QgAQF8a2DI157jYwfT1paOl9PSSHjx5ODB/nQxAl0HtrU1MS3EK1obSXV1XyL4BMzmo3++OOPOTk5np6e8+bN6zqanp5+6tQpV1fXZ599lntt92TECIhEyM1FfT3fUrggOxsZGVAqO1+/fh0ZGSgr40MTJxj33uh//oNRo3DmDN86eMOMbPS9994D8M9//lPtDhTtmLd48eI+BnVUrLU1hg1DWxtycviWwtAXLS0thBCxWNzT4xQNgkOHsHo1Cgtx8ybfUnjDXGz00KFDWVlZzs7Ozz33XNfRkydPHjp0qG/fvi+99BL32u4Dyx41dYx4Y7SkBPPmoa0N//43pkzhWw1vmIuNrlmzBsCSJUtsbW27jr777rsAXn75ZQcHB66V3RcWZTJ1jDX3vrUVTz6J8nI88gjefJNvNXxiFglP586dO3jwoL29/csvv9x1NDc3NyUlxdraWiqVcq/t/lAbNafZ6N69EN39wbx4kScpnGCs2U7LluHoUXh4YMcOMz/hxixs9J133iGEvPjii47qztFOTExUKpXPPffcoE59Eg2EUaMgEODCBbS1mcmHdeZMvhVwi1Eu6tPS8P77EImwYwf69+dbDc+Yvo1eunRp165dVlZWixcv7jpaXFz89ddfC4VCtc2bDQJHR3h64upVXLmC4cP5VsMF5851PgPtm2+wahU/Yjjgvov6hQsXCoXCJ598csKECQZRGFJUhPnzQQjee099g1Ezw/RtdO3atUqlcsGCBW5ubl1H161b19zc/NRTTw0x5PTgBx/E1att588LzcNGAwLQyVIMc52gK7qfjdbW1m7fvr2xsXHTpk3u7u5z58598skn1XbV4YimJsTEoLIS0dFQNzUxQwzgm02flJSUbN++XSgUqm3PfPPmzf/9738CgSAhIYF7bZqzbfx4j4EDl5txXp5p0/1s1N7e/vTp0zKZzN/f/9q1a++///7o0aO9vb2XLVuWm5vLrVIAwKuv4vRp+Plh61ZTbXzXU0zcRjds2NDc3Dxnzhx/f/+uo3K5/Pbt2xKJZMSIEdxr0xw7P79rpaXnWLDeRLlviCkwMHDVqlWXL1++ePFiQkLCoEGDioqK1q5dGxAQEBQUtGrVqvz8fI607tyJpCRYWSE5Gf36cfRQw4fvMio9cvPmTTs7OwCnT5/uOlpTU0MjTkePHuVeW48oLCwE0L9/f76F6J2pUwlAupZEJiURgHz9NR+a9E9WVhaAsWPHavj6tra2jIwMqVTa/05sx8LCIjw8XC6Xl5aW6lHopUukb18CkKQkPT7FCDHl2eiHH35YV1c3Y8aMUaNGdR399NNPq6qqJkyYEG7we+ReXl5OTk4VFRXXrl3jWwtD9/Q0b9TCwiIiIuLDDz8sKSlJSUmJi4uzsbHJzMxcvHixu7t7RETEpk2bamtrdazy9m088QRqajBvHuLjdXxzY4dvH9cXdXV19Ls6IyOj62hjYyONOO3Zs4d7bVrwt7/9DUBqairfQvRLRQUpKVFz/fZtUlJC6us5F8QJX3/9NYAhQ4YUFhZqd4f6+vrk5GSJRKKKU1lbW0skEoVCcfv2bd2onD+fAGTYMFJTo5sbmhAma6Pr168HMG7cOLWjn376KYCQkBClUsmxMO1YunQpgLfffptvIfplxw4SH082bep8/YcfSHw8uXqVD016Jjk52dHR0YkeZASEhobK5fLr169rd7fKykqFQhEZGanKi3JwcIiLi0tJSWnp2jhLY24pFAQgtrYkJ0frm5gwpmmjzc3N9PT5tLQ0tS/YvHnzgAEDduzYwbEwrdmyZQuAmJgYvoXol1dfJQARici5c3ddX7GCAOTMGZ5k6YebN2/OmTOHmt2ECRNiYmJUlcoikSgqKurLL7+8deuWdjcvLi6Wy+UdN6ycnZ3j4+MzMjJ6OnU4e/asg53dr5Mmka1btRNj8pimjdJT5oODg7v5xDQ0NLS2tnKpqjdkZ2cD8PX15VuIfqE2amNDwsNJx/91pmej+/fv9/DwAGBvb590J2JTX1+fkpISGxur2ie1srKia/O6ujrtHvTbb7/JZLJhw4ap/HTw4MFSqVRt3LUrNTU19L1///vftRNgDpimjcbExABIMqF4YktLi7W1tUAgqDbp/rjURt98kwDks8/+um5KNlpfX5+QkEAX3WFhYVeuXOn6mqqqKoVCIZFIRHeaC9jY2MTGxqakpDQ3N2v33BMnTixZsqRjEUpwcLDayEFH6J9ScHBwvanuTOsC07RROhsNDAz8888/+daiM2jhys8//8y3ED1CbbSwkDzwAHFyIjdutF83GRs9ceIEndyJxWKZTHbf9VBJSQldm6takTo5OcXFxaWnp2u3ra9KlnJxcQGQ0+1eJz0l197ePjc3V4tnmQ+maaOlpaUhISEAvL291X7bGyMvvPACALlczrcQPUJttKSE7NtHADJ/fvt1E7DRlpaWxMREuloPCgo608NfprCwMDExcXiHamBPT0+pVHrf6eS9aGpqOnDgQDcvOH78uKWlpUAg+Pbbb7V7hPlgmjZKCKmsrAwLCwMwcODACxcu8C1HB2zcuBHAggUL+BaiR1Q2Sgh54gkiELSfv2TsNvrHH3/QaI9AIJBKpY2NjVrf6uLFizKZzNfXV+WngYGBMpns8uXLOhRcWVnp7e0NYOnSpTq8ralisjZKCKmrq5syZQpdBx07doxvORpRX1/f0NCgdigzMxPAyJEjOZbEJR1t9OpVYmdHAgNJS4sR26hSqUxKSqIheC8vr0OHDunqzqdOnZJKpQMGDOjop4mJib3fyFIqlTNnzgQwduxYYz1lj1tM2UYJIY2NjY8//jgAOzu7g4Z9sKRSqUxOTvbx8aHdUbtSV1dnYWFhaWnZm7mMgdPRRgkha9cSgHz44V022tbGo8CeUVpaKpFIqMfFxsZWVlbq/BGtra0ZGRnx8fF9+/alD1IVhpaXl2t3z3feeYdOPgoKCnQq1mQxcRslhLS2ts6fP5/GOg22Zmn//v0jaZd7YNKkSfeKHtDoRE+31YyITjba3EwCA4mTE3n55XYb/f134uND5HKiq9oc/fHNN984OzsDcHFx+f777/X9uIaGBlVhaKdkqdraWs3vc+TIEaFQaGFhYbB/LAaI6dsoIUSpVNIDQiwtLZOTk/mWcxc5OTmxsbGqoEFSUlI30du5c+cC2Lx5M5cKOaCiguzdS0gXGyWEHD5MBAJiY9Nuo2+8QQACEFdXsnq1gZ6OXl1dHX+n6jwqKuratWscP71TslSfPn1ostR9V+ilpaU0I+pf//oXN2pNA7OwUUKIUql84403AAiFws8//5xvOYQQUlxcHB8fLxQKATg6OiYmJt5rV1QFPZhv0aJF3Cjkhn37iLs7sbEhublqbJQQ8tRT7dZ55gxpayMpKWTcuPYr9vZEKlVfhs8XBw4c8PT0pOYll8t5rDauqKhISkrqmCzl6OhIC0PVflW3tbVFRkbS9ZARVaYYAuZioxR6GL1AINiwYQOPMmpra2UyWZ8+fWj+YHx8fFlZmSZvpD0shg0bdvPmTX2L5IC6OvLSS0QgIACZOJEUFqq30dJS4uDQOcSUkUEkknYztbQkcXHk0iWO5XemoaFBlVc/duzYS7wLukNRUZFcLu/Y58zDw6NrstTy5csBDBgwwJSyrbnBvGyUEPLf//6XftATEhK4f3pzc3NSUpKrqyt189jY2Ly8PE3eePv27cTERHt7e1rLZGdnJ5VKi4uL9S1Yfxw/ToYNIwARi4lMRujsJzeXpKeTriG07GySnq6mtdDZsyQujgiFBCAWFkQiISdPciG+KxcuXAgODgYgEok0yavnBZos1fG8HG9v74SEhNzc3N27d1tYWAiFwu6TSRlqMTsbJYRs376dbhu98sorXK65UlJSVJ/gsLCwzMxMTd7V0tKSlJSkOrV08uTJkyZNoj9bWlouXLhQtwmDHNDSQhITiVhMABIUpIM0prw8IpUSK6v2yWlkJOGyE3dra6sqrz4gIODUqVPcPVsrlEplZmbmK6+8Qr/OVfEoAO+++y7f6owSc7RRQgg9mB5AXFxcbxqIaUhWVlZERAT9vA4fPlzzMFd6ejqd4wAYM2bMkSNH6PXz58/HxcXRLwMLCwuJRHL8+HG9ydclv/9OHnqIAEQgIFKpmomn1ly/ThISiK1tu5mGh5OUFKLvb8n8/Pzx48fTtUV8fLzOmntygqow1MHBYfDgwX5+fsbSN9LQMFMbJYQcOnTI3t4ewKxZs/SXiZmbm6sKxLu5uSUlJWno2idPnlTNOr28vBQKRdePeH5+vlQqpd8HAMLDw1NSUvTwS+gGpZIkJbXbnJcXOXxYL08pLycyGXFyajfT4GCiUBA9fVEqFAp6Ss2gQYN2796tl2dwQnFxsVAotLKy6lFqFEOF+dooIeTEiRM0s2/GjBk6b2BTXl4ulUrphNHW1jYhIaFGs7bhRUVF8fHxdAPX2dk5MTGxe5cvLS2VyWT97pwvNmrUKIVC0WZgSerXr5NHH223tthYooc89LuoqSHr1hE3t/YnRkd/lJSUpMMvyxs3bjz22GOqvHoTiPjRyukffviBbyFGiVnbKCHk4sWLdNtxwoQJWrfI7URdXV1iYiKtKhGJRPHx8Ro2M79582ZCQgKdXfbp0ychIUHztni3bt2Sy+UDBw6kf9sPPPCAQqHQuqmabklOJs7OBCAuLmTXLu6e29hIkpLI5MnVAoEFnTOuW7dOwy+zbvjuu+/o+TQODg5bTaWT8bvvvgvg+eef51uIUWLuNkoIyc3NpYl+oaGhWtfPUdra2hQKhSocFBkZmZ2drckbm5qa5HK5g4MD3euMjY3Vrg6vrq5OLpfTX4fuBtBDpLW4lU6oribx8e1TwmnTCLd56O20tbWlpKSMHj2a/jfp27evVCrVLqfn1q1bqrz6KVOmlBhUwmrvoH3BXV1dDW0dYxQwGyWEkKKiInqQfUBAgNZZROnp6arz7seMGaNhY1BVKb3Kec+ePaudABXNzc0KhSIgIIDe08XFRSaT6aOgu3vS04mHR3s3e7lc79Ge+5KRkaGqcLeysoqPjy8qKtL87ZmZmX5+fnShkJiYaHp2Qz+ExhKrNCiYjbbTmxalJ06cUIWD/P39k5OTNYx4HjhwQJUUHRQUdK+To7SDzsLGjh1L729vby+VSrmZQNXX17/66hI/v99oxPyPPzh4pqacPn06NjaWFvaIxeK4uLjuWxcTQhobGxMSEmi92ZgxY0y1h/GiRYsArFy5km8hxgez0b+oqqrqaYvSoqKiuLg4+jepSThIRcdSeg8Pj+5L6XtJx1mYpaVlXFycXgtsTp48SbsLBweHrVlDDDIPnWRnZ6syxgQCgUQiycrKutcradcYkUiUkJBgINvN+mD//v0AQkJC+BZifDAbvQtVi1JHR0dNWpQuWbIEgI2NzfLlyzWMUJWUlKhK6e3s7GQyGTen3Jw9ezYuLo4+l6aa6jxRvGOD98DAQA0PTeORgoICqVRKq3JVGWOqlURbW5tcLqd56b6+vke5zOnng6amJhoXZf3xegqz0c40NjY+8cQT1OPuWxhXUVHx0ksvabhS7lpKf0N12BBX5OXlSaVSag10K1ZX7pCfn09LDIwuEf3GjRsymczR0ZH+Nxk5cqRCocjLy5s4caLq19H6YE7jYvbs2QA2btzItxAjg9moGlpbWxcsWECnmTpJq6al9LRReY9K6fVEUVGRVCpVNabsNAvTAlUi+uDBg3XY4J1LqqurV69eraqPpN927u7ue/fu/eOPPwy/xFMnKBQKANOmTeNbiJHBbFQ9SqXy1VdfpZuJO3fu7M2tOpXSG87asLy8XCaTOTk5UW3BwcEKhaKnpbGlpaXR0dH0DsabiH779u3Nmzd/8sknjY2NCoXC399/6dKl8+bNq6ysbGpqEggEYrHYHAolKyoqaDlT77NrzQpmo90hk8kACIXCzzoemq4xWVlZtOAaPSyl55La2lq5XO7h4UF1+vj4yOVyDbdrv/32W1Ui+rZt2/QtVX9UV1fTZAb6r52+S+iOYVVVFR/SuIYevcdBu35TgtnofVC1KF2/fr3m76Kl9DSC7+LiIpfLOWiA0huampoUCgU9pISmYctksm6Mo2Mi+tSpU00gEZ3uF6vtnE3TRY2uk5Z20A/8s88+y7cQY4LZ6P355JNPNG9RWl5enpCQQKPVPSqlNwQ0LPg5evSoKhGd3wbvOsTd3R2A2uILmganYWNDYycnJwesnKmHMBvViO3bt4vFYgD/+Mc/7vXxop2VtSilN0DuVfDTscH7mDFjDKfBe++hyaFqk7RoFxLzadtBt/LvlUjL6AqzUU3ppkVp11J6DbP3DZyjR49KJBJVwc/MmTOHDh1Kf3777bcNfJuip9B84b30aL27ef755wFotz9ujNDg6vLly/kWYjQwG+0Bhw8fpi1KZ86cqapW6thZefTo0arOyiaDquBHJBJZWVkNHz78JF8ndeiTp556CoDajk3Lli0DsHr1au5V8cKBAwcAjBgxgm8hRoMFGBozadKkgwcPOjs7//jjj48//nhmZubkyZOnTJly4cIF2ln5+GS98ocAAAV9SURBVPHjNGfblHjggQe2bNly6dKlL774Ii0t7cyZMw899BDfonSPi4sLgPLy8h4NmSQTJkxwcHDIzs4uKCjgW4txwGy0Z4wePfrAgQOurq579uyJiIg4fPhw//79P/roo8uXLz/zzDOqk2xND19f36effjoyMlJVOmliMBtVIRaLp06dCuCnn37iW4txwGy0x4wcOfKXX36ZP3/+jBkzEhISrly5smjRIhqaZxgv1CvLysq6DtHSJvOxUQC0pCI1NZVvIcaBiG8BRsmwYcO+/PJLQogJTz/NDTYb7ciMGTNEItGRI0dqa2tpPIDRDWw2qj3MQ02JbqacZmijTk5OYWFhzc3NtHseo3uYjTIYgAaz0bKyMkII17L4g63rNYfZKIMBdLs3am1tbW9v39zcXFtby7ku3qA2mpaW1tbWxrcWQ4fZKIMBAP369bO0tKypqWlqauo6aobr+uHDh/v7+9+8efP48eN8azF0mI0yGAAgEAhot6qKioquo2ZoowBoQTBb198XZqMMRjvdrOu7GTJh2PaohjAbZTDaYTlPnRg/fryjo2NOTk5eXh7fWgwaZqMMRjvd5Dy9MHz48YkTH2ls5FwUn4hEoqioKAC7d+/mW4tBw2yUwWhng79/XVDQE1VVXYfChMIxP//snZ/PvSp+Yet6TWA2ymC0M1Asts3J6XP9upoxFxcAMLNFPYDp06eLRKKff/6ZnrPCUAuzUQbjDtQr1caRuhkyaRwdHcPDw1taWtLT0/nWYrgwG2Uw7tDNlNNcZ6Ng63oNYDbKYNyBHlKv1iu7GTJ1Zs6cCeCnn35qbW3lW4uBwmyUwbgDm42qY8iQIUOHDq2srMzKyuJbi4HCbJTBuEM3XtmnD2xt0dgIcyqrV8HW9d3DbJTBuIODA8RiVFejuVnNqBmv65mNdg+zUQbjDgIBnJ0BQF1ZvTmv6yMiIpydnXNzc69cucK3FkOE2SiD0YFuppzmmvMEQCgU0nKmtLQ0vrUYIsxGGYwOsCjTPWDr+m5gNspgdKCbKacZ740CmD59ulgszsjIqFJXLGvmMBtlMDrAZqP3oF+/fhEREa2trfv27eNbi8HBTgZlMDrAbPTeREdHFxcXszNFusJslMHowH1t1CxDTBSpVLpkyRK+VRgibFHPYHTgvpF6M56NCoVCviUYKMxGGYwOdOOV5h1iYnQDs1EGowP37ZXHbJTRBWajDEYHXF3h6Ql3dzVDNja4cgU3bnCuiWHoCAghfGtgMBgMI4bNRhkMdVRV4V//QmAgrKxgYQFPT8yfj99+41sWwxBhs1EGowuFhXjkEeTnIzISkybBygrZ2UhOBiHYsQOzZvGtj2FYMBtlMO6GEISH49gxbN+OJ5/86/pvv+Fvf0N9PS5ehJcXf/oYBgdb1DMYd3P4MLKy8PTTd3kogMBArF+Pujp89BFPyhgGCrNRBuNuaM347NlqhubMgZUV9u7lWBHDwGE2ymDczaVLAODtrWbIygr+/rhyBWwrjNEBZqMMxt3U1QHAoEHqR+3t0dKChgYuFTEMHGajDMbd2NkBuKdR1tVBJEKfPlwqYhg4zEYZjLsZMgQAcnPVDLW0IC8PQ4ZAIOBYFMOQYTbKYNzNI48AwPffqxlKS0NDA6ZM4VgRw8BheaMMxt0olQgJwaVLSE/HxIl/Xb9xA+HhuHYN2dntM1YGAwCzUQZDDRcu4JFHUFODZ5/FI4/A2hrnz2PjRpSVISkJCxfyrY9hWDAbZTDUUVCAlSvx44+4fRsAhEI8/DBWrcLkyXwrYxgczEYZjHvT3Iw//0RjIzw82iP4DEYXmI0yGAxGr2CRegaDwegVzEYZDAajVzAbZTAYjF7BbJTBYDB6BbNRBoPB6BX/D9zy9pf++VQJAAABRnpUWHRyZGtpdFBLTCByZGtpdCAyMDIyLjAzLjIAAHice79v7T0GIOBlgABGIOYHYgEgbmBkY0gAiTGzOWgAaWYWDgjNxOaQAaKZGZEYEBVsDFCVEJqJnQGsgAlqFBMTXCEWI6AMmC3cQNcwMiUwMScws2QwsbAmsLIpsLFrMLFxKHBwMnByMXBxZzBx8yTw8GYw8fIlsDJmMPFxJYgwsTIyMbOwsnJz8fHyiO+DegoM+PWsmxxsgp/sB3G2nMtwSL29EaSAobJsosORLRH2IHaweY7DOX5WBxBbyVPAwevCJbD4ZV0+h/8PxOxA7Bs6tfa2cqZgc5zK+uyzP/McALF7rfbsi9Dq2gti3718Zv9x6RywmjIb2wOrWyeA7TLf0nEgubQBLB6xcvWB+eHHbUBsK73pB/IObQDbFaHof0CncQaYLQYA3OFKqmAFP5MAAAGielRYdE1PTCByZGtpdCAyMDIyLjAzLjIAAHicfVNbbtswEPzXKfYCJvbF12dsB0FRRAJat3fof+6PzkpwqSBESS1BSsPhcna0ULQf9+9/Puhf0/uyEPF/nt47/TZmXt4pJnR9ffu20u3xcn2+uW2/1sdPkkxSsAf9M/blsb0/3wjdyBOXXtXpIqk2qx07Eu9tbFUALRWrBaQXTubVap0AjTYwZs9VFJ+bl8xtgvODsHMDjSbGsdODM3CaNLsXJ0nFS28ywZUDp5I90hLk5zbBVeA49dZ62S9SuXqfARsuIklEe4M0oGa1PLtxp3VXpNRiHjMuNZL9ihQUJ1QuzMgzoF1VUdEJNCqDU3su7YBqU60zhSRqc/GkVcId4Ge23HQGtYBm5OquO0DdbJqqH6TwhUEeSda420wnZLfRxZKCFBeEZF3APkG+rvdP5jvseN3W+7BjdB2mc4QNa3nEcFD0PIyCBZXhB0HUUXZFtFFcwbKPEkrEuVCyD3Kqh8cgepLdYxA7qesxiJ9U9Bgkn9Ry5DVYSiDy6aRQ6axJrJ+/N+bLX+HRyRRayjA1AAAA23pUWHRTTUlMRVMgcmRraXQgMjAyMi4wMy4yAAB4nCWPyY3EMAwEU9mnDdAEL/GAMS//d4NQAJPABD+U9iMIhVZ36Zk8j+d4/Z2/z5Q551vOPvjncxiSVwhcjJEaBbeia3gTQrXQCLgFRXgMIOQmpnATVma5r1RQWDVjZJZKuDpOog73qvBwtRUjD/NNGZ1I9kKJSPVov6nhuZmkSI9ehvIvRqQjG4xuM5PWIDFVzR2KvhcwatKyuBR727gJF5tt+2HmDdy8/dYPizJBkKKo1w2HjeAuTvNBCefnCz8uP03l64UvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fdae1f39c40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chem.MolFromSmiles(herg_df.SMILES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be246d55-a850-4b4b-8602-c9cb155f71ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(herg_df.adjacency_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14ae2ea3-2d5d-4228-844a-d6ec3073a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "[[13], [12], [4, 11], [9, 14], [7, 2], [11, 7], [12, 10], [5, 4], [13, 9], [8, 3], [6, 11], [10, 5, 2], [14, 1, 6], [0, 8, 14], [3, 12, 13]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect features for molecule 0\n",
    "conv_feature = train_dataset.X[0]\n",
    "# Print the atom features\n",
    "print(conv_feature.get_atom_features())\n",
    "# Print the adjacency list\n",
    "print(conv_feature.get_adjacency_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f44b2045-ce3b-4d81-a2db-b398ddd68c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], shape=(0, 0), dtype=int32),\n",
       " array([[13],\n",
       "        [12]], dtype=int32),\n",
       " array([[ 4, 11],\n",
       "        [ 9, 14],\n",
       "        [ 7,  2],\n",
       "        [11,  7],\n",
       "        [12, 10],\n",
       "        [ 5,  4],\n",
       "        [13,  9],\n",
       "        [ 8,  3],\n",
       "        [ 6, 11]], dtype=int32),\n",
       " array([[10,  5,  2],\n",
       "        [14,  1,  6],\n",
       "        [ 0,  8, 14],\n",
       "        [ 3, 12, 13]], dtype=int32),\n",
       " array([], shape=(0, 4), dtype=int32),\n",
       " array([], shape=(0, 5), dtype=int32),\n",
       " array([], shape=(0, 6), dtype=int32),\n",
       " array([], shape=(0, 7), dtype=int32),\n",
       " array([], shape=(0, 8), dtype=int32),\n",
       " array([], shape=(0, 9), dtype=int32),\n",
       " array([], shape=(0, 10), dtype=int32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feature.get_deg_adjacency_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f7e2a40-84dc-4de0-897a-9cdfd325fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_deg_sort',\n",
       " 'agglomerate_mols',\n",
       " 'atom_features',\n",
       " 'canon_adj_list',\n",
       " 'deg_adj_lists',\n",
       " 'deg_block_indices',\n",
       " 'deg_id_list',\n",
       " 'deg_list',\n",
       " 'deg_slice',\n",
       " 'deg_start',\n",
       " 'degree_list',\n",
       " 'get_adjacency_list',\n",
       " 'get_atom_features',\n",
       " 'get_atoms_with_deg',\n",
       " 'get_deg_adjacency_lists',\n",
       " 'get_deg_slice',\n",
       " 'get_null_mol',\n",
       " 'get_num_atoms',\n",
       " 'get_num_atoms_with_deg',\n",
       " 'max_deg',\n",
       " 'membership',\n",
       " 'min_deg',\n",
       " 'n_atoms',\n",
       " 'n_feat']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(conv_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d696e5e-eff1-4d8c-943e-21f561b963e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function deepchem.feat.mol_graphs.ConvMol.agglomerate_mols(mols, max_deg=10, min_deg=0)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feature.agglomerate_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce78965d-b48b-4d88-ae9e-b1caa7bad2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fdb64473b80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chem.MolFromSmiles(herg_df.SMILES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddafdc20-6a8c-436e-848f-d843249ac285",
   "metadata": {},
   "source": [
    "### Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1HAFXE6VTCJn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HAFXE6VTCJn",
    "outputId": "33a03746-2ae9-4fb0-b72d-c36d176d0b28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(531,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(531, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(3340,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(3340, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(2925,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(2925, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(136, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_11:0\", shape=(531,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_10:0\", shape=(531, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_13:0\", shape=(3340,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_12:0\", shape=(3340, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_15:0\", shape=(2925,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_14:0\", shape=(2925, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_16:0\", shape=(136, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_14:0\", shape=(531,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_13:0\", shape=(531, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_17:0\", shape=(3340,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_16:0\", shape=(3340, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_20:0\", shape=(2925,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_19:0\", shape=(2925, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_22:0\", shape=(136, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(545,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(545, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(3320,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(3320, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(2895,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(2895, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(172, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_11:0\", shape=(545,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_10:0\", shape=(545, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_13:0\", shape=(3320,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_12:0\", shape=(3320, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_15:0\", shape=(2895,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_14:0\", shape=(2895, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_17:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_16:0\", shape=(172, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_14:0\", shape=(545,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_13:0\", shape=(545, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_17:0\", shape=(3320,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_16:0\", shape=(3320, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_20:0\", shape=(2895,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_19:0\", shape=(2895, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_22:0\", shape=(172, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_10:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_12:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_14:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "metrics must be one of metric function / dc.metrics.Metric object /list of dc.metrics.Metric or metric functions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m train_dataset, valid_dataset, test_dataset \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39mtrain_valid_test_split(dataset)\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_dataset)\n\u001b[0;32m----> 9\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m training_score_list\u001b[38;5;241m.\u001b[39mappend(train_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean-matthews_corrcoef\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m validation_scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(valid_dataset,\n\u001b[1;32m     14\u001b[0m                                    metrics,\n\u001b[1;32m     15\u001b[0m                                    transformers)\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/models.py:215\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, dataset, metrics, transformers, per_task_metrics, use_sample_weights, n_classes)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mEvaluates the performance of this model on specified dataset.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m  separately.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator(\u001b[38;5;28mself\u001b[39m, dataset, transformers)\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_model_performance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_task_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_task_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/utils/evaluate.py:295\u001b[0m, in \u001b[0;36mEvaluator.compute_model_performance\u001b[0;34m(self, metrics, csv_out, stats_out, per_task_metrics, use_sample_weights, n_classes)\u001b[0m\n\u001b[1;32m    291\u001b[0m   logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    292\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats_out is deprecated as an argument and will be removed in a future version of DeepChem.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStats output is not written; please manually write output instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Process input metrics\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43m_process_metric_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m    298\u001b[0m y \u001b[38;5;241m=\u001b[39m dc\u001b[38;5;241m.\u001b[39mtrans\u001b[38;5;241m.\u001b[39mundo_transforms(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_transformers)\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/utils/evaluate.py:111\u001b[0m, in \u001b[0;36m_process_metric_input\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m    109\u001b[0m     final_metrics\u001b[38;5;241m.\u001b[39mappend(wrap_metric)\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics must be one of metric function / dc.metrics.Metric object /\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist of dc.metrics.Metric or metric functions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_metrics\n",
      "\u001b[0;31mValueError\u001b[0m: metrics must be one of metric function / dc.metrics.Metric object /list of dc.metrics.Metric or metric functions."
     ]
    }
   ],
   "source": [
    "# training_score_list = []\n",
    "# validation_score_list = []\n",
    "# transformers = []\n",
    "# cv_folds = 5\n",
    "# for i in range(0, cv_folds):\n",
    "#   model = generate_gcnn_model()\n",
    "#   train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset)\n",
    "#   model.fit(train_dataset)\n",
    "#   train_scores = model.evaluate(train_dataset,\n",
    "#                                 metrics,\n",
    "#                                 transformers)\n",
    "#   training_score_list.append(train_scores[\"mean-matthews_corrcoef\"])\n",
    "#   validation_scores = model.evaluate(valid_dataset,\n",
    "#                                      metrics,\n",
    "#                                      transformers)\n",
    "#   validation_score_list.append(validation_scores[\"mean-matthews_corrcoef\"])\n",
    "#   print(training_score_list)\n",
    "#   print(validation_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4vVsMFXO4evS",
   "metadata": {
    "id": "4vVsMFXO4evS"
   },
   "outputs": [],
   "source": [
    "model = generate_gcnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf94804c-c87c-4eee-b52c-bcfa27225fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02195476144552231"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b882a925-9b37-4f2c-99ca-beed4f463a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.8986171319786729, 'mean-accuracy_score': 0.9916820100043994}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.4466402519674134, 'mean-accuracy_score': 0.9598852934467365}\n"
     ]
    }
   ],
   "source": [
    "print('Training set score:', model.evaluate(train_dataset, metrics, transformers))\n",
    "print('Test set score:', model.evaluate(test_dataset, metrics, transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f9a251a-fb54-479f-b859-6ee40d87ed01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/models.py:115\u001b[0m, in \u001b[0;36mModel.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;124;03m\"\"\"Dispatcher function for saving.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m  Each subclass is responsible for overriding this method.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0304cad-826d-4013-ab74-56fd8c189f6c",
   "metadata": {},
   "source": [
    "# model results\n",
    "\n",
    "1. 2 GCN layers; 128 neurons each, with 20 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.6428713584722922, 'mean-accuracy_score': 0.9734085021100484}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.4787317574971372, 'mean-accuracy_score': 0.9628833056343077}  \n",
    "\n",
    "2. 2 GCN layers; 128 neurons each, with 100 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.8986171319786729, 'mean-accuracy_score': 0.9916820100043994}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.4466402519674134, 'mean-accuracy_score': 0.9598852934467365}\n",
    "---\n",
    "3. 2 GCN layers; 128 neurons each, 1-layer FNN (256); with 100 epochs, with 20% dropout:   \n",
    "Training set score: {'mean-matthews_corrcoef': 0.45850212856054634, 'mean-accuracy_score': 0.964960161634595}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.3731441911144923, 'mean-accuracy_score': 0.9615133937300397}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.37520900721711353, 'mean-accuracy_score': 0.9615472349854988}  \n",
    "\n",
    "4. 2 GCN layers (128, 256); 1-layer FNN (256); 100 epochs; with 20% dropout:   \n",
    "Training set score: {'mean-matthews_corrcoef': 0.4142104435615528, 'mean-accuracy_score': 0.9632004301565835}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.3484192642848399, 'mean-accuracy_score': 0.9608616307110734}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.330927336552633, 'mean-accuracy_score': 0.9602111643366898}  \n",
    "\n",
    "5.  3 GCN layers (64, 128, 256); 1-layer FNN (256); 100 epochs; 20% dropout:   \n",
    "Training set score: {'mean-matthews_corrcoef': 0.5025293293380898, 'mean-accuracy_score': 0.9669235657373764}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.37836007619427664, 'mean-accuracy_score': 0.9616763344847813}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.40029470609974166, 'mean-accuracy_score': 0.9624270863883729}  \n",
    "\n",
    "6. 2 GCN layers; 128 neurons each, 1-layer FNN (256); with 300 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.980639353687451, 'mean-accuracy_score': 0.9983543251918596}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.4669227968724198, 'mean-accuracy_score': 0.9597536335788307}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.43511600018388047, 'mean-accuracy_score': 0.9573109134161045}  \n",
    "loss? 0.01113940954208374\n",
    "\n",
    "7. 2 GCN layers (512, 1024); 1-layer FNN (256); 20 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.6449390262476722, 'mean-accuracy_score': 0.9708625943004253}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.4749802086322286, 'mean-accuracy_score': 0.9571791696539138}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.49445900413598426, 'mean-accuracy_score': 0.9600156418027178}  \n",
    "loss? 0.08594311078389485  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.48013768550166536, 'mean-accuracy_score': 0.9623280975037476}\n",
    "\n",
    "8. 2 GCN layers (1024, 2048); 1-layer FNN (256); 20 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.5892717340747637, 'mean-accuracy_score': 0.9709155491828654}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.44678468227552504, 'mean-accuracy_score': 0.9629472723717656}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.4300309731397157, 'mean-accuracy_score': 0.9623293251213869}  \n",
    "loss? 0.08380654652913412  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.4794959701248735, 'mean-accuracy_score': 0.9537574138043408}  \n",
    "[[28548   764]  \n",
    " [  655   719]]  \n",
    "Specificity = 0.9739  \n",
    "FPR = 0.0261  \n",
    "Recall/TPR = 0.5233  \n",
    "Precision = 0.4848  \n",
    "\n",
    "\n",
    "9. 2 GCN layers (256, 512); 1-layer FNN (256); 20 epochs:   \n",
    "Training set score: {'mean-matthews_corrcoef': 0.6073488599104414, 'mean-accuracy_score': 0.9714043634823131}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.45385158253018826, 'mean-accuracy_score': 0.9619044515414196}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.45851465260990887, 'mean-accuracy_score': 0.9628507185453123}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.475989831688181, 'mean-accuracy_score': 0.9620999804471094}  \n",
    "Loss? = 0.08921345869700113  \n",
    "[[28983   329]  \n",
    " [  834   540]]  \n",
    "Specificity = 0.9888  \n",
    "FPR = 0.0112  \n",
    "Recall/TPR = 0.393  \n",
    "Precision = 0.6214  \n",
    "\n",
    "10. 2 GCN layers (1024, 512); 1-layer FNN (256); 20 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.6335385781975322, 'mean-accuracy_score': 0.9702923109510697, 'mean-roc_auc_score': 0.961515084775735}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.4787927575103589, 'mean-accuracy_score': 0.9584501075408981, 'mean-roc_auc_score': 0.9025637020453146}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.45549041923086453, 'mean-accuracy_score': 0.9574412617720859, 'mean-roc_auc_score': 0.8991438760820261}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.47967790456375287, 'mean-accuracy_score': 0.9603728084468487, 'mean-roc_auc_score': 0.9118796090983995}  \n",
    "Loss? = 0.09841734568277995  \n",
    "[[28875   437]  \n",
    " [  779   595]]  \n",
    "Specificity = 0.9851  \n",
    "FPR = 0.0149  \n",
    "Recall/TPR = 0.433  \n",
    "Precision = 0.5766  \n",
    "\n",
    "11. 2 GCN layers (512, 1024); 1-layer FNN (256); 200 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.9886646777979844, 'mean-accuracy_score': 0.9990305183060955, 'mean-roc_auc_score': 0.9999464164108443}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.47246252561496016, 'mean-accuracy_score': 0.9592322231636577, 'mean-roc_auc_score': 0.8847153576956326}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.45208120822716674, 'mean-accuracy_score': 0.9575390230390719, 'mean-roc_auc_score': 0.8811270699702469}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.5072253130749046, 'mean-accuracy_score': 0.9620999804471094, 'mean-roc_auc_score': 0.9022784670609987}  \n",
    "Loss? = 0.005859992504119873  \n",
    "[[28888   424]  \n",
    " [  739   635]]  \n",
    "Specificity = 0.9855  \n",
    "FPR = 0.0145  \n",
    "Recall/TPR = 0.4622  \n",
    "Precision = 0.5996  \n",
    "\n",
    "12. 2 GCN layers (512, 1024); 1-layer FNN (256); 100 epochs; 40% dropout:  NO GOOD!\n",
    "\n",
    "\n",
    "13. 3 GCN layers (64, 256, 1024); 1-layer FNN (256); 50 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.909140121876442, 'mean-accuracy_score': 0.9923948641910938, 'mean-roc_auc_score': 0.998363235694375}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.4833174530782624, 'mean-accuracy_score': 0.9604379847487453, 'mean-roc_auc_score': 0.8920752781498891}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.4723276007506134, 'mean-accuracy_score': 0.9602437514256852, 'mean-roc_auc_score': 0.8915162808121608}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.5157338258031209, 'mean-accuracy_score': 0.9591018705598644, 'mean-roc_auc_score': 0.9039374184599518}  \n",
    "Loss? = 0.024915108680725096  \n",
    "[[28703   609]  \n",
    " [  646   728]]  \n",
    "Specificity = 0.9792  \n",
    "FPR = 0.0208  \n",
    "Recall/TPR = 0.5298  \n",
    "Precision = 0.5445  \n",
    "\n",
    "14. 4 GCN layers (64, 128, 256, 1024); 1-layer FNN (256); 50 epochs:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.9070435223658783, 'mean-accuracy_score': 0.992325615498672, 'mean-roc_auc_score': 0.9984876464016141}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.47465749458314266, 'mean-accuracy_score': 0.9614808055790914, 'mean-roc_auc_score': 0.8894597581984992}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.44472971937887906, 'mean-accuracy_score': 0.9596245967347736, 'mean-roc_auc_score': 0.8910045500476188}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.5090293891953639, 'mean-accuracy_score': 0.9603402202959004, 'mean-roc_auc_score': 0.9029619360428067}  \n",
    "Loss? = 0.024895613193511964  \n",
    "[[28787   525]  \n",
    " [  692   682]]  \n",
    "Specificity = 0.9821  \n",
    "FPR = 0.0179  \n",
    "Recall/TPR = 0.4964  \n",
    "Precision = 0.565  \n",
    "\n",
    "15. 2 GCN layers (512, 1024); 1-layer FNN (256); 50 epochs; ExponentialDecay(0.0002, 0.9, 1000) learning rate:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.7217100528792778, 'mean-accuracy_score': 0.9786062274941749, 'mean-roc_auc_score': 0.9822691438584852}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.4959475259187963, 'mean-accuracy_score': 0.963501270937887, 'mean-roc_auc_score': 0.9078039350671072}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.45667643852553963, 'mean-accuracy_score': 0.960993254472578, 'mean-roc_auc_score': 0.9089811772064509}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.4914812283046677, 'mean-accuracy_score': 0.9584501075408981, 'mean-roc_auc_score': 0.8989923522188428}  \n",
    "Loss? = 0.0440226411819458  \n",
    "[[28741   571]  \n",
    " [  704   670]]  \n",
    "Specificity = 0.9805  \n",
    "FPR = 0.0195  \n",
    "Recall/TPR = 0.4876  \n",
    "Precision = 0.5399  \n",
    "\n",
    "Training set score: {'mean-matthews_corrcoef': 0.9207555725826339, 'mean-accuracy_score': 0.9931443794502468, 'mean-roc_auc_score': 0.9987767954381437}\n",
    "Validation set score: {'mean-matthews_corrcoef': 0.49751482292778093, 'mean-accuracy_score': 0.9596884572769341, 'mean-roc_auc_score': 0.9024850732549436}\n",
    "Test set score: {'mean-matthews_corrcoef': 0.4706869427390173, 'mean-accuracy_score': 0.9575064359500766, 'mean-roc_auc_score': 0.8960391845161029}\n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.4743725453287934, 'mean-accuracy_score': 0.957928697125725, 'mean-roc_auc_score': 0.8933988700297318}\n",
    "Loss? = 0.032622498273849485\n",
    "[[28763   549]\n",
    " [  742   632]]\n",
    "Specificity = 0.9813\n",
    "FPR = 0.0187\n",
    "Recall/TPR = 0.46\n",
    "Precision = 0.5351\n",
    "  \n",
    "\n",
    "16. 2 GCN layers (512, 1024); 1-layer FNN (256); 50 epochs; ExponentialDecay(0.001, 0.8, 1024) learning rate: \n",
    "Training set score: {'mean-matthews_corrcoef': 0.8927756751796663, 'mean-accuracy_score': 0.9908632460528245, 'mean-roc_auc_score': 0.9976606794241611}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.48610187283927797, 'mean-accuracy_score': 0.959167046861761, 'mean-roc_auc_score': 0.894108869322588}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.4625984316111824, 'mean-accuracy_score': 0.9567569329031838, 'mean-roc_auc_score': 0.8956954195273609}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.4976525550546536, 'mean-accuracy_score': 0.9589389298051229, 'mean-roc_auc_score': 0.9024744400254572}  \n",
    "Loss? = 0.03420705506295869  \n",
    "[[28748   564]  \n",
    " [  696   678]]  \n",
    "Specificity = 0.9808  \n",
    "FPR = 0.0192  \n",
    "Recall/TPR = 0.4934  \n",
    "Precision = 0.5459  \n",
    "\n",
    "17. 2 GCN layers (512, 1024); 1-layer FNN (256); 50 epochs; ExponentialDecay(0.0001, 0.8, 1024) learning rate:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.8483985164161991, 'mean-accuracy_score': 0.9876044840565069, 'mean-roc_auc_score': 0.995549869080302}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.49007610781698174, 'mean-accuracy_score': 0.961545981880988, 'mean-roc_auc_score': 0.8972737293458364}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.47299340720365723, 'mean-accuracy_score': 0.9608629061165966, 'mean-roc_auc_score': 0.8971972421236217}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.5054448195412395, 'mean-accuracy_score': 0.9630450368246106, 'mean-roc_auc_score': 0.9066868066116365}  \n",
    "Loss? = 0.042947678565979  \n",
    "[[28948   364]  \n",
    " [  770   604]]  \n",
    "Specificity = 0.9876  \n",
    "FPR = 0.0124  \n",
    "Recall/TPR = 0.4396  \n",
    "Precision = 0.624  \n",
    "  \n",
    "18. 3 GCN layers (64, 256, 1024); 1-layer FNN (256); 50 epochs; ExponentialDecay(0.0001, 0.8, 1024) learning rate:  \n",
    "Training set score: {'mean-matthews_corrcoef': 0.9336822419012412, 'mean-accuracy_score': 0.9943908559138384, 'mean-roc_auc_score': 0.9991360995012725}  \n",
    "Validation set score: {'mean-matthews_corrcoef': 0.47689518696611505, 'mean-accuracy_score': 0.9596232809750375, 'mean-roc_auc_score': 0.8967864878307685}  \n",
    "Test set score: {'mean-matthews_corrcoef': 0.4639100959675954, 'mean-accuracy_score': 0.959559422556783, 'mean-roc_auc_score': 0.895078024261657}  \n",
    "Best validation set score: {'mean-matthews_corrcoef': 0.5000765849173642, 'mean-accuracy_score': 0.9637945642964219, 'mean-roc_auc_score': 0.9049660484024109}  \n",
    "Loss? = 0.026622450351715087  \n",
    "[[29011   301]  \n",
    " [  810   564]]  \n",
    "Specificity = 0.9897  \n",
    "FPR = 0.0103  \n",
    "Recall/TPR = 0.4105  \n",
    "Precision = 0.652  \n",
    "\n",
    "19. 3 GCN layers (1024, 2048); 1-layer FNN (256); 50 epochs; ExponentialDecay(0.001, 0.7, 1024) learning rate:  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fedf83-74f0-4afe-b9d7-f8b62c35bb9a",
   "metadata": {},
   "source": [
    "#### model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8f8ea07-75a5-4531-acc2-4ab40d8724eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.2,\n",
    "                        graph_conv_layers=[128, 128],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_3')\n",
    "model3.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e4757ad-bbf2-48e8-9a07-a907fba281db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.45850212856054634, 'mean-accuracy_score': 0.964960161634595}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.3731441911144923, 'mean-accuracy_score': 0.9615133937300397}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.37520900721711353, 'mean-accuracy_score': 0.9615472349854988}\n"
     ]
    }
   ],
   "source": [
    "print('Training set score:', model3.evaluate(train_dataset, metrics, transformers))\n",
    "print('Validation set score:', model3.evaluate(valid_dataset, metrics, transformers))\n",
    "print('Test set score:', model3.evaluate(test_dataset, metrics, transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd796b9-6362-4aa0-8e16-ea0b6706155f",
   "metadata": {},
   "source": [
    "#### model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48c5d96d-58a3-449c-b27d-ea5abd2ec699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_14:0\", shape=(530,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_13:0\", shape=(530, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_17:0\", shape=(3292,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_16:0\", shape=(3292, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_20:0\", shape=(2874,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_19:0\", shape=(2874, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_23:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_22:0\", shape=(152, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_11:0\", shape=(530,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_10:0\", shape=(530, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_13:0\", shape=(3292,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_12:0\", shape=(3292, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_15:0\", shape=(2874,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_14:0\", shape=(2874, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_17:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_16:0\", shape=(152, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_14:0\", shape=(530,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_13:0\", shape=(530, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_17:0\", shape=(3292,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_16:0\", shape=(3292, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_20:0\", shape=(2874,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_19:0\", shape=(2874, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_23:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_22:0\", shape=(152, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_14:0\", shape=(516,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_13:0\", shape=(516, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_17:0\", shape=(3414,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_16:0\", shape=(3414, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_20:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_19:0\", shape=(2892, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_23:0\", shape=(148,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_22:0\", shape=(148, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_11:0\", shape=(516,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_10:0\", shape=(516, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_13:0\", shape=(3414,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_12:0\", shape=(3414, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_15:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_14:0\", shape=(2892, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_17:0\", shape=(148,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_16:0\", shape=(148, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_14:0\", shape=(516,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_13:0\", shape=(516, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_17:0\", shape=(3414,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_16:0\", shape=(3414, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_20:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_19:0\", shape=(2892, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_23:0\", shape=(148,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_22:0\", shape=(148, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_10:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_12:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_14:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_19/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_18/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0835663604736328"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.2,\n",
    "                        graph_conv_layers=[128, 256],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_4')\n",
    "model4.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b330b75-d714-416a-a1b6-0e1d4a26f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.4142104435615528, 'mean-accuracy_score': 0.9632004301565835}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.3484192642848399, 'mean-accuracy_score': 0.9608616307110734}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.330927336552633, 'mean-accuracy_score': 0.9602111643366898}\n"
     ]
    }
   ],
   "source": [
    "print('Training set score:', model4.evaluate(train_dataset, metrics, transformers))\n",
    "print('Validation set score:', model4.evaluate(valid_dataset, metrics, transformers))\n",
    "print('Test set score:', model4.evaluate(test_dataset, metrics, transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf77f11-ca93-4964-bd61-627046d7cd31",
   "metadata": {},
   "source": [
    "#### model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c2d2fd1-e205-4df7-876e-1eefa581aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 03:59:44.159427: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-13 03:59:44.161648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 03:59:44.162371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 03:59:44.162951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 03:59:51.688246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 03:59:51.688914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 03:59:51.689472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 03:59:51.690133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13001 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_13:0\", shape=(527, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_17:0\", shape=(3430,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_16:0\", shape=(3430, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_20:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_19:0\", shape=(2877, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_23:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_22:0\", shape=(180, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_10:0\", shape=(527, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_13:0\", shape=(3430,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_12:0\", shape=(3430, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_15:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_14:0\", shape=(2877, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_17:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_16:0\", shape=(180, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(527, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(3430,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(3430, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(2877, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(180, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(527, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(3430,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(3430, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(2877, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(180, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(527, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(3430,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(3430, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(2877, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(180, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_14:0\", shape=(511,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_13:0\", shape=(511, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_17:0\", shape=(3458,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_16:0\", shape=(3458, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_20:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_19:0\", shape=(2847, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_23:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_22:0\", shape=(124, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_11:0\", shape=(511,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_10:0\", shape=(511, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_13:0\", shape=(3458,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_12:0\", shape=(3458, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_15:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_14:0\", shape=(2847, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_17:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_16:0\", shape=(124, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(511,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(511, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(3458,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(3458, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(2847, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(124, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(511,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(511, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(3458,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(3458, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(2847, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(124, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(511,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(511, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(3458,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(3458, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(2847, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(124, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_10:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_12:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_14:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model5 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.2,\n",
    "                        graph_conv_layers=[64, 128, 256],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_5')\n",
    "hist5 = model5.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9be9d85-5c5d-4b6e-8a54-244bc8c01ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.5025293293380898, 'mean-accuracy_score': 0.9669235657373764}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.37836007619427664, 'mean-accuracy_score': 0.9616763344847813}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.40029470609974166, 'mean-accuracy_score': 0.9624270863883729}\n"
     ]
    }
   ],
   "source": [
    "print('Training set score:', model5.evaluate(train_dataset, metrics))\n",
    "print('Validation set score:', model5.evaluate(valid_dataset, metrics))\n",
    "print('Test set score:', model5.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca9e6418-6f5b-49b0-8d63-fef8c3afb2c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'ConvMol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_saliency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/keras_model.py:956\u001b[0m, in \u001b[0;36mKerasModel.compute_saliency\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    954\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X, [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_inputs([X])\n\u001b[0;32m--> 956\u001b[0m X_b, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# Use a GradientTape to compute gradients.\u001b[39;00m\n\u001b[1;32m    960\u001b[0m X_c \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(X_b[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/keras_model.py:983\u001b[0m, in \u001b[0;36mKerasModel._prepare_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    981\u001b[0m                    batch: Tuple[Any, Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List, List, List]:\n\u001b[1;32m    982\u001b[0m   inputs, labels, weights \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 983\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    984\u001b[0m       x \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m t \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mastype(t)\n\u001b[1;32m    985\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dtypes)\n\u001b[1;32m    986\u001b[0m   ]\n\u001b[1;32m    987\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    989\u001b[0m         x \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m t \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mastype(t)\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_dtypes)\n\u001b[1;32m    991\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/keras_model.py:984\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    981\u001b[0m                    batch: Tuple[Any, Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List, List, List]:\n\u001b[1;32m    982\u001b[0m   inputs, labels, weights \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    983\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 984\u001b[0m       x \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m t \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dtypes)\n\u001b[1;32m    986\u001b[0m   ]\n\u001b[1;32m    987\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    989\u001b[0m         x \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m t \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mastype(t)\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_dtypes)\n\u001b[1;32m    991\u001b[0m     ]\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'ConvMol'"
     ]
    }
   ],
   "source": [
    "model5.compute_saliency(dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8eab12bd-761d-488f-8c24-f39eedcefa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hist5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e0febda-63a4-4fc1-9e44-19201e6aace8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhist5\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist5' is not defined"
     ]
    }
   ],
   "source": [
    "hist5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f5f52-4198-4352-90c5-dd727fff5d6f",
   "metadata": {},
   "source": [
    "#### model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48221740-15dc-469a-a563-0052bf4b0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir6=f'{get_home_path()}/models/gcn_model_6/callbacks'\n",
    "\n",
    "\n",
    "model6 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.0,\n",
    "                        graph_conv_layers=[128, 128],\n",
    "                        dense_layer_size=256,\n",
    "                        learning_rate=0.0002,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_6')\n",
    "validation6=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir6,\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "62b7ae7f-d341-47a1-aaa5-c3b38e8074bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gcn_model_6/ckpt-574', '../models/gcn_model_6/ckpt-575', '../models/gcn_model_6/ckpt-576', '../models/gcn_model_6/ckpt-1', '../models/gcn_model_6/ckpt-3']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.get_checkpoints(f'{get_home_path()}/models/gcn_model_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c5a4e6d5-d9ea-4a9a-8da5-26e725a9cd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "54db2e0c-5a21-42b0-9591-2476feb5e666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_14:0\", shape=(533,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_13:0\", shape=(533, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_17:0\", shape=(3410,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_16:0\", shape=(3410, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_20:0\", shape=(2907,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_19:0\", shape=(2907, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_23:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_22:0\", shape=(156, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_11:0\", shape=(533,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_10:0\", shape=(533, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_13:0\", shape=(3410,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_12:0\", shape=(3410, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_15:0\", shape=(2907,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_14:0\", shape=(2907, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_17:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_16:0\", shape=(156, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_14:0\", shape=(533,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_13:0\", shape=(533, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_17:0\", shape=(3410,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_16:0\", shape=(3410, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_20:0\", shape=(2907,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_19:0\", shape=(2907, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_23:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_22:0\", shape=(156, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_14:0\", shape=(568,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_13:0\", shape=(568, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_17:0\", shape=(3248,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_16:0\", shape=(3248, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_20:0\", shape=(2964,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_19:0\", shape=(2964, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_23:0\", shape=(132,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_22:0\", shape=(132, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_11:0\", shape=(568,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_10:0\", shape=(568, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_13:0\", shape=(3248,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_12:0\", shape=(3248, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_15:0\", shape=(2964,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_14:0\", shape=(2964, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_17:0\", shape=(132,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_16:0\", shape=(132, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_14:0\", shape=(568,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_13:0\", shape=(568, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_17:0\", shape=(3248,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_16:0\", shape=(3248, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_20:0\", shape=(2964,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_19:0\", shape=(2964, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_23:0\", shape=(132,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_22:0\", shape=(132, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_10:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_12:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_14:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_conv_22/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_21/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.779697 mean-accuracy_score=0.981914 mean-roc_auc_score=0.970716\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.775986 mean-accuracy_score=0.980936 mean-roc_auc_score=0.968649\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.772157 mean-accuracy_score=0.98061 mean-roc_auc_score=0.969619\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.742707 mean-accuracy_score=0.980154 mean-roc_auc_score=0.969643\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.770653 mean-accuracy_score=0.981262 mean-roc_auc_score=0.968705\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.756702 mean-accuracy_score=0.980936 mean-roc_auc_score=0.969177\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.77265 mean-accuracy_score=0.980871 mean-roc_auc_score=0.969956\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.772477 mean-accuracy_score=0.981034 mean-roc_auc_score=0.970174\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.747273 mean-accuracy_score=0.976569 mean-roc_auc_score=0.968656\n"
     ]
    }
   ],
   "source": [
    "hist6 = model6.fit(train_dataset, nb_epoch=5, callbacks=validation6, restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98c864da-98ef-4cb0-9668-fd2ce57f94e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02809069686465793"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05e534cb-7fbd-41c0-ac2f-89f8d833e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.980639353687451, 'mean-accuracy_score': 0.9983543251918596}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.4669227968724198, 'mean-accuracy_score': 0.9597536335788307}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.43511600018388047, 'mean-accuracy_score': 0.9573109134161045}\n"
     ]
    }
   ],
   "source": [
    "print('Training set score:', model6.evaluate(train_dataset, metrics))\n",
    "print('Validation set score:', model6.evaluate(valid_dataset, metrics))\n",
    "print('Test set score:', model6.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31f4d3dc-5269-47a9-a9f5-a6c83cc39108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01113940954208374"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35246b-d6af-45e2-82fe-8108075f204d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "433d82fb-60de-436f-89ea-41797bf7aa8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c70d6de5-c56d-4769-809e-c43a1f4d5a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_14:0\", shape=(524,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_13:0\", shape=(524, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_17:0\", shape=(3358,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_16:0\", shape=(3358, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_20:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_19:0\", shape=(2898, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_23:0\", shape=(140,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_22:0\", shape=(140, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_11:0\", shape=(524,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_10:0\", shape=(524, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_13:0\", shape=(3358,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_12:0\", shape=(3358, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_15:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_14:0\", shape=(2898, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_17:0\", shape=(140,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_16:0\", shape=(140, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_14:0\", shape=(524,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_13:0\", shape=(524, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_17:0\", shape=(3358,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_16:0\", shape=(3358, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_20:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_19:0\", shape=(2898, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_23:0\", shape=(140,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_22:0\", shape=(140, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_14:0\", shape=(547,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_13:0\", shape=(547, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_17:0\", shape=(3198,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_16:0\", shape=(3198, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_20:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_19:0\", shape=(2877, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_23:0\", shape=(160,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_22:0\", shape=(160, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_11:0\", shape=(547,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_10:0\", shape=(547, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_13:0\", shape=(3198,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_12:0\", shape=(3198, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_15:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_14:0\", shape=(2877, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_17:0\", shape=(160,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_16:0\", shape=(160, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_14:0\", shape=(547,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_13:0\", shape=(547, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_17:0\", shape=(3198,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_16:0\", shape=(3198, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_20:0\", shape=(2877,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_19:0\", shape=(2877, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_23:0\", shape=(160,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_22:0\", shape=(160, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_conv_6/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_2/graph_pool_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.0847167 mean-accuracy_score=0.955517\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.246311 mean-accuracy_score=0.954865\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.102047 mean-accuracy_score=0.955713\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.214306 mean-accuracy_score=0.957147\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.23503 mean-accuracy_score=0.956853\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.248537 mean-accuracy_score=0.957277\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.295433 mean-accuracy_score=0.956397\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.226613 mean-accuracy_score=0.957147\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.2582 mean-accuracy_score=0.958222\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.338989 mean-accuracy_score=0.958092\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.27402 mean-accuracy_score=0.958352\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.362152 mean-accuracy_score=0.959265\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.356271 mean-accuracy_score=0.960177\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.358925 mean-accuracy_score=0.960177\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.362682 mean-accuracy_score=0.959754\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.398486 mean-accuracy_score=0.959493\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.399991 mean-accuracy_score=0.96034\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.388949 mean-accuracy_score=0.960862\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.42677 mean-accuracy_score=0.958776\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.463776 mean-accuracy_score=0.961416\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.424993 mean-accuracy_score=0.959102\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.395013 mean-accuracy_score=0.961709\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.430222 mean-accuracy_score=0.961383\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.386742 mean-accuracy_score=0.961579\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.445055 mean-accuracy_score=0.962784\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.444944 mean-accuracy_score=0.961611\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.442217 mean-accuracy_score=0.96135\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.430155 mean-accuracy_score=0.962915\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.410645 mean-accuracy_score=0.961807\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.41869 mean-accuracy_score=0.962035\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.458683 mean-accuracy_score=0.963599\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.431034 mean-accuracy_score=0.963012\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.457313 mean-accuracy_score=0.962328\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.459334 mean-accuracy_score=0.962393\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.4675 mean-accuracy_score=0.959558\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.458112 mean-accuracy_score=0.959819\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.480138 mean-accuracy_score=0.962328\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.459002 mean-accuracy_score=0.961774\n"
     ]
    }
   ],
   "source": [
    "save_dir=f'{get_home_path()}/models/gcn_model_7/callbacks'\n",
    "\n",
    "model7 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.0,\n",
    "                        graph_conv_layers=[512, 1024],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_7')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir,\n",
    "                                        save_on_minimum=False)\n",
    "hist7 = model7.fit(train_dataset, nb_epoch=20, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9c7da6-0578-479f-813c-b956378bd248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.6449390262476722, 'mean-accuracy_score': 0.9708625943004253}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.4749802086322286, 'mean-accuracy_score': 0.9571791696539138}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.49445900413598426, 'mean-accuracy_score': 0.9600156418027178}\n"
     ]
    }
   ],
   "source": [
    "print('Training set score:', model7.evaluate(train_dataset, metrics))\n",
    "print('Validation set score:', model7.evaluate(valid_dataset, metrics))\n",
    "print('Test set score:', model7.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "735c895d-1298-453b-8d1b-059a79e78286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation set score: {'mean-matthews_corrcoef': 0.48013768550166536, 'mean-accuracy_score': 0.9623280975037476}\n"
     ]
    }
   ],
   "source": [
    "model7.restore(model_dir=save_dir)\n",
    "print('Best validation set score:', model7.evaluate(valid_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fedb9a4d-83af-4b01-96bc-a746aab81069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08594311078389485"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28f08b-c39b-44cc-a3ba-d78c528075c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74962e6e-8284-43c8-8f43-fb1c3e783c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_14:0\", shape=(540,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_13:0\", shape=(540, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_17:0\", shape=(3370,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_16:0\", shape=(3370, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_20:0\", shape=(2994,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_19:0\", shape=(2994, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_23:0\", shape=(120,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_22:0\", shape=(120, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_11:0\", shape=(540,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_10:0\", shape=(540, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_13:0\", shape=(3370,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_12:0\", shape=(3370, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_15:0\", shape=(2994,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_14:0\", shape=(2994, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_17:0\", shape=(120,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_16:0\", shape=(120, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_18:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_20:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_22:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_24:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_26:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_28:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(540,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(540, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(3370,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(3370, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(2994,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(2994, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(120,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(120, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_14:0\", shape=(493,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_13:0\", shape=(493, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_17:0\", shape=(3278,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_16:0\", shape=(3278, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_20:0\", shape=(2727,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_19:0\", shape=(2727, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_23:0\", shape=(176,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_22:0\", shape=(176, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_11:0\", shape=(493,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_10:0\", shape=(493, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_13:0\", shape=(3278,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_12:0\", shape=(3278, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_15:0\", shape=(2727,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_14:0\", shape=(2727, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_17:0\", shape=(176,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_16:0\", shape=(176, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(493,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(493, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(3278,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(3278, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(2727,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(2727, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(176,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(176, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_13:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_16:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_19:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Reshape_22:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_8/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_10:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_12:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_14:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_8/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.0297338 mean-accuracy_score=0.955256\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.244214 mean-accuracy_score=0.955419\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.218712 mean-accuracy_score=0.955224\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.177553 mean-accuracy_score=0.956299\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.291364 mean-accuracy_score=0.956234\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.179451 mean-accuracy_score=0.95656\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.287288 mean-accuracy_score=0.957277\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.328919 mean-accuracy_score=0.957342\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.369203 mean-accuracy_score=0.954018\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.251715 mean-accuracy_score=0.957994\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.371504 mean-accuracy_score=0.954148\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.31216 mean-accuracy_score=0.95933\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.33943 mean-accuracy_score=0.960177\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.377061 mean-accuracy_score=0.958548\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.360136 mean-accuracy_score=0.960373\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.399664 mean-accuracy_score=0.959754\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.386027 mean-accuracy_score=0.961057\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.391404 mean-accuracy_score=0.961416\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.354384 mean-accuracy_score=0.960796\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.358676 mean-accuracy_score=0.960373\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.409648 mean-accuracy_score=0.961481\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.439915 mean-accuracy_score=0.959917\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.418246 mean-accuracy_score=0.961774\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.400785 mean-accuracy_score=0.962328\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.440798 mean-accuracy_score=0.961383\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.430607 mean-accuracy_score=0.962654\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.444309 mean-accuracy_score=0.96285\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.450054 mean-accuracy_score=0.963273\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.457314 mean-accuracy_score=0.963175\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.430199 mean-accuracy_score=0.962556\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.451598 mean-accuracy_score=0.96223\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.439798 mean-accuracy_score=0.962882\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.447748 mean-accuracy_score=0.96197\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.460617 mean-accuracy_score=0.960568\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.479496 mean-accuracy_score=0.953757\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.459615 mean-accuracy_score=0.962719\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.464109 mean-accuracy_score=0.963436\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.444143 mean-accuracy_score=0.963599\n"
     ]
    }
   ],
   "source": [
    "save_dir8=f'{get_home_path()}/models/gcn_model_8/callbacks'\n",
    "\n",
    "model8 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.0,\n",
    "                        graph_conv_layers=[1024, 2048],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_8')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir8,\n",
    "                                        save_on_minimum=False)\n",
    "hist8 = model8.fit(train_dataset, nb_epoch=20, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2082f555-9206-4518-acd6-0322df8204cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.5892717340747637, 'mean-accuracy_score': 0.9709155491828654}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.44678468227552504, 'mean-accuracy_score': 0.9629472723717656}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.4300309731397157, 'mean-accuracy_score': 0.9623293251213869}\n"
     ]
    }
   ],
   "source": [
    "print('Training set score:', model8.evaluate(train_dataset, metrics))\n",
    "print('Validation set score:', model8.evaluate(valid_dataset, metrics))\n",
    "print('Test set score:', model8.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbb35d9a-040b-4895-8b66-eaa79e885043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation set score: {'mean-matthews_corrcoef': 0.4794959701248735, 'mean-accuracy_score': 0.9537574138043408}\n"
     ]
    }
   ],
   "source": [
    "model8.restore(model_dir=save_dir8)\n",
    "print('Best validation set score:', model8.evaluate(valid_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "242fcb5b-8b43-43ef-8813-97449a87ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss? = 0.08380654652913412\n"
     ]
    }
   ],
   "source": [
    "print(f'Loss? = {hist8}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cf71b05-e7d4-4f16-b9ba-dd5d24d52da1",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred8 = [x.flatten() for x in model8.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5785fe6a-0c48-4a26-b65b-1c8e5223af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = cust_confusion_matrix(valid_dataset.y, [round(x[1]) for x in pred8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0aa1212-90a3-4acb-8c64-1ccc92aad926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28548,   764],\n",
       "       [  655,   719]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_confusion_matrix(valid_dataset.y, [round(x[1]) for x in pred8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bbae517a-e184-427b-a688-c18043f2cd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28548,   764],\n",
       "       [  655,   719]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(valid_dataset.y, [round(x[1]) for x in pred8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "86cacdfe-c607-4f18-a53a-81ae2a2b5f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28548   764]\n",
      " [  655   719]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "41e29f35-bec1-4121-a054-db4cf715204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "22c41384-2b84-439b-aa35-744fff9d6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity\n",
    "print(f'Specificity = {round(tn/(tn+fp), 4)}')\n",
    "\n",
    "# specificity\n",
    "print(f'FPR = {round(fp/(tn+fp), 4)}')\n",
    "\n",
    "# sensitivity\n",
    "print(f'Recall/TPR = {round(tp/(tp+fn), 4)}')\n",
    "\n",
    "print(f'Precision = {round(tp/(tp+fp), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5ab3b-d82d-4575-978e-933d02c944f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15860561-642c-45b1-80b3-1180da45e967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "393356ed-f4b1-4066-946a-79425af5fdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.6300517131506186, 'mean-accuracy_score': 0.9669765206198165}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.4794959701248735, 'mean-accuracy_score': 0.9537574138043408}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.4825840518268879, 'mean-accuracy_score': 0.9545410108515007}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.4794959701248735, 'mean-accuracy_score': 0.9537574138043408}\n",
      "Loss? = 0.08380654652913412\n",
      "[[28548   764]\n",
      " [  655   719]]\n",
      "Specificity = 0.9739\n",
      "FPR = 0.0261\n",
      "Recall/TPR = 0.5233\n",
      "Precision = 0.4848\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model8, hist8, save_dir8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c8f26-a830-4077-bd36-39e7d1ff3001",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "889f02d5-42bc-47c5-9660-f0d6c2c33cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_14:0\", shape=(561,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_13:0\", shape=(561, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_17:0\", shape=(3378,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_16:0\", shape=(3378, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_20:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_19:0\", shape=(2847, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_23:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_22:0\", shape=(208, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_11:0\", shape=(561,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_10:0\", shape=(561, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_13:0\", shape=(3378,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_12:0\", shape=(3378, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_15:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_14:0\", shape=(2847, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_17:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_16:0\", shape=(208, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_14:0\", shape=(561,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_13:0\", shape=(561, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_17:0\", shape=(3378,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_16:0\", shape=(3378, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_20:0\", shape=(2847,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_19:0\", shape=(2847, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_23:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_22:0\", shape=(208, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_14:0\", shape=(536,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_13:0\", shape=(536, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_17:0\", shape=(3434,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_16:0\", shape=(3434, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_20:0\", shape=(2814,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_19:0\", shape=(2814, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_23:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_22:0\", shape=(156, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_11:0\", shape=(536,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_10:0\", shape=(536, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_13:0\", shape=(3434,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_12:0\", shape=(3434, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_15:0\", shape=(2814,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_14:0\", shape=(2814, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_17:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_16:0\", shape=(156, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_14:0\", shape=(536,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_13:0\", shape=(536, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_17:0\", shape=(3434,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_16:0\", shape=(3434, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_20:0\", shape=(2814,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_19:0\", shape=(2814, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_23:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_22:0\", shape=(156, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.158129 mean-accuracy_score=0.955615\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.16331 mean-accuracy_score=0.955485\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.138452 mean-accuracy_score=0.954833\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.253093 mean-accuracy_score=0.956918\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.3099 mean-accuracy_score=0.955941\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.321122 mean-accuracy_score=0.95731\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.274737 mean-accuracy_score=0.957701\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.320692 mean-accuracy_score=0.955876\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.308999 mean-accuracy_score=0.959069\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.324574 mean-accuracy_score=0.958939\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.367091 mean-accuracy_score=0.959591\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.282185 mean-accuracy_score=0.95858\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.348334 mean-accuracy_score=0.960014\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.337338 mean-accuracy_score=0.959656\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.371539 mean-accuracy_score=0.960112\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.391907 mean-accuracy_score=0.960177\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.39828 mean-accuracy_score=0.960731\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.36592 mean-accuracy_score=0.960862\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.430437 mean-accuracy_score=0.960731\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.410075 mean-accuracy_score=0.961513\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.437903 mean-accuracy_score=0.958776\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.428456 mean-accuracy_score=0.961383\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.453537 mean-accuracy_score=0.951639\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.442935 mean-accuracy_score=0.961872\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.430994 mean-accuracy_score=0.960959\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.446756 mean-accuracy_score=0.962556\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.434746 mean-accuracy_score=0.960796\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.385238 mean-accuracy_score=0.961644\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.452437 mean-accuracy_score=0.962426\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.452186 mean-accuracy_score=0.961676\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.421286 mean-accuracy_score=0.961253\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.475146 mean-accuracy_score=0.961383\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.451317 mean-accuracy_score=0.962752\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.469101 mean-accuracy_score=0.958548\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.444461 mean-accuracy_score=0.961155\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.438508 mean-accuracy_score=0.962784\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.47599 mean-accuracy_score=0.9621\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.451747 mean-accuracy_score=0.961285\n"
     ]
    }
   ],
   "source": [
    "save_dir9=f'{get_home_path()}/models/gcn_model_9/callbacks'\n",
    "\n",
    "model9 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.0,\n",
    "                        graph_conv_layers=[256, 512],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_9')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir9,\n",
    "                                        save_on_minimum=False)\n",
    "hist9 = model9.fit(train_dataset, nb_epoch=20, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c466d162-f2da-42fc-bf55-db14c40a8f5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model9' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_model(\u001b[43mmodel9\u001b[49m, hist9, save_dir9)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model9' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(model9, hist9, save_dir9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a0892b8f-08f8-4722-9904-c1dab97a0666",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred9 = [x.flatten() for x in model9.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3bf3f17c-94aa-43d4-8af8-c7b2d009001e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values  pred_probs\n",
       "0          1.0    0.018548\n",
       "1          0.0    0.013990\n",
       "2          0.0    0.007407\n",
       "3          0.0    0.000030\n",
       "4          0.0    0.000020"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred9_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred9])})\n",
    "\n",
    "pred9_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "42182a54-20ac-4b7e-98b2-844a1bc19fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred9_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that Outcome = 1')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1800);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d44756-1d03-42a8-ad3c-ebb227e62152",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.metrics.roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a192122d-d023-4c30-a146-6475d8432239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: {'mean-roc_auc_score': 0.9008084814746785}\n"
     ]
    }
   ],
   "source": [
    "print('Test set score:', model9.evaluate(test_dataset, dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode='classification')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4154f009-37ea-4d43-8e0a-8e24e3e90985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057449557399426"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from sklearn import metrics\n",
    "\n",
    "\n",
    "# y = np.array([1, 1, 2, 2])\n",
    "# pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "fpr, tpr, thresholds = roc_curve(valid_dataset.y.flatten(), np.array([x[1] for x in pred9]))\n",
    "auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02f8cc-5f5b-4e73-8f1a-246620142ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd34e1b-29ad-4e43-b0d7-4e4a2b241e21",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "425e5299-1a36-46b4-847d-459cd3772a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(552,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(552, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(3260,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(3260, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(2886,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(2886, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(196,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(196, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(552,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(552, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(3260,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(3260, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(2886,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(2886, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(196,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(196, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_18:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_20:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_22:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_24:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_26:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_28:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(552,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(552, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(3260,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(3260, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(2886,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(2886, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(196,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(196, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(504,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(504, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(3334,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(3334, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(2880,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(2880, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(156, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(504,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(504, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(3334,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(3334, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(2880,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(2880, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(156, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(504,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(504, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(3334,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(3334, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(2880,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(2880, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(156, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.0749301 mean-accuracy_score=0.955354 mean-roc_auc_score=0.823519\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.0841959 mean-accuracy_score=0.955191 mean-roc_auc_score=0.825633\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.222645 mean-accuracy_score=0.956853 mean-roc_auc_score=0.855938\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.0870839 mean-accuracy_score=0.95555 mean-roc_auc_score=0.854983\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.313674 mean-accuracy_score=0.952519 mean-roc_auc_score=0.853513\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.2556 mean-accuracy_score=0.957831 mean-roc_auc_score=0.872088\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.276459 mean-accuracy_score=0.957831 mean-roc_auc_score=0.863173\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.223942 mean-accuracy_score=0.957505 mean-roc_auc_score=0.876804\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.311143 mean-accuracy_score=0.958092 mean-roc_auc_score=0.871792\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.395391 mean-accuracy_score=0.954246 mean-roc_auc_score=0.884378\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.286563 mean-accuracy_score=0.958646 mean-roc_auc_score=0.884713\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.283659 mean-accuracy_score=0.958255 mean-roc_auc_score=0.885295\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.37755 mean-accuracy_score=0.959363 mean-roc_auc_score=0.891876\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.400273 mean-accuracy_score=0.955289 mean-roc_auc_score=0.890353\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.40853 mean-accuracy_score=0.958092 mean-roc_auc_score=0.893224\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.367561 mean-accuracy_score=0.96008 mean-roc_auc_score=0.888925\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.313101 mean-accuracy_score=0.959493 mean-roc_auc_score=0.891938\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.407651 mean-accuracy_score=0.962002 mean-roc_auc_score=0.900713\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.341868 mean-accuracy_score=0.959688 mean-roc_auc_score=0.899033\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.41207 mean-accuracy_score=0.962067 mean-roc_auc_score=0.90179\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.422374 mean-accuracy_score=0.959069 mean-roc_auc_score=0.900754\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.43846 mean-accuracy_score=0.96109 mean-roc_auc_score=0.90494\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.396049 mean-accuracy_score=0.962165 mean-roc_auc_score=0.901495\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.417766 mean-accuracy_score=0.962133 mean-roc_auc_score=0.901677\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.367792 mean-accuracy_score=0.960796 mean-roc_auc_score=0.899394\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.409908 mean-accuracy_score=0.962361 mean-roc_auc_score=0.906701\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.443276 mean-accuracy_score=0.963371 mean-roc_auc_score=0.905722\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.419273 mean-accuracy_score=0.962263 mean-roc_auc_score=0.901943\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.446807 mean-accuracy_score=0.961318 mean-roc_auc_score=0.910308\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.446304 mean-accuracy_score=0.962263 mean-roc_auc_score=0.906995\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.46325 mean-accuracy_score=0.961285 mean-roc_auc_score=0.908591\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.427257 mean-accuracy_score=0.962589 mean-roc_auc_score=0.909199\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.451153 mean-accuracy_score=0.961676 mean-roc_auc_score=0.907394\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.466069 mean-accuracy_score=0.961513 mean-roc_auc_score=0.905434\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.43875 mean-accuracy_score=0.962296 mean-roc_auc_score=0.900357\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.412296 mean-accuracy_score=0.962491 mean-roc_auc_score=0.909748\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.434458 mean-accuracy_score=0.961383 mean-roc_auc_score=0.904051\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.479678 mean-accuracy_score=0.960373 mean-roc_auc_score=0.91188\n"
     ]
    }
   ],
   "source": [
    "save_dir10=f'{get_home_path()}/models/gcn_model_10/callbacks'\n",
    "\n",
    "model10 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.0,\n",
    "                        graph_conv_layers=[1024, 512],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_10')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir10,\n",
    "                                        save_on_minimum=False)\n",
    "hist10 = model10.fit(train_dataset, nb_epoch=20, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8b5f7063-47f0-4e9e-a479-3f66d1ba9cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.6335385781975322, 'mean-accuracy_score': 0.9702923109510697, 'mean-roc_auc_score': 0.961515084775735}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.4787927575103589, 'mean-accuracy_score': 0.9584501075408981, 'mean-roc_auc_score': 0.9025637020453146}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.45549041923086453, 'mean-accuracy_score': 0.9574412617720859, 'mean-roc_auc_score': 0.8991438760820261}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.47967790456375287, 'mean-accuracy_score': 0.9603728084468487, 'mean-roc_auc_score': 0.9118796090983995}\n",
      "Loss? = 0.09841734568277995\n",
      "[[28875   437]\n",
      " [  779   595]]\n",
      "Specificity = 0.9851\n",
      "FPR = 0.0149\n",
      "Recall/TPR = 0.433\n",
      "Precision = 0.5766\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model10, hist10, save_dir10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cb46d856-6780-4455-ba99-01407631e0f6",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred10 = [x.flatten() for x in model10.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "84464ced-17d6-4a51-bf23-17294fe587b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values  pred_probs\n",
       "0          1.0    0.014788\n",
       "1          0.0    0.001358\n",
       "2          0.0    0.015869\n",
       "3          0.0    0.001218\n",
       "4          0.0    0.000029"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred10_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred10])})\n",
    "\n",
    "pred10_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b864bcad-cd4e-4dbf-81fa-c53bef1238f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred10_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# plot distributions of predicted probabilities by actual values\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpred10_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      5\u001b[0m     sns\u001b[38;5;241m.\u001b[39mdistplot(group[\u001b[38;5;241m1\u001b[39m], kde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Outcome = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Add cutoff line\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred10_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred10_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that Outcome = 1')\n",
    "plt.legend()\n",
    "plt.ylim(0, 2000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6ed18-18a2-42f8-b11c-47ccca0a5a11",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e75e5d45-4a67-4c93-8206-70fb576c48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir11=f'{get_home_path()}/models/gcn_model_11/callbacks'\n",
    "\n",
    "model11 = GraphConvModel(1, batch_size=128,\n",
    "                        dropout=0.0,\n",
    "                        graph_conv_layers=[512, 1024],\n",
    "                        dense_layer_size=256,\n",
    "                        mode='classification',\n",
    "                        model_dir=f'{get_home_path()}/models/gcn_model_11')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir11,\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8be13b5-8ef9-4f14-9398-1f2d0d2a491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 11:57:57.064529: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-14 11:57:57.067045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 11:57:57.067880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 11:57:57.068484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 11:58:04.757209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 11:58:04.757883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 11:58:04.758454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 11:58:04.759046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13001 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(520,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(520, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(3442,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(3442, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(2886,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(2886, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(192,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(192, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(520,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(520, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(3442,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(3442, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(2886,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(2886, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(192,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(192, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(520,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(520, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(3442,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(3442, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(2886,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(2886, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(192,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(192, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(567,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(567, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(3182, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(2865,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(2865, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(180, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(567,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(567, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(3182, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(2865,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(2865, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(180, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(567,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(567, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(3182, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(2865,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(2865, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(180,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(180, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.12553 mean-accuracy_score=0.95555 mean-roc_auc_score=0.82594\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.259122 mean-accuracy_score=0.956234 mean-roc_auc_score=0.838415\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.322674 mean-accuracy_score=0.954865 mean-roc_auc_score=0.848688\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.210909 mean-accuracy_score=0.956886 mean-roc_auc_score=0.853348\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.282432 mean-accuracy_score=0.957244 mean-roc_auc_score=0.853595\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.227346 mean-accuracy_score=0.956723 mean-roc_auc_score=0.857647\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.341555 mean-accuracy_score=0.957701 mean-roc_auc_score=0.870065\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.30998 mean-accuracy_score=0.957864 mean-roc_auc_score=0.868527\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.313041 mean-accuracy_score=0.959037 mean-roc_auc_score=0.87669\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.324364 mean-accuracy_score=0.958385 mean-roc_auc_score=0.879871\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.320718 mean-accuracy_score=0.958776 mean-roc_auc_score=0.87339\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.38202 mean-accuracy_score=0.95845 mean-roc_auc_score=0.883229\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.284417 mean-accuracy_score=0.958483 mean-roc_auc_score=0.885831\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.383683 mean-accuracy_score=0.960796 mean-roc_auc_score=0.889448\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.370904 mean-accuracy_score=0.959917 mean-roc_auc_score=0.886731\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.360384 mean-accuracy_score=0.960601 mean-roc_auc_score=0.890185\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.42356 mean-accuracy_score=0.960275 mean-roc_auc_score=0.897519\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.365804 mean-accuracy_score=0.960568 mean-roc_auc_score=0.897493\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.439167 mean-accuracy_score=0.957179 mean-roc_auc_score=0.892841\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.385413 mean-accuracy_score=0.960764 mean-roc_auc_score=0.890635\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.407346 mean-accuracy_score=0.960959 mean-roc_auc_score=0.899043\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.459604 mean-accuracy_score=0.96223 mean-roc_auc_score=0.902815\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.396776 mean-accuracy_score=0.961742 mean-roc_auc_score=0.900284\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.433412 mean-accuracy_score=0.961448 mean-roc_auc_score=0.900442\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.452733 mean-accuracy_score=0.962393 mean-roc_auc_score=0.900992\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.403115 mean-accuracy_score=0.961481 mean-roc_auc_score=0.899224\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.456762 mean-accuracy_score=0.96021 mean-roc_auc_score=0.899249\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.446529 mean-accuracy_score=0.96122 mean-roc_auc_score=0.903583\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.468285 mean-accuracy_score=0.962589 mean-roc_auc_score=0.902234\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.455481 mean-accuracy_score=0.963371 mean-roc_auc_score=0.905803\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.465505 mean-accuracy_score=0.960438 mean-roc_auc_score=0.903501\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.457937 mean-accuracy_score=0.96223 mean-roc_auc_score=0.905753\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.434675 mean-accuracy_score=0.961807 mean-roc_auc_score=0.903203\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.448034 mean-accuracy_score=0.961122 mean-roc_auc_score=0.898902\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.458102 mean-accuracy_score=0.963241 mean-roc_auc_score=0.90202\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.433073 mean-accuracy_score=0.9621 mean-roc_auc_score=0.899601\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.445361 mean-accuracy_score=0.960699 mean-roc_auc_score=0.897849\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.450145 mean-accuracy_score=0.962035 mean-roc_auc_score=0.895678\n",
      "Step 39000 validation: mean-matthews_corrcoef=0.486284 mean-accuracy_score=0.963436 mean-roc_auc_score=0.907099\n",
      "Step 40000 validation: mean-matthews_corrcoef=0.483114 mean-accuracy_score=0.961709 mean-roc_auc_score=0.905982\n",
      "Step 41000 validation: mean-matthews_corrcoef=0.471871 mean-accuracy_score=0.962426 mean-roc_auc_score=0.901313\n",
      "Step 42000 validation: mean-matthews_corrcoef=0.409091 mean-accuracy_score=0.962198 mean-roc_auc_score=0.898421\n",
      "Step 43000 validation: mean-matthews_corrcoef=0.468119 mean-accuracy_score=0.96285 mean-roc_auc_score=0.898853\n",
      "Step 44000 validation: mean-matthews_corrcoef=0.475302 mean-accuracy_score=0.963045 mean-roc_auc_score=0.90412\n",
      "Step 45000 validation: mean-matthews_corrcoef=0.485186 mean-accuracy_score=0.962687 mean-roc_auc_score=0.902525\n",
      "Step 46000 validation: mean-matthews_corrcoef=0.436274 mean-accuracy_score=0.962589 mean-roc_auc_score=0.899971\n",
      "Step 47000 validation: mean-matthews_corrcoef=0.482377 mean-accuracy_score=0.959232 mean-roc_auc_score=0.898439\n",
      "Step 48000 validation: mean-matthews_corrcoef=0.496896 mean-accuracy_score=0.962035 mean-roc_auc_score=0.902265\n",
      "Step 49000 validation: mean-matthews_corrcoef=0.507225 mean-accuracy_score=0.9621 mean-roc_auc_score=0.902278\n",
      "Step 50000 validation: mean-matthews_corrcoef=0.486165 mean-accuracy_score=0.963241 mean-roc_auc_score=0.90514\n",
      "Step 51000 validation: mean-matthews_corrcoef=0.430832 mean-accuracy_score=0.96298 mean-roc_auc_score=0.903305\n",
      "Step 52000 validation: mean-matthews_corrcoef=0.493547 mean-accuracy_score=0.96021 mean-roc_auc_score=0.903261\n",
      "Step 53000 validation: mean-matthews_corrcoef=0.488537 mean-accuracy_score=0.962491 mean-roc_auc_score=0.895432\n",
      "Step 54000 validation: mean-matthews_corrcoef=0.486248 mean-accuracy_score=0.960503 mean-roc_auc_score=0.905537\n",
      "Step 55000 validation: mean-matthews_corrcoef=0.490248 mean-accuracy_score=0.963208 mean-roc_auc_score=0.898374\n",
      "Step 56000 validation: mean-matthews_corrcoef=0.447425 mean-accuracy_score=0.960014 mean-roc_auc_score=0.897085\n",
      "Step 57000 validation: mean-matthews_corrcoef=0.487468 mean-accuracy_score=0.961937 mean-roc_auc_score=0.896791\n",
      "Step 58000 validation: mean-matthews_corrcoef=0.475523 mean-accuracy_score=0.962328 mean-roc_auc_score=0.899914\n",
      "Step 59000 validation: mean-matthews_corrcoef=0.44601 mean-accuracy_score=0.963599 mean-roc_auc_score=0.895842\n",
      "Step 60000 validation: mean-matthews_corrcoef=0.468623 mean-accuracy_score=0.962621 mean-roc_auc_score=0.893984\n",
      "Step 61000 validation: mean-matthews_corrcoef=0.494596 mean-accuracy_score=0.961285 mean-roc_auc_score=0.898409\n",
      "Step 62000 validation: mean-matthews_corrcoef=0.46587 mean-accuracy_score=0.961709 mean-roc_auc_score=0.895194\n",
      "Step 63000 validation: mean-matthews_corrcoef=0.464771 mean-accuracy_score=0.961807 mean-roc_auc_score=0.897017\n",
      "Step 64000 validation: mean-matthews_corrcoef=0.478884 mean-accuracy_score=0.95933 mean-roc_auc_score=0.897843\n",
      "Step 65000 validation: mean-matthews_corrcoef=0.458593 mean-accuracy_score=0.96197 mean-roc_auc_score=0.892723\n",
      "Step 66000 validation: mean-matthews_corrcoef=0.474396 mean-accuracy_score=0.961676 mean-roc_auc_score=0.895088\n",
      "Step 67000 validation: mean-matthews_corrcoef=0.471041 mean-accuracy_score=0.960796 mean-roc_auc_score=0.890343\n",
      "Step 68000 validation: mean-matthews_corrcoef=0.491356 mean-accuracy_score=0.959363 mean-roc_auc_score=0.89914\n",
      "Step 69000 validation: mean-matthews_corrcoef=0.480408 mean-accuracy_score=0.962002 mean-roc_auc_score=0.893681\n",
      "Step 70000 validation: mean-matthews_corrcoef=0.485672 mean-accuracy_score=0.96008 mean-roc_auc_score=0.901186\n",
      "Step 71000 validation: mean-matthews_corrcoef=0.461601 mean-accuracy_score=0.961513 mean-roc_auc_score=0.894625\n",
      "Step 72000 validation: mean-matthews_corrcoef=0.473648 mean-accuracy_score=0.961057 mean-roc_auc_score=0.897475\n",
      "Step 73000 validation: mean-matthews_corrcoef=0.466314 mean-accuracy_score=0.962067 mean-roc_auc_score=0.901573\n",
      "Step 74000 validation: mean-matthews_corrcoef=0.495407 mean-accuracy_score=0.960275 mean-roc_auc_score=0.899271\n",
      "Step 75000 validation: mean-matthews_corrcoef=0.476055 mean-accuracy_score=0.958809 mean-roc_auc_score=0.894842\n",
      "Step 76000 validation: mean-matthews_corrcoef=0.489309 mean-accuracy_score=0.961416 mean-roc_auc_score=0.90206\n",
      "Step 77000 validation: mean-matthews_corrcoef=0.466441 mean-accuracy_score=0.96034 mean-roc_auc_score=0.89644\n",
      "Step 78000 validation: mean-matthews_corrcoef=0.477327 mean-accuracy_score=0.96034 mean-roc_auc_score=0.893093\n",
      "Step 79000 validation: mean-matthews_corrcoef=0.465266 mean-accuracy_score=0.960894 mean-roc_auc_score=0.897442\n",
      "Step 80000 validation: mean-matthews_corrcoef=0.447171 mean-accuracy_score=0.959819 mean-roc_auc_score=0.891974\n",
      "Step 81000 validation: mean-matthews_corrcoef=0.471414 mean-accuracy_score=0.960471 mean-roc_auc_score=0.895376\n",
      "Step 82000 validation: mean-matthews_corrcoef=0.476444 mean-accuracy_score=0.96122 mean-roc_auc_score=0.898776\n",
      "Step 83000 validation: mean-matthews_corrcoef=0.486947 mean-accuracy_score=0.960634 mean-roc_auc_score=0.899718\n",
      "Step 84000 validation: mean-matthews_corrcoef=0.490404 mean-accuracy_score=0.959656 mean-roc_auc_score=0.899058\n",
      "Step 85000 validation: mean-matthews_corrcoef=0.463646 mean-accuracy_score=0.95744 mean-roc_auc_score=0.893392\n",
      "Step 86000 validation: mean-matthews_corrcoef=0.462838 mean-accuracy_score=0.96109 mean-roc_auc_score=0.896939\n",
      "Step 87000 validation: mean-matthews_corrcoef=0.461058 mean-accuracy_score=0.960894 mean-roc_auc_score=0.89578\n",
      "Step 88000 validation: mean-matthews_corrcoef=0.47893 mean-accuracy_score=0.962165 mean-roc_auc_score=0.897395\n",
      "Step 89000 validation: mean-matthews_corrcoef=0.481163 mean-accuracy_score=0.959721 mean-roc_auc_score=0.896833\n",
      "Step 90000 validation: mean-matthews_corrcoef=0.479445 mean-accuracy_score=0.956821 mean-roc_auc_score=0.897206\n",
      "Step 91000 validation: mean-matthews_corrcoef=0.475636 mean-accuracy_score=0.95946 mean-roc_auc_score=0.897302\n",
      "Step 92000 validation: mean-matthews_corrcoef=0.443272 mean-accuracy_score=0.96135 mean-roc_auc_score=0.895567\n",
      "Step 93000 validation: mean-matthews_corrcoef=0.462565 mean-accuracy_score=0.959526 mean-roc_auc_score=0.893686\n",
      "Step 94000 validation: mean-matthews_corrcoef=0.471969 mean-accuracy_score=0.962133 mean-roc_auc_score=0.895464\n",
      "Step 95000 validation: mean-matthews_corrcoef=0.484876 mean-accuracy_score=0.957212 mean-roc_auc_score=0.897627\n",
      "Step 96000 validation: mean-matthews_corrcoef=0.439536 mean-accuracy_score=0.960731 mean-roc_auc_score=0.891381\n",
      "Step 97000 validation: mean-matthews_corrcoef=0.464373 mean-accuracy_score=0.955908 mean-roc_auc_score=0.895018\n",
      "Step 98000 validation: mean-matthews_corrcoef=0.460926 mean-accuracy_score=0.959591 mean-roc_auc_score=0.897838\n",
      "Step 99000 validation: mean-matthews_corrcoef=0.484067 mean-accuracy_score=0.95757 mean-roc_auc_score=0.896558\n",
      "Step 100000 validation: mean-matthews_corrcoef=0.460797 mean-accuracy_score=0.961644 mean-roc_auc_score=0.89587\n",
      "Step 101000 validation: mean-matthews_corrcoef=0.476194 mean-accuracy_score=0.958972 mean-roc_auc_score=0.896687\n",
      "Step 102000 validation: mean-matthews_corrcoef=0.467994 mean-accuracy_score=0.959754 mean-roc_auc_score=0.896229\n",
      "Step 103000 validation: mean-matthews_corrcoef=0.47995 mean-accuracy_score=0.956788 mean-roc_auc_score=0.899564\n",
      "Step 104000 validation: mean-matthews_corrcoef=0.490527 mean-accuracy_score=0.960568 mean-roc_auc_score=0.902069\n",
      "Step 105000 validation: mean-matthews_corrcoef=0.462139 mean-accuracy_score=0.959428 mean-roc_auc_score=0.891995\n",
      "Step 106000 validation: mean-matthews_corrcoef=0.477363 mean-accuracy_score=0.958841 mean-roc_auc_score=0.895164\n",
      "Step 107000 validation: mean-matthews_corrcoef=0.475119 mean-accuracy_score=0.95757 mean-roc_auc_score=0.892303\n",
      "Step 108000 validation: mean-matthews_corrcoef=0.47124 mean-accuracy_score=0.961774 mean-roc_auc_score=0.897873\n",
      "Step 109000 validation: mean-matthews_corrcoef=0.444415 mean-accuracy_score=0.960862 mean-roc_auc_score=0.891207\n",
      "Step 110000 validation: mean-matthews_corrcoef=0.460866 mean-accuracy_score=0.960145 mean-roc_auc_score=0.894112\n",
      "Step 111000 validation: mean-matthews_corrcoef=0.460155 mean-accuracy_score=0.957929 mean-roc_auc_score=0.89281\n",
      "Step 112000 validation: mean-matthews_corrcoef=0.479017 mean-accuracy_score=0.958776 mean-roc_auc_score=0.896886\n",
      "Step 113000 validation: mean-matthews_corrcoef=0.460926 mean-accuracy_score=0.959591 mean-roc_auc_score=0.892311\n",
      "Step 114000 validation: mean-matthews_corrcoef=0.456309 mean-accuracy_score=0.958972 mean-roc_auc_score=0.894742\n",
      "Step 115000 validation: mean-matthews_corrcoef=0.448005 mean-accuracy_score=0.96008 mean-roc_auc_score=0.894161\n",
      "Step 116000 validation: mean-matthews_corrcoef=0.456295 mean-accuracy_score=0.958352 mean-roc_auc_score=0.894091\n",
      "Step 117000 validation: mean-matthews_corrcoef=0.472439 mean-accuracy_score=0.957961 mean-roc_auc_score=0.894681\n",
      "Step 118000 validation: mean-matthews_corrcoef=0.466961 mean-accuracy_score=0.961122 mean-roc_auc_score=0.894785\n",
      "Step 119000 validation: mean-matthews_corrcoef=0.469466 mean-accuracy_score=0.958646 mean-roc_auc_score=0.899366\n",
      "Step 120000 validation: mean-matthews_corrcoef=0.465243 mean-accuracy_score=0.958222 mean-roc_auc_score=0.898887\n",
      "Step 121000 validation: mean-matthews_corrcoef=0.470202 mean-accuracy_score=0.959493 mean-roc_auc_score=0.898139\n",
      "Step 122000 validation: mean-matthews_corrcoef=0.45616 mean-accuracy_score=0.960666 mean-roc_auc_score=0.894073\n",
      "Step 123000 validation: mean-matthews_corrcoef=0.467341 mean-accuracy_score=0.959493 mean-roc_auc_score=0.890123\n",
      "Step 124000 validation: mean-matthews_corrcoef=0.461011 mean-accuracy_score=0.958776 mean-roc_auc_score=0.895835\n",
      "Step 125000 validation: mean-matthews_corrcoef=0.469884 mean-accuracy_score=0.955028 mean-roc_auc_score=0.896575\n",
      "Step 126000 validation: mean-matthews_corrcoef=0.462201 mean-accuracy_score=0.958157 mean-roc_auc_score=0.893014\n",
      "Step 127000 validation: mean-matthews_corrcoef=0.473153 mean-accuracy_score=0.95946 mean-roc_auc_score=0.892435\n",
      "Step 128000 validation: mean-matthews_corrcoef=0.476999 mean-accuracy_score=0.955354 mean-roc_auc_score=0.896251\n",
      "Step 129000 validation: mean-matthews_corrcoef=0.471463 mean-accuracy_score=0.957407 mean-roc_auc_score=0.893651\n",
      "Step 130000 validation: mean-matthews_corrcoef=0.451669 mean-accuracy_score=0.959037 mean-roc_auc_score=0.891884\n",
      "Step 131000 validation: mean-matthews_corrcoef=0.472718 mean-accuracy_score=0.958352 mean-roc_auc_score=0.896713\n",
      "Step 132000 validation: mean-matthews_corrcoef=0.462678 mean-accuracy_score=0.958515 mean-roc_auc_score=0.893878\n",
      "Step 133000 validation: mean-matthews_corrcoef=0.468637 mean-accuracy_score=0.959656 mean-roc_auc_score=0.895147\n",
      "Step 134000 validation: mean-matthews_corrcoef=0.463789 mean-accuracy_score=0.959982 mean-roc_auc_score=0.892113\n",
      "Step 135000 validation: mean-matthews_corrcoef=0.443245 mean-accuracy_score=0.960666 mean-roc_auc_score=0.894252\n",
      "Step 136000 validation: mean-matthews_corrcoef=0.466469 mean-accuracy_score=0.958776 mean-roc_auc_score=0.89338\n",
      "Step 137000 validation: mean-matthews_corrcoef=0.461515 mean-accuracy_score=0.959395 mean-roc_auc_score=0.891467\n",
      "Step 138000 validation: mean-matthews_corrcoef=0.447963 mean-accuracy_score=0.957994 mean-roc_auc_score=0.8895\n",
      "Step 139000 validation: mean-matthews_corrcoef=0.458386 mean-accuracy_score=0.95467 mean-roc_auc_score=0.893016\n",
      "Step 140000 validation: mean-matthews_corrcoef=0.459552 mean-accuracy_score=0.960568 mean-roc_auc_score=0.894461\n",
      "Step 141000 validation: mean-matthews_corrcoef=0.473857 mean-accuracy_score=0.957701 mean-roc_auc_score=0.895424\n",
      "Step 142000 validation: mean-matthews_corrcoef=0.47366 mean-accuracy_score=0.959526 mean-roc_auc_score=0.891778\n",
      "Step 143000 validation: mean-matthews_corrcoef=0.46624 mean-accuracy_score=0.958841 mean-roc_auc_score=0.891199\n",
      "Step 144000 validation: mean-matthews_corrcoef=0.462762 mean-accuracy_score=0.95946 mean-roc_auc_score=0.894559\n",
      "Step 145000 validation: mean-matthews_corrcoef=0.453199 mean-accuracy_score=0.958189 mean-roc_auc_score=0.890774\n",
      "Step 146000 validation: mean-matthews_corrcoef=0.471272 mean-accuracy_score=0.959493 mean-roc_auc_score=0.893289\n",
      "Step 147000 validation: mean-matthews_corrcoef=0.466495 mean-accuracy_score=0.957375 mean-roc_auc_score=0.891033\n",
      "Step 148000 validation: mean-matthews_corrcoef=0.473882 mean-accuracy_score=0.957961 mean-roc_auc_score=0.895408\n",
      "Step 149000 validation: mean-matthews_corrcoef=0.460194 mean-accuracy_score=0.958906 mean-roc_auc_score=0.89066\n",
      "Step 150000 validation: mean-matthews_corrcoef=0.46802 mean-accuracy_score=0.959167 mean-roc_auc_score=0.894924\n",
      "Step 151000 validation: mean-matthews_corrcoef=0.477123 mean-accuracy_score=0.958515 mean-roc_auc_score=0.894255\n",
      "Step 152000 validation: mean-matthews_corrcoef=0.456303 mean-accuracy_score=0.959558 mean-roc_auc_score=0.89272\n",
      "Step 153000 validation: mean-matthews_corrcoef=0.467902 mean-accuracy_score=0.956886 mean-roc_auc_score=0.893821\n",
      "Step 154000 validation: mean-matthews_corrcoef=0.475704 mean-accuracy_score=0.95669 mean-roc_auc_score=0.893938\n",
      "Step 155000 validation: mean-matthews_corrcoef=0.459405 mean-accuracy_score=0.959493 mean-roc_auc_score=0.890115\n",
      "Step 156000 validation: mean-matthews_corrcoef=0.462675 mean-accuracy_score=0.958418 mean-roc_auc_score=0.889079\n",
      "Step 157000 validation: mean-matthews_corrcoef=0.469333 mean-accuracy_score=0.95731 mean-roc_auc_score=0.894186\n",
      "Step 158000 validation: mean-matthews_corrcoef=0.465863 mean-accuracy_score=0.95568 mean-roc_auc_score=0.890104\n",
      "Step 159000 validation: mean-matthews_corrcoef=0.469836 mean-accuracy_score=0.956462 mean-roc_auc_score=0.89071\n",
      "Step 160000 validation: mean-matthews_corrcoef=0.465805 mean-accuracy_score=0.957538 mean-roc_auc_score=0.892095\n",
      "Step 161000 validation: mean-matthews_corrcoef=0.469131 mean-accuracy_score=0.959493 mean-roc_auc_score=0.891916\n",
      "Step 162000 validation: mean-matthews_corrcoef=0.477951 mean-accuracy_score=0.958776 mean-roc_auc_score=0.894998\n",
      "Step 163000 validation: mean-matthews_corrcoef=0.471938 mean-accuracy_score=0.955419 mean-roc_auc_score=0.890638\n",
      "Step 164000 validation: mean-matthews_corrcoef=0.459105 mean-accuracy_score=0.959721 mean-roc_auc_score=0.893706\n",
      "Step 165000 validation: mean-matthews_corrcoef=0.477144 mean-accuracy_score=0.960145 mean-roc_auc_score=0.896173\n",
      "Step 166000 validation: mean-matthews_corrcoef=0.463997 mean-accuracy_score=0.955387 mean-roc_auc_score=0.893995\n",
      "Step 167000 validation: mean-matthews_corrcoef=0.450492 mean-accuracy_score=0.956299 mean-roc_auc_score=0.888633\n",
      "Step 168000 validation: mean-matthews_corrcoef=0.466242 mean-accuracy_score=0.958059 mean-roc_auc_score=0.890385\n",
      "Step 169000 validation: mean-matthews_corrcoef=0.469946 mean-accuracy_score=0.95946 mean-roc_auc_score=0.893581\n",
      "Step 170000 validation: mean-matthews_corrcoef=0.441979 mean-accuracy_score=0.956006 mean-roc_auc_score=0.890167\n",
      "Step 171000 validation: mean-matthews_corrcoef=0.462787 mean-accuracy_score=0.955778 mean-roc_auc_score=0.892182\n",
      "Step 172000 validation: mean-matthews_corrcoef=0.458634 mean-accuracy_score=0.95832 mean-roc_auc_score=0.889974\n",
      "Step 173000 validation: mean-matthews_corrcoef=0.459554 mean-accuracy_score=0.95669 mean-roc_auc_score=0.891915\n",
      "Step 174000 validation: mean-matthews_corrcoef=0.452208 mean-accuracy_score=0.957244 mean-roc_auc_score=0.893192\n",
      "Step 175000 validation: mean-matthews_corrcoef=0.465569 mean-accuracy_score=0.959037 mean-roc_auc_score=0.892411\n",
      "Step 176000 validation: mean-matthews_corrcoef=0.456562 mean-accuracy_score=0.957277 mean-roc_auc_score=0.890913\n",
      "Step 177000 validation: mean-matthews_corrcoef=0.473153 mean-accuracy_score=0.95946 mean-roc_auc_score=0.892313\n",
      "Step 178000 validation: mean-matthews_corrcoef=0.469851 mean-accuracy_score=0.960699 mean-roc_auc_score=0.888183\n",
      "Step 179000 validation: mean-matthews_corrcoef=0.463615 mean-accuracy_score=0.958972 mean-roc_auc_score=0.893376\n",
      "Step 180000 validation: mean-matthews_corrcoef=0.458561 mean-accuracy_score=0.958743 mean-roc_auc_score=0.890351\n",
      "Step 181000 validation: mean-matthews_corrcoef=0.468994 mean-accuracy_score=0.959656 mean-roc_auc_score=0.894427\n",
      "Step 182000 validation: mean-matthews_corrcoef=0.437095 mean-accuracy_score=0.958906 mean-roc_auc_score=0.884676\n",
      "Step 183000 validation: mean-matthews_corrcoef=0.45392 mean-accuracy_score=0.957635 mean-roc_auc_score=0.889307\n",
      "Step 184000 validation: mean-matthews_corrcoef=0.45668 mean-accuracy_score=0.954637 mean-roc_auc_score=0.885127\n",
      "Step 185000 validation: mean-matthews_corrcoef=0.463417 mean-accuracy_score=0.958613 mean-roc_auc_score=0.890129\n",
      "Step 186000 validation: mean-matthews_corrcoef=0.450373 mean-accuracy_score=0.958548 mean-roc_auc_score=0.893888\n",
      "Step 187000 validation: mean-matthews_corrcoef=0.456609 mean-accuracy_score=0.958776 mean-roc_auc_score=0.890205\n",
      "Step 188000 validation: mean-matthews_corrcoef=0.45016 mean-accuracy_score=0.954865 mean-roc_auc_score=0.88883\n",
      "Step 189000 validation: mean-matthews_corrcoef=0.456113 mean-accuracy_score=0.955843 mean-roc_auc_score=0.890435\n",
      "Step 190000 validation: mean-matthews_corrcoef=0.465457 mean-accuracy_score=0.960308 mean-roc_auc_score=0.889219\n",
      "Step 191000 validation: mean-matthews_corrcoef=0.467434 mean-accuracy_score=0.956039 mean-roc_auc_score=0.892233\n",
      "Step 192000 validation: mean-matthews_corrcoef=0.463409 mean-accuracy_score=0.958515 mean-roc_auc_score=0.890811\n",
      "Step 193000 validation: mean-matthews_corrcoef=0.446432 mean-accuracy_score=0.958711 mean-roc_auc_score=0.886137\n",
      "Step 194000 validation: mean-matthews_corrcoef=0.467101 mean-accuracy_score=0.956658 mean-roc_auc_score=0.88986\n",
      "Step 195000 validation: mean-matthews_corrcoef=0.462891 mean-accuracy_score=0.957798 mean-roc_auc_score=0.888063\n",
      "Step 196000 validation: mean-matthews_corrcoef=0.477547 mean-accuracy_score=0.9592 mean-roc_auc_score=0.891724\n",
      "Step 197000 validation: mean-matthews_corrcoef=0.463166 mean-accuracy_score=0.958287 mean-roc_auc_score=0.889715\n",
      "Step 198000 validation: mean-matthews_corrcoef=0.47227 mean-accuracy_score=0.956332 mean-roc_auc_score=0.891311\n",
      "Step 199000 validation: mean-matthews_corrcoef=0.463961 mean-accuracy_score=0.954605 mean-roc_auc_score=0.891781\n",
      "Step 200000 validation: mean-matthews_corrcoef=0.471922 mean-accuracy_score=0.958092 mean-roc_auc_score=0.890863\n",
      "Step 201000 validation: mean-matthews_corrcoef=0.473052 mean-accuracy_score=0.960373 mean-roc_auc_score=0.89223\n",
      "Step 202000 validation: mean-matthews_corrcoef=0.46012 mean-accuracy_score=0.959037 mean-roc_auc_score=0.890049\n",
      "Step 203000 validation: mean-matthews_corrcoef=0.474323 mean-accuracy_score=0.959656 mean-roc_auc_score=0.890979\n",
      "Step 204000 validation: mean-matthews_corrcoef=0.467999 mean-accuracy_score=0.957538 mean-roc_auc_score=0.894713\n",
      "Step 205000 validation: mean-matthews_corrcoef=0.47076 mean-accuracy_score=0.957929 mean-roc_auc_score=0.89041\n",
      "Step 206000 validation: mean-matthews_corrcoef=0.467153 mean-accuracy_score=0.96122 mean-roc_auc_score=0.886927\n",
      "Step 207000 validation: mean-matthews_corrcoef=0.477833 mean-accuracy_score=0.957961 mean-roc_auc_score=0.892504\n",
      "Step 208000 validation: mean-matthews_corrcoef=0.470035 mean-accuracy_score=0.957929 mean-roc_auc_score=0.889334\n",
      "Step 209000 validation: mean-matthews_corrcoef=0.460354 mean-accuracy_score=0.95845 mean-roc_auc_score=0.885385\n",
      "Step 210000 validation: mean-matthews_corrcoef=0.451279 mean-accuracy_score=0.956136 mean-roc_auc_score=0.887658\n",
      "Step 211000 validation: mean-matthews_corrcoef=0.457183 mean-accuracy_score=0.96034 mean-roc_auc_score=0.886745\n",
      "Step 212000 validation: mean-matthews_corrcoef=0.464748 mean-accuracy_score=0.958548 mean-roc_auc_score=0.884783\n",
      "Step 213000 validation: mean-matthews_corrcoef=0.458439 mean-accuracy_score=0.956853 mean-roc_auc_score=0.887735\n",
      "Step 214000 validation: mean-matthews_corrcoef=0.469931 mean-accuracy_score=0.959949 mean-roc_auc_score=0.887975\n",
      "Step 215000 validation: mean-matthews_corrcoef=0.466264 mean-accuracy_score=0.959493 mean-roc_auc_score=0.889428\n",
      "Step 216000 validation: mean-matthews_corrcoef=0.454502 mean-accuracy_score=0.955713 mean-roc_auc_score=0.887562\n",
      "Step 217000 validation: mean-matthews_corrcoef=0.472412 mean-accuracy_score=0.958059 mean-roc_auc_score=0.887661\n",
      "Step 218000 validation: mean-matthews_corrcoef=0.469285 mean-accuracy_score=0.95933 mean-roc_auc_score=0.890737\n",
      "Step 219000 validation: mean-matthews_corrcoef=0.470996 mean-accuracy_score=0.956527 mean-roc_auc_score=0.889758\n",
      "Step 220000 validation: mean-matthews_corrcoef=0.466674 mean-accuracy_score=0.955224 mean-roc_auc_score=0.889365\n",
      "Step 221000 validation: mean-matthews_corrcoef=0.469152 mean-accuracy_score=0.960699 mean-roc_auc_score=0.887837\n",
      "Step 222000 validation: mean-matthews_corrcoef=0.471759 mean-accuracy_score=0.960959 mean-roc_auc_score=0.890169\n",
      "Step 223000 validation: mean-matthews_corrcoef=0.462165 mean-accuracy_score=0.957016 mean-roc_auc_score=0.8878\n",
      "Step 224000 validation: mean-matthews_corrcoef=0.461813 mean-accuracy_score=0.955159 mean-roc_auc_score=0.887238\n",
      "Step 225000 validation: mean-matthews_corrcoef=0.468814 mean-accuracy_score=0.955094 mean-roc_auc_score=0.889012\n",
      "Step 226000 validation: mean-matthews_corrcoef=0.462497 mean-accuracy_score=0.949488 mean-roc_auc_score=0.891593\n",
      "Step 227000 validation: mean-matthews_corrcoef=0.451096 mean-accuracy_score=0.95946 mean-roc_auc_score=0.887161\n",
      "Step 228000 validation: mean-matthews_corrcoef=0.465422 mean-accuracy_score=0.960177 mean-roc_auc_score=0.889669\n",
      "Step 229000 validation: mean-matthews_corrcoef=0.457302 mean-accuracy_score=0.959004 mean-roc_auc_score=0.890352\n",
      "Step 230000 validation: mean-matthews_corrcoef=0.461603 mean-accuracy_score=0.953203 mean-roc_auc_score=0.887733\n",
      "Step 231000 validation: mean-matthews_corrcoef=0.467303 mean-accuracy_score=0.958255 mean-roc_auc_score=0.888833\n",
      "Step 232000 validation: mean-matthews_corrcoef=0.466327 mean-accuracy_score=0.95832 mean-roc_auc_score=0.890244\n",
      "Step 233000 validation: mean-matthews_corrcoef=0.456615 mean-accuracy_score=0.957179 mean-roc_auc_score=0.88492\n",
      "Step 234000 validation: mean-matthews_corrcoef=0.448056 mean-accuracy_score=0.959623 mean-roc_auc_score=0.888896\n",
      "Step 235000 validation: mean-matthews_corrcoef=0.459721 mean-accuracy_score=0.957407 mean-roc_auc_score=0.884971\n",
      "Step 236000 validation: mean-matthews_corrcoef=0.464045 mean-accuracy_score=0.961481 mean-roc_auc_score=0.884273\n",
      "Step 237000 validation: mean-matthews_corrcoef=0.461071 mean-accuracy_score=0.956364 mean-roc_auc_score=0.887677\n",
      "Step 238000 validation: mean-matthews_corrcoef=0.448809 mean-accuracy_score=0.959754 mean-roc_auc_score=0.886386\n",
      "Step 239000 validation: mean-matthews_corrcoef=0.461783 mean-accuracy_score=0.95568 mean-roc_auc_score=0.887805\n",
      "Step 240000 validation: mean-matthews_corrcoef=0.467732 mean-accuracy_score=0.957342 mean-roc_auc_score=0.889031\n",
      "Step 241000 validation: mean-matthews_corrcoef=0.453291 mean-accuracy_score=0.959721 mean-roc_auc_score=0.887354\n",
      "Step 242000 validation: mean-matthews_corrcoef=0.460671 mean-accuracy_score=0.958874 mean-roc_auc_score=0.887534\n",
      "Step 243000 validation: mean-matthews_corrcoef=0.473938 mean-accuracy_score=0.956364 mean-roc_auc_score=0.888611\n",
      "Step 244000 validation: mean-matthews_corrcoef=0.473042 mean-accuracy_score=0.957635 mean-roc_auc_score=0.887819\n",
      "Step 245000 validation: mean-matthews_corrcoef=0.468336 mean-accuracy_score=0.959884 mean-roc_auc_score=0.887563\n",
      "Step 246000 validation: mean-matthews_corrcoef=0.476628 mean-accuracy_score=0.954572 mean-roc_auc_score=0.890106\n",
      "Step 247000 validation: mean-matthews_corrcoef=0.468783 mean-accuracy_score=0.960112 mean-roc_auc_score=0.885346\n",
      "Step 248000 validation: mean-matthews_corrcoef=0.469803 mean-accuracy_score=0.957896 mean-roc_auc_score=0.886469\n",
      "Step 249000 validation: mean-matthews_corrcoef=0.469084 mean-accuracy_score=0.956625 mean-roc_auc_score=0.884331\n",
      "Step 250000 validation: mean-matthews_corrcoef=0.475709 mean-accuracy_score=0.955322 mean-roc_auc_score=0.892013\n",
      "Step 251000 validation: mean-matthews_corrcoef=0.473787 mean-accuracy_score=0.958743 mean-roc_auc_score=0.891228\n",
      "Step 252000 validation: mean-matthews_corrcoef=0.462675 mean-accuracy_score=0.958418 mean-roc_auc_score=0.888046\n",
      "Step 253000 validation: mean-matthews_corrcoef=0.4659 mean-accuracy_score=0.957961 mean-roc_auc_score=0.886812\n",
      "Step 254000 validation: mean-matthews_corrcoef=0.454186 mean-accuracy_score=0.96008 mean-roc_auc_score=0.883798\n",
      "Step 255000 validation: mean-matthews_corrcoef=0.469751 mean-accuracy_score=0.958092 mean-roc_auc_score=0.887308\n",
      "Step 256000 validation: mean-matthews_corrcoef=0.463874 mean-accuracy_score=0.959819 mean-roc_auc_score=0.887118\n",
      "Step 257000 validation: mean-matthews_corrcoef=0.467681 mean-accuracy_score=0.958157 mean-roc_auc_score=0.883588\n",
      "Step 258000 validation: mean-matthews_corrcoef=0.484165 mean-accuracy_score=0.955582 mean-roc_auc_score=0.890346\n",
      "Step 259000 validation: mean-matthews_corrcoef=0.472107 mean-accuracy_score=0.958515 mean-roc_auc_score=0.885019\n",
      "Step 260000 validation: mean-matthews_corrcoef=0.463099 mean-accuracy_score=0.953269 mean-roc_auc_score=0.886225\n",
      "Step 261000 validation: mean-matthews_corrcoef=0.478961 mean-accuracy_score=0.959526 mean-roc_auc_score=0.88665\n",
      "Step 262000 validation: mean-matthews_corrcoef=0.472586 mean-accuracy_score=0.957147 mean-roc_auc_score=0.88681\n",
      "Step 263000 validation: mean-matthews_corrcoef=0.469397 mean-accuracy_score=0.958972 mean-roc_auc_score=0.889455\n",
      "Step 264000 validation: mean-matthews_corrcoef=0.458971 mean-accuracy_score=0.956984 mean-roc_auc_score=0.890369\n",
      "Step 265000 validation: mean-matthews_corrcoef=0.471681 mean-accuracy_score=0.955843 mean-roc_auc_score=0.89037\n",
      "Step 266000 validation: mean-matthews_corrcoef=0.473912 mean-accuracy_score=0.959917 mean-roc_auc_score=0.887062\n",
      "Step 267000 validation: mean-matthews_corrcoef=0.47397 mean-accuracy_score=0.955973 mean-roc_auc_score=0.889809\n",
      "Step 268000 validation: mean-matthews_corrcoef=0.468362 mean-accuracy_score=0.959395 mean-roc_auc_score=0.888153\n",
      "Step 269000 validation: mean-matthews_corrcoef=0.475149 mean-accuracy_score=0.956495 mean-roc_auc_score=0.886647\n",
      "Step 270000 validation: mean-matthews_corrcoef=0.474022 mean-accuracy_score=0.958678 mean-roc_auc_score=0.889338\n",
      "Step 271000 validation: mean-matthews_corrcoef=0.472226 mean-accuracy_score=0.95858 mean-roc_auc_score=0.887926\n",
      "Step 272000 validation: mean-matthews_corrcoef=0.474636 mean-accuracy_score=0.95933 mean-roc_auc_score=0.888852\n",
      "Step 273000 validation: mean-matthews_corrcoef=0.486793 mean-accuracy_score=0.960992 mean-roc_auc_score=0.889248\n",
      "Step 274000 validation: mean-matthews_corrcoef=0.466877 mean-accuracy_score=0.959297 mean-roc_auc_score=0.886709\n",
      "Step 275000 validation: mean-matthews_corrcoef=0.478718 mean-accuracy_score=0.959167 mean-roc_auc_score=0.888075\n",
      "Step 276000 validation: mean-matthews_corrcoef=0.468408 mean-accuracy_score=0.958157 mean-roc_auc_score=0.887527\n",
      "Step 277000 validation: mean-matthews_corrcoef=0.47347 mean-accuracy_score=0.958157 mean-roc_auc_score=0.888329\n",
      "Step 278000 validation: mean-matthews_corrcoef=0.446364 mean-accuracy_score=0.956527 mean-roc_auc_score=0.884072\n",
      "Step 279000 validation: mean-matthews_corrcoef=0.474671 mean-accuracy_score=0.957505 mean-roc_auc_score=0.890404\n",
      "Step 280000 validation: mean-matthews_corrcoef=0.466564 mean-accuracy_score=0.95845 mean-roc_auc_score=0.888744\n",
      "Step 281000 validation: mean-matthews_corrcoef=0.478104 mean-accuracy_score=0.960177 mean-roc_auc_score=0.888956\n",
      "Step 282000 validation: mean-matthews_corrcoef=0.464159 mean-accuracy_score=0.958711 mean-roc_auc_score=0.887253\n",
      "Step 283000 validation: mean-matthews_corrcoef=0.46438 mean-accuracy_score=0.95845 mean-roc_auc_score=0.886244\n",
      "Step 284000 validation: mean-matthews_corrcoef=0.463338 mean-accuracy_score=0.956756 mean-roc_auc_score=0.886725\n",
      "Step 285000 validation: mean-matthews_corrcoef=0.474754 mean-accuracy_score=0.958874 mean-roc_auc_score=0.887996\n",
      "Step 286000 validation: mean-matthews_corrcoef=0.461665 mean-accuracy_score=0.959232 mean-roc_auc_score=0.883855\n",
      "Step 287000 validation: mean-matthews_corrcoef=0.481411 mean-accuracy_score=0.959102 mean-roc_auc_score=0.887506\n",
      "Step 288000 validation: mean-matthews_corrcoef=0.471883 mean-accuracy_score=0.959526 mean-roc_auc_score=0.887653\n",
      "Step 289000 validation: mean-matthews_corrcoef=0.468721 mean-accuracy_score=0.960275 mean-roc_auc_score=0.885818\n",
      "Step 290000 validation: mean-matthews_corrcoef=0.458123 mean-accuracy_score=0.960242 mean-roc_auc_score=0.884789\n",
      "Step 291000 validation: mean-matthews_corrcoef=0.47863 mean-accuracy_score=0.960112 mean-roc_auc_score=0.888603\n",
      "Step 292000 validation: mean-matthews_corrcoef=0.465784 mean-accuracy_score=0.960471 mean-roc_auc_score=0.886677\n",
      "Step 293000 validation: mean-matthews_corrcoef=0.456522 mean-accuracy_score=0.959363 mean-roc_auc_score=0.883452\n",
      "Step 294000 validation: mean-matthews_corrcoef=0.455208 mean-accuracy_score=0.957961 mean-roc_auc_score=0.883203\n",
      "Step 295000 validation: mean-matthews_corrcoef=0.474984 mean-accuracy_score=0.958809 mean-roc_auc_score=0.8876\n",
      "Step 296000 validation: mean-matthews_corrcoef=0.462565 mean-accuracy_score=0.959526 mean-roc_auc_score=0.887764\n",
      "Step 297000 validation: mean-matthews_corrcoef=0.478132 mean-accuracy_score=0.957798 mean-roc_auc_score=0.888133\n",
      "Step 298000 validation: mean-matthews_corrcoef=0.475952 mean-accuracy_score=0.958939 mean-roc_auc_score=0.886844\n",
      "Step 299000 validation: mean-matthews_corrcoef=0.461704 mean-accuracy_score=0.960927 mean-roc_auc_score=0.883494\n",
      "Step 300000 validation: mean-matthews_corrcoef=0.470604 mean-accuracy_score=0.958059 mean-roc_auc_score=0.888213\n",
      "Step 301000 validation: mean-matthews_corrcoef=0.470165 mean-accuracy_score=0.957896 mean-roc_auc_score=0.88787\n",
      "Step 302000 validation: mean-matthews_corrcoef=0.476129 mean-accuracy_score=0.9592 mean-roc_auc_score=0.889484\n",
      "Step 303000 validation: mean-matthews_corrcoef=0.465427 mean-accuracy_score=0.956462 mean-roc_auc_score=0.887323\n",
      "Step 304000 validation: mean-matthews_corrcoef=0.479725 mean-accuracy_score=0.958678 mean-roc_auc_score=0.889376\n",
      "Step 305000 validation: mean-matthews_corrcoef=0.441501 mean-accuracy_score=0.961383 mean-roc_auc_score=0.878204\n",
      "Step 306000 validation: mean-matthews_corrcoef=0.47146 mean-accuracy_score=0.961122 mean-roc_auc_score=0.888145\n",
      "Step 307000 validation: mean-matthews_corrcoef=0.475548 mean-accuracy_score=0.956886 mean-roc_auc_score=0.888358\n",
      "Step 308000 validation: mean-matthews_corrcoef=0.47557 mean-accuracy_score=0.96021 mean-roc_auc_score=0.88778\n",
      "Step 309000 validation: mean-matthews_corrcoef=0.482005 mean-accuracy_score=0.96135 mean-roc_auc_score=0.890976\n",
      "Step 310000 validation: mean-matthews_corrcoef=0.455211 mean-accuracy_score=0.961318 mean-roc_auc_score=0.885571\n",
      "Step 311000 validation: mean-matthews_corrcoef=0.468603 mean-accuracy_score=0.95731 mean-roc_auc_score=0.886613\n",
      "Step 312000 validation: mean-matthews_corrcoef=0.475049 mean-accuracy_score=0.960275 mean-roc_auc_score=0.886727\n",
      "Step 313000 validation: mean-matthews_corrcoef=0.481452 mean-accuracy_score=0.956853 mean-roc_auc_score=0.890293\n",
      "Step 314000 validation: mean-matthews_corrcoef=0.459197 mean-accuracy_score=0.959688 mean-roc_auc_score=0.883616\n",
      "Step 315000 validation: mean-matthews_corrcoef=0.467781 mean-accuracy_score=0.95832 mean-roc_auc_score=0.888138\n",
      "Step 316000 validation: mean-matthews_corrcoef=0.476883 mean-accuracy_score=0.960242 mean-roc_auc_score=0.884692\n",
      "Step 317000 validation: mean-matthews_corrcoef=0.464315 mean-accuracy_score=0.96034 mean-roc_auc_score=0.886768\n",
      "Step 318000 validation: mean-matthews_corrcoef=0.467366 mean-accuracy_score=0.957342 mean-roc_auc_score=0.886581\n",
      "Step 319000 validation: mean-matthews_corrcoef=0.471469 mean-accuracy_score=0.956039 mean-roc_auc_score=0.886127\n",
      "Step 320000 validation: mean-matthews_corrcoef=0.469736 mean-accuracy_score=0.956723 mean-roc_auc_score=0.887346\n",
      "Step 321000 validation: mean-matthews_corrcoef=0.463781 mean-accuracy_score=0.958222 mean-roc_auc_score=0.885323\n",
      "Step 322000 validation: mean-matthews_corrcoef=0.471625 mean-accuracy_score=0.956006 mean-roc_auc_score=0.888503\n",
      "Step 323000 validation: mean-matthews_corrcoef=0.481148 mean-accuracy_score=0.95858 mean-roc_auc_score=0.889325\n",
      "Step 324000 validation: mean-matthews_corrcoef=0.474691 mean-accuracy_score=0.960145 mean-roc_auc_score=0.886527\n",
      "Step 325000 validation: mean-matthews_corrcoef=0.467653 mean-accuracy_score=0.958548 mean-roc_auc_score=0.884445\n",
      "Step 326000 validation: mean-matthews_corrcoef=0.471218 mean-accuracy_score=0.960405 mean-roc_auc_score=0.883186\n",
      "Step 327000 validation: mean-matthews_corrcoef=0.469674 mean-accuracy_score=0.959102 mean-roc_auc_score=0.883755\n",
      "Step 328000 validation: mean-matthews_corrcoef=0.472638 mean-accuracy_score=0.957472 mean-roc_auc_score=0.886351\n",
      "Step 329000 validation: mean-matthews_corrcoef=0.473406 mean-accuracy_score=0.959493 mean-roc_auc_score=0.887128\n",
      "Step 330000 validation: mean-matthews_corrcoef=0.471824 mean-accuracy_score=0.959102 mean-roc_auc_score=0.886056\n",
      "Step 331000 validation: mean-matthews_corrcoef=0.472847 mean-accuracy_score=0.956364 mean-roc_auc_score=0.888643\n",
      "Step 332000 validation: mean-matthews_corrcoef=0.457289 mean-accuracy_score=0.958483 mean-roc_auc_score=0.884473\n",
      "Step 333000 validation: mean-matthews_corrcoef=0.472357 mean-accuracy_score=0.959721 mean-roc_auc_score=0.885478\n",
      "Step 334000 validation: mean-matthews_corrcoef=0.467948 mean-accuracy_score=0.961155 mean-roc_auc_score=0.882416\n",
      "Step 335000 validation: mean-matthews_corrcoef=0.459404 mean-accuracy_score=0.95757 mean-roc_auc_score=0.886527\n",
      "Step 336000 validation: mean-matthews_corrcoef=0.462358 mean-accuracy_score=0.952682 mean-roc_auc_score=0.891603\n",
      "Step 337000 validation: mean-matthews_corrcoef=0.45548 mean-accuracy_score=0.959591 mean-roc_auc_score=0.882873\n",
      "Step 338000 validation: mean-matthews_corrcoef=0.479627 mean-accuracy_score=0.958418 mean-roc_auc_score=0.886252\n",
      "Step 339000 validation: mean-matthews_corrcoef=0.460822 mean-accuracy_score=0.959884 mean-roc_auc_score=0.883905\n",
      "Step 340000 validation: mean-matthews_corrcoef=0.461709 mean-accuracy_score=0.95858 mean-roc_auc_score=0.882839\n",
      "Step 341000 validation: mean-matthews_corrcoef=0.469053 mean-accuracy_score=0.954833 mean-roc_auc_score=0.887156\n",
      "Step 342000 validation: mean-matthews_corrcoef=0.469674 mean-accuracy_score=0.959102 mean-roc_auc_score=0.889226\n",
      "Step 343000 validation: mean-matthews_corrcoef=0.468673 mean-accuracy_score=0.959526 mean-roc_auc_score=0.884154\n",
      "Step 344000 validation: mean-matthews_corrcoef=0.471033 mean-accuracy_score=0.958711 mean-roc_auc_score=0.88633\n",
      "Step 345000 validation: mean-matthews_corrcoef=0.463873 mean-accuracy_score=0.960536 mean-roc_auc_score=0.882567\n",
      "Step 346000 validation: mean-matthews_corrcoef=0.479333 mean-accuracy_score=0.955322 mean-roc_auc_score=0.888335\n",
      "Step 347000 validation: mean-matthews_corrcoef=0.480412 mean-accuracy_score=0.959623 mean-roc_auc_score=0.887754\n",
      "Step 348000 validation: mean-matthews_corrcoef=0.466773 mean-accuracy_score=0.95933 mean-roc_auc_score=0.882492\n",
      "Step 349000 validation: mean-matthews_corrcoef=0.468265 mean-accuracy_score=0.958678 mean-roc_auc_score=0.884277\n",
      "Step 350000 validation: mean-matthews_corrcoef=0.4714 mean-accuracy_score=0.95832 mean-roc_auc_score=0.884641\n",
      "Step 351000 validation: mean-matthews_corrcoef=0.459124 mean-accuracy_score=0.959982 mean-roc_auc_score=0.882563\n",
      "Step 352000 validation: mean-matthews_corrcoef=0.469708 mean-accuracy_score=0.9592 mean-roc_auc_score=0.887842\n",
      "Step 353000 validation: mean-matthews_corrcoef=0.486105 mean-accuracy_score=0.958026 mean-roc_auc_score=0.890395\n",
      "Step 354000 validation: mean-matthews_corrcoef=0.465744 mean-accuracy_score=0.958776 mean-roc_auc_score=0.884214\n",
      "Step 355000 validation: mean-matthews_corrcoef=0.465196 mean-accuracy_score=0.961383 mean-roc_auc_score=0.881919\n",
      "Step 356000 validation: mean-matthews_corrcoef=0.471943 mean-accuracy_score=0.956169 mean-roc_auc_score=0.887793\n",
      "Step 357000 validation: mean-matthews_corrcoef=0.476241 mean-accuracy_score=0.959493 mean-roc_auc_score=0.885591\n",
      "Step 358000 validation: mean-matthews_corrcoef=0.479595 mean-accuracy_score=0.960405 mean-roc_auc_score=0.884818\n",
      "Step 359000 validation: mean-matthews_corrcoef=0.4741 mean-accuracy_score=0.956886 mean-roc_auc_score=0.886597\n",
      "Step 360000 validation: mean-matthews_corrcoef=0.480374 mean-accuracy_score=0.960112 mean-roc_auc_score=0.886757\n",
      "Step 361000 validation: mean-matthews_corrcoef=0.470429 mean-accuracy_score=0.957831 mean-roc_auc_score=0.884771\n",
      "Step 362000 validation: mean-matthews_corrcoef=0.48316 mean-accuracy_score=0.958515 mean-roc_auc_score=0.88709\n",
      "Step 363000 validation: mean-matthews_corrcoef=0.466034 mean-accuracy_score=0.95757 mean-roc_auc_score=0.886963\n",
      "Step 364000 validation: mean-matthews_corrcoef=0.463207 mean-accuracy_score=0.961318 mean-roc_auc_score=0.880934\n",
      "Step 365000 validation: mean-matthews_corrcoef=0.477504 mean-accuracy_score=0.95832 mean-roc_auc_score=0.88543\n",
      "Step 366000 validation: mean-matthews_corrcoef=0.471585 mean-accuracy_score=0.961253 mean-roc_auc_score=0.883688\n",
      "Step 367000 validation: mean-matthews_corrcoef=0.460875 mean-accuracy_score=0.958711 mean-roc_auc_score=0.881967\n",
      "Step 368000 validation: mean-matthews_corrcoef=0.473796 mean-accuracy_score=0.954279 mean-roc_auc_score=0.886177\n",
      "Step 369000 validation: mean-matthews_corrcoef=0.472431 mean-accuracy_score=0.96034 mean-roc_auc_score=0.882936\n",
      "Step 370000 validation: mean-matthews_corrcoef=0.486851 mean-accuracy_score=0.957668 mean-roc_auc_score=0.88688\n",
      "Step 371000 validation: mean-matthews_corrcoef=0.467469 mean-accuracy_score=0.959688 mean-roc_auc_score=0.883144\n",
      "Step 372000 validation: mean-matthews_corrcoef=0.482688 mean-accuracy_score=0.956658 mean-roc_auc_score=0.886269\n",
      "Step 373000 validation: mean-matthews_corrcoef=0.468502 mean-accuracy_score=0.961807 mean-roc_auc_score=0.879034\n",
      "Step 374000 validation: mean-matthews_corrcoef=0.45184 mean-accuracy_score=0.958874 mean-roc_auc_score=0.880538\n",
      "Step 375000 validation: mean-matthews_corrcoef=0.468815 mean-accuracy_score=0.959037 mean-roc_auc_score=0.883433\n",
      "Step 376000 validation: mean-matthews_corrcoef=0.468412 mean-accuracy_score=0.95744 mean-roc_auc_score=0.887457\n",
      "Step 377000 validation: mean-matthews_corrcoef=0.475209 mean-accuracy_score=0.960796 mean-roc_auc_score=0.879676\n",
      "Step 378000 validation: mean-matthews_corrcoef=0.474265 mean-accuracy_score=0.959917 mean-roc_auc_score=0.884384\n",
      "Step 379000 validation: mean-matthews_corrcoef=0.464172 mean-accuracy_score=0.959591 mean-roc_auc_score=0.883037\n",
      "Step 380000 validation: mean-matthews_corrcoef=0.47181 mean-accuracy_score=0.960308 mean-roc_auc_score=0.880765\n",
      "Step 381000 validation: mean-matthews_corrcoef=0.471623 mean-accuracy_score=0.959851 mean-roc_auc_score=0.882097\n",
      "Step 382000 validation: mean-matthews_corrcoef=0.47114 mean-accuracy_score=0.960438 mean-roc_auc_score=0.880615\n",
      "Step 383000 validation: mean-matthews_corrcoef=0.475698 mean-accuracy_score=0.958809 mean-roc_auc_score=0.882609\n"
     ]
    }
   ],
   "source": [
    "hist11 = model11.fit(train_dataset, nb_epoch=200, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3ab6d-b82c-45b9-9bc8-3f5f3f7e304a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a9ff10f-9dd2-42f5-af37-ff62fd0e2a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.9886646777979844, 'mean-accuracy_score': 0.9990305183060955, 'mean-roc_auc_score': 0.9999464164108443}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.47246252561496016, 'mean-accuracy_score': 0.9592322231636577, 'mean-roc_auc_score': 0.8847153576956326}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.45208120822716674, 'mean-accuracy_score': 0.9575390230390719, 'mean-roc_auc_score': 0.8811270699702469}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.5072253130749046, 'mean-accuracy_score': 0.9620999804471094, 'mean-roc_auc_score': 0.9022784670609987}\n",
      "Loss? = 0.005859992504119873\n",
      "[[28888   424]\n",
      " [  739   635]]\n",
      "Specificity = 0.9855\n",
      "FPR = 0.0145\n",
      "Recall/TPR = 0.4622\n",
      "Precision = 0.5996\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model11, hist11, save_dir11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61a10833-1daf-4afd-bf9c-f3ec6f247ad0",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred11 = [x.flatten() for x in model11.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c971a1-0176-473c-bef0-bc0771c6cf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values  pred_probs\n",
       "0          0.0    0.000401\n",
       "1          0.0    0.000221\n",
       "2          0.0    0.001008\n",
       "3          0.0    0.000019\n",
       "4          0.0    0.461923"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred11_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred11])})\n",
    "\n",
    "pred11_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f9d2f45-e2f1-4766-8f52-ac9c15e3427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred11_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that Outcome = 1')\n",
    "plt.legend()\n",
    "plt.ylim(0, 2000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9eded-d958-49e7-a93b-9561f2476370",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f48bbaa-5f92-4b85-9598-150ea7a9dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(539,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(539, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(3500,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(3500, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(2871,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(2871, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(188, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_11:0\", shape=(539,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_10:0\", shape=(539, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_13:0\", shape=(3500,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_12:0\", shape=(3500, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_15:0\", shape=(2871,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_14:0\", shape=(2871, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_17:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_16:0\", shape=(188, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_14:0\", shape=(539,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_13:0\", shape=(539, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_17:0\", shape=(3500,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_16:0\", shape=(3500, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_20:0\", shape=(2871,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_19:0\", shape=(2871, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_22:0\", shape=(188, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(541,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(541, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(3312, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(2913, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(148,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(148, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_11:0\", shape=(541,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_10:0\", shape=(541, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_13:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_12:0\", shape=(3312, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_15:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_14:0\", shape=(2913, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_17:0\", shape=(148,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_16:0\", shape=(148, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_14:0\", shape=(541,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_13:0\", shape=(541, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_17:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_16:0\", shape=(3312, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_19:0\", shape=(2913, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_23:0\", shape=(148,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_22:0\", shape=(148, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_conv_7/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.174233 mean-accuracy_score=0.847422 mean-roc_auc_score=0.737251\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.0997615 mean-accuracy_score=0.638891 mean-roc_auc_score=0.673467\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.0672155 mean-accuracy_score=0.365932 mean-roc_auc_score=0.656573\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.0637507 mean-accuracy_score=0.270449 mean-roc_auc_score=0.688401\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.0748139 mean-accuracy_score=0.512416 mean-roc_auc_score=0.677161\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.0559193 mean-accuracy_score=0.362315 mean-roc_auc_score=0.672145\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.0695083 mean-accuracy_score=0.401062 mean-roc_auc_score=0.630751\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.195316 mean-accuracy_score=0.759369 mean-roc_auc_score=0.773623\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.069914 mean-accuracy_score=0.378511 mean-roc_auc_score=0.659596\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.0661351 mean-accuracy_score=0.364042 mean-roc_auc_score=0.651838\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.0901546 mean-accuracy_score=0.425536 mean-roc_auc_score=0.713332\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.112813 mean-accuracy_score=0.459819 mean-roc_auc_score=0.718471\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.0765768 mean-accuracy_score=0.426253 mean-roc_auc_score=0.662054\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.0969112 mean-accuracy_score=0.505019 mean-roc_auc_score=0.700818\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.205529 mean-accuracy_score=0.794499 mean-roc_auc_score=0.790385\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.170767 mean-accuracy_score=0.749756 mean-roc_auc_score=0.764324\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.185594 mean-accuracy_score=0.838591 mean-roc_auc_score=0.786341\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.246896 mean-accuracy_score=0.817734 mean-roc_auc_score=0.81477\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.140331 mean-accuracy_score=0.665157 mean-roc_auc_score=0.724355\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.264803 mean-accuracy_score=0.882259 mean-roc_auc_score=0.821882\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.268148 mean-accuracy_score=0.908264 mean-roc_auc_score=0.829535\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.255212 mean-accuracy_score=0.840383 mean-roc_auc_score=0.814394\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.22184 mean-accuracy_score=0.828293 mean-roc_auc_score=0.802042\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.245021 mean-accuracy_score=0.94926 mean-roc_auc_score=0.844243\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.270049 mean-accuracy_score=0.955941 mean-roc_auc_score=0.863501\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.140879 mean-accuracy_score=0.955028 mean-roc_auc_score=0.855288\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.140722 mean-accuracy_score=0.951867 mean-roc_auc_score=0.8444\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.145259 mean-accuracy_score=0.94258 mean-roc_auc_score=0.846746\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.0411691 mean-accuracy_score=0.946132 mean-roc_auc_score=0.845385\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.0668908 mean-accuracy_score=0.9548 mean-roc_auc_score=0.858655\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.0389689 mean-accuracy_score=0.942319 mean-roc_auc_score=0.837953\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.0640085 mean-accuracy_score=0.950955 mean-roc_auc_score=0.854003\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.0630939 mean-accuracy_score=0.954181 mean-roc_auc_score=0.866025\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.0606147 mean-accuracy_score=0.955256 mean-roc_auc_score=0.872706\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.0384575 mean-accuracy_score=0.954051 mean-roc_auc_score=0.869685\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.0339601 mean-accuracy_score=0.953692 mean-roc_auc_score=0.863186\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.0286169 mean-accuracy_score=0.954865 mean-roc_auc_score=0.86056\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.0397842 mean-accuracy_score=0.954311 mean-roc_auc_score=0.864893\n",
      "Step 39000 validation: mean-matthews_corrcoef=0.0232057 mean-accuracy_score=0.953366 mean-roc_auc_score=0.860616\n",
      "Step 40000 validation: mean-matthews_corrcoef=0.0239617 mean-accuracy_score=0.953725 mean-roc_auc_score=0.853709\n",
      "Step 41000 validation: mean-matthews_corrcoef=0.0179631 mean-accuracy_score=0.954279 mean-roc_auc_score=0.871902\n",
      "Step 42000 validation: mean-matthews_corrcoef=0.0414864 mean-accuracy_score=0.955191 mean-roc_auc_score=0.873588\n",
      "Step 43000 validation: mean-matthews_corrcoef=0.0237553 mean-accuracy_score=0.954214 mean-roc_auc_score=0.866067\n",
      "Step 44000 validation: mean-matthews_corrcoef=0.0315496 mean-accuracy_score=0.95392 mean-roc_auc_score=0.87017\n",
      "Step 45000 validation: mean-matthews_corrcoef=0.0221766 mean-accuracy_score=0.953823 mean-roc_auc_score=0.867583\n",
      "Step 46000 validation: mean-matthews_corrcoef=0.0572024 mean-accuracy_score=0.955354 mean-roc_auc_score=0.880231\n",
      "Step 47000 validation: mean-matthews_corrcoef=0.0470264 mean-accuracy_score=0.955224 mean-roc_auc_score=0.867585\n",
      "Step 48000 validation: mean-matthews_corrcoef=0 mean-accuracy_score=0.955224 mean-roc_auc_score=0.851565\n",
      "Step 49000 validation: mean-matthews_corrcoef=0.0484722 mean-accuracy_score=0.955289 mean-roc_auc_score=0.854152\n",
      "Step 50000 validation: mean-matthews_corrcoef=0.0265906 mean-accuracy_score=0.954409 mean-roc_auc_score=0.842305\n",
      "Step 51000 validation: mean-matthews_corrcoef=0.0299888 mean-accuracy_score=0.954768 mean-roc_auc_score=0.829958\n",
      "Step 52000 validation: mean-matthews_corrcoef=0.0403105 mean-accuracy_score=0.955094 mean-roc_auc_score=0.796223\n",
      "Step 53000 validation: mean-matthews_corrcoef=0.0389524 mean-accuracy_score=0.955061 mean-roc_auc_score=0.766353\n",
      "Step 54000 validation: mean-matthews_corrcoef=0.0304872 mean-accuracy_score=0.954931 mean-roc_auc_score=0.737185\n",
      "Step 55000 validation: mean-matthews_corrcoef=0.0435366 mean-accuracy_score=0.955224 mean-roc_auc_score=0.720701\n",
      "Step 56000 validation: mean-matthews_corrcoef=0.0338026 mean-accuracy_score=0.955028 mean-roc_auc_score=0.698882\n",
      "Step 57000 validation: mean-matthews_corrcoef=0.03647 mean-accuracy_score=0.955094 mean-roc_auc_score=0.694053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model12 \u001b[38;5;241m=\u001b[39m GraphConvModel(\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      4\u001b[0m                          dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m      5\u001b[0m                          graph_conv_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1024\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m                          tensorboard\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                          model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_home_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/models/gcn_model_12\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m validation\u001b[38;5;241m=\u001b[39mdc\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mValidationCallback(valid_dataset,\n\u001b[1;32m     11\u001b[0m                                         \u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                         metrics,\n\u001b[1;32m     13\u001b[0m                                         save_dir\u001b[38;5;241m=\u001b[39msave_dir12,\n\u001b[1;32m     14\u001b[0m                                         save_on_minimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m hist12 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel12\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/keras_model.py:355\u001b[0m, in \u001b[0;36mKerasModel.fit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    307\u001b[0m         dataset: Dataset,\n\u001b[1;32m    308\u001b[0m         nb_epoch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m         callbacks: Union[Callable, List[Callable]] \u001b[38;5;241m=\u001b[39m [],\n\u001b[1;32m    316\u001b[0m         all_losses: Optional[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    317\u001b[0m   \u001b[38;5;124;03m\"\"\"Train this model on a dataset.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m  Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m  The average loss over the most recent checkpoint interval\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m \"\"\"\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_checkpoints_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/keras_model.py:432\u001b[0m, in \u001b[0;36mKerasModel.fit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    428\u001b[0m time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Main training loop.\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m    433\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_training_ops(batch)\n\u001b[1;32m    434\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m restore:\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/graph_models.py:1007\u001b[0m, in \u001b[0;36mGraphConvModel.default_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_b \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1005\u001b[0m   y_b \u001b[38;5;241m=\u001b[39m to_one_hot(y_b\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes)\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m   1006\u001b[0m       \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tasks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes)\n\u001b[0;32m-> 1007\u001b[0m multiConvMol \u001b[38;5;241m=\u001b[39m \u001b[43mConvMol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magglomerate_mols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1009\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1010\u001b[0m     multiConvMol\u001b[38;5;241m.\u001b[39mget_atom_features(), multiConvMol\u001b[38;5;241m.\u001b[39mdeg_slice,\n\u001b[1;32m   1011\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(multiConvMol\u001b[38;5;241m.\u001b[39mmembership), n_samples\n\u001b[1;32m   1012\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/feat/mol_graphs.py:329\u001b[0m, in \u001b[0;36mConvMol.agglomerate_mols\u001b[0;34m(mols, max_deg, min_deg)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nbr_list\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    328\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m nbr_list\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mint32:\n\u001b[0;32m--> 329\u001b[0m     final_id \u001b[38;5;241m=\u001b[39m \u001b[43mmol_atom_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmol_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnbr_list\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    330\u001b[0m     deg_adj_lists[deg_id][row:(row \u001b[38;5;241m+\u001b[39m nbr_list\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])] \u001b[38;5;241m=\u001b[39m final_id\n\u001b[1;32m    331\u001b[0m     row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nbr_list\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_dir12=f'{get_home_path()}/models/gcn_model_12/callbacks'\n",
    "\n",
    "model12 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.4,\n",
    "                         graph_conv_layers=[512, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         model_dir=f'{get_home_path()}/models/gcn_model_12')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir12,\n",
    "                                        save_on_minimum=False)\n",
    "\n",
    "hist12 = model12.fit(train_dataset, nb_epoch=100, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f0eb914-87cb-4106-a465-3328914b92a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist12' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_model(model12, \u001b[43mhist12\u001b[49m, save_dir12)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist12' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(model12, hist12, save_dir12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f92cc-59f5-4a49-b978-c6d63adc5d37",
   "metadata": {},
   "source": [
    "#### model 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f55a5257-f169-4529-8df2-82c22ff26e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_14:0\", shape=(580,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_13:0\", shape=(580, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_17:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_16:0\", shape=(3312, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_20:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_19:0\", shape=(2892, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_23:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_22:0\", shape=(208, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_11:0\", shape=(580,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_10:0\", shape=(580, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_13:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_12:0\", shape=(3312, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_15:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_14:0\", shape=(2892, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_17:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_16:0\", shape=(208, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_14:0\", shape=(580,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_13:0\", shape=(580, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_17:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_16:0\", shape=(3312, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_20:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_19:0\", shape=(2892, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_23:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_22:0\", shape=(208, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_11:0\", shape=(580,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_10:0\", shape=(580, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_13:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_12:0\", shape=(3312, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_15:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_14:0\", shape=(2892, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_17:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_16:0\", shape=(208, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_14:0\", shape=(580,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_13:0\", shape=(580, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_17:0\", shape=(3312,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_16:0\", shape=(3312, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_20:0\", shape=(2892,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_19:0\", shape=(2892, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_23:0\", shape=(208,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_22:0\", shape=(208, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_14:0\", shape=(521,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_13:0\", shape=(521, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_17:0\", shape=(3356,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_16:0\", shape=(3356, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_20:0\", shape=(2823,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_19:0\", shape=(2823, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_23:0\", shape=(128,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_22:0\", shape=(128, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_11:0\", shape=(521,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_10:0\", shape=(521, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_13:0\", shape=(3356,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_12:0\", shape=(3356, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_15:0\", shape=(2823,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_14:0\", shape=(2823, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_17:0\", shape=(128,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_16:0\", shape=(128, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_14:0\", shape=(521,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_13:0\", shape=(521, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_17:0\", shape=(3356,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_16:0\", shape=(3356, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_20:0\", shape=(2823,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_19:0\", shape=(2823, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_23:0\", shape=(128,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_22:0\", shape=(128, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_11:0\", shape=(521,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_10:0\", shape=(521, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_13:0\", shape=(3356,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_12:0\", shape=(3356, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_15:0\", shape=(2823,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_14:0\", shape=(2823, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_17:0\", shape=(128,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_16:0\", shape=(128, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_14:0\", shape=(521,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_13:0\", shape=(521, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_17:0\", shape=(3356,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_16:0\", shape=(3356, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_20:0\", shape=(2823,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_19:0\", shape=(2823, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_23:0\", shape=(128,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_22:0\", shape=(128, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_10/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_conv_9/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_4/graph_pool_8/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.108458 mean-accuracy_score=0.95555 mean-roc_auc_score=0.817729\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.148704 mean-accuracy_score=0.95581 mean-roc_auc_score=0.839141\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.250886 mean-accuracy_score=0.957179 mean-roc_auc_score=0.857552\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.209686 mean-accuracy_score=0.956984 mean-roc_auc_score=0.863411\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.284893 mean-accuracy_score=0.957896 mean-roc_auc_score=0.859309\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.234004 mean-accuracy_score=0.957179 mean-roc_auc_score=0.869292\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.284201 mean-accuracy_score=0.95845 mean-roc_auc_score=0.870584\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.368751 mean-accuracy_score=0.959688 mean-roc_auc_score=0.872785\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.296611 mean-accuracy_score=0.959102 mean-roc_auc_score=0.875513\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.340635 mean-accuracy_score=0.959851 mean-roc_auc_score=0.882608\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.424413 mean-accuracy_score=0.959982 mean-roc_auc_score=0.885156\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.403418 mean-accuracy_score=0.959232 mean-roc_auc_score=0.883868\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.34408 mean-accuracy_score=0.959623 mean-roc_auc_score=0.885397\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.434026 mean-accuracy_score=0.959884 mean-roc_auc_score=0.894719\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.374164 mean-accuracy_score=0.961057 mean-roc_auc_score=0.891758\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.398951 mean-accuracy_score=0.961611 mean-roc_auc_score=0.892642\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.367116 mean-accuracy_score=0.960796 mean-roc_auc_score=0.895776\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.383891 mean-accuracy_score=0.961188 mean-roc_auc_score=0.888168\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.415684 mean-accuracy_score=0.96223 mean-roc_auc_score=0.903301\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.455935 mean-accuracy_score=0.962621 mean-roc_auc_score=0.901066\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.435117 mean-accuracy_score=0.962524 mean-roc_auc_score=0.896301\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.446102 mean-accuracy_score=0.962361 mean-roc_auc_score=0.898043\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.452831 mean-accuracy_score=0.961904 mean-roc_auc_score=0.896153\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.455157 mean-accuracy_score=0.962752 mean-roc_auc_score=0.899657\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.352273 mean-accuracy_score=0.960796 mean-roc_auc_score=0.90067\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.457149 mean-accuracy_score=0.96311 mean-roc_auc_score=0.902404\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.482813 mean-accuracy_score=0.961937 mean-roc_auc_score=0.902741\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.462949 mean-accuracy_score=0.9621 mean-roc_auc_score=0.902666\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.472007 mean-accuracy_score=0.963566 mean-roc_auc_score=0.902017\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.480314 mean-accuracy_score=0.963371 mean-roc_auc_score=0.901625\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.482213 mean-accuracy_score=0.962198 mean-roc_auc_score=0.905652\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.485276 mean-accuracy_score=0.961611 mean-roc_auc_score=0.90441\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.431309 mean-accuracy_score=0.962915 mean-roc_auc_score=0.901597\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.448559 mean-accuracy_score=0.962654 mean-roc_auc_score=0.90055\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.489524 mean-accuracy_score=0.961481 mean-roc_auc_score=0.902034\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.47499 mean-accuracy_score=0.9621 mean-roc_auc_score=0.902144\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.481064 mean-accuracy_score=0.959754 mean-roc_auc_score=0.899842\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.464674 mean-accuracy_score=0.96197 mean-roc_auc_score=0.900754\n",
      "Step 39000 validation: mean-matthews_corrcoef=0.483942 mean-accuracy_score=0.964088 mean-roc_auc_score=0.903771\n",
      "Step 40000 validation: mean-matthews_corrcoef=0.470542 mean-accuracy_score=0.963045 mean-roc_auc_score=0.900189\n",
      "Step 41000 validation: mean-matthews_corrcoef=0.481861 mean-accuracy_score=0.964186 mean-roc_auc_score=0.900303\n",
      "Step 42000 validation: mean-matthews_corrcoef=0.486643 mean-accuracy_score=0.962067 mean-roc_auc_score=0.90496\n",
      "Step 43000 validation: mean-matthews_corrcoef=0.477839 mean-accuracy_score=0.961904 mean-roc_auc_score=0.903873\n",
      "Step 44000 validation: mean-matthews_corrcoef=0.515734 mean-accuracy_score=0.959102 mean-roc_auc_score=0.903937\n",
      "Step 45000 validation: mean-matthews_corrcoef=0.483543 mean-accuracy_score=0.96285 mean-roc_auc_score=0.900987\n",
      "Step 46000 validation: mean-matthews_corrcoef=0.493181 mean-accuracy_score=0.96034 mean-roc_auc_score=0.899039\n",
      "Step 47000 validation: mean-matthews_corrcoef=0.489239 mean-accuracy_score=0.961644 mean-roc_auc_score=0.901331\n",
      "Step 48000 validation: mean-matthews_corrcoef=0.51199 mean-accuracy_score=0.96197 mean-roc_auc_score=0.904459\n",
      "Step 49000 validation: mean-matthews_corrcoef=0.491126 mean-accuracy_score=0.961025 mean-roc_auc_score=0.897295\n",
      "Step 50000 validation: mean-matthews_corrcoef=0.503093 mean-accuracy_score=0.96008 mean-roc_auc_score=0.90334\n",
      "Step 51000 validation: mean-matthews_corrcoef=0.504402 mean-accuracy_score=0.960438 mean-roc_auc_score=0.900989\n",
      "Step 52000 validation: mean-matthews_corrcoef=0.472477 mean-accuracy_score=0.963078 mean-roc_auc_score=0.898688\n",
      "Step 53000 validation: mean-matthews_corrcoef=0.477937 mean-accuracy_score=0.963175 mean-roc_auc_score=0.89356\n",
      "Step 54000 validation: mean-matthews_corrcoef=0.477423 mean-accuracy_score=0.962556 mean-roc_auc_score=0.90033\n",
      "Step 55000 validation: mean-matthews_corrcoef=0.490389 mean-accuracy_score=0.955843 mean-roc_auc_score=0.901068\n",
      "Step 56000 validation: mean-matthews_corrcoef=0.508203 mean-accuracy_score=0.959949 mean-roc_auc_score=0.901972\n",
      "Step 57000 validation: mean-matthews_corrcoef=0.503267 mean-accuracy_score=0.958809 mean-roc_auc_score=0.901631\n",
      "Step 58000 validation: mean-matthews_corrcoef=0.498567 mean-accuracy_score=0.959167 mean-roc_auc_score=0.899197\n",
      "Step 59000 validation: mean-matthews_corrcoef=0.4714 mean-accuracy_score=0.95832 mean-roc_auc_score=0.895477\n",
      "Step 60000 validation: mean-matthews_corrcoef=0.477861 mean-accuracy_score=0.957603 mean-roc_auc_score=0.895736\n",
      "Step 61000 validation: mean-matthews_corrcoef=0.479363 mean-accuracy_score=0.961122 mean-roc_auc_score=0.895041\n",
      "Step 62000 validation: mean-matthews_corrcoef=0.488567 mean-accuracy_score=0.959917 mean-roc_auc_score=0.897911\n",
      "Step 63000 validation: mean-matthews_corrcoef=0.491918 mean-accuracy_score=0.960829 mean-roc_auc_score=0.898055\n",
      "Step 64000 validation: mean-matthews_corrcoef=0.49834 mean-accuracy_score=0.961253 mean-roc_auc_score=0.897525\n",
      "Step 65000 validation: mean-matthews_corrcoef=0.491817 mean-accuracy_score=0.960731 mean-roc_auc_score=0.898844\n",
      "Step 66000 validation: mean-matthews_corrcoef=0.487559 mean-accuracy_score=0.962133 mean-roc_auc_score=0.895258\n",
      "Step 67000 validation: mean-matthews_corrcoef=0.477613 mean-accuracy_score=0.961807 mean-roc_auc_score=0.893003\n",
      "Step 68000 validation: mean-matthews_corrcoef=0.477268 mean-accuracy_score=0.960503 mean-roc_auc_score=0.895378\n",
      "Step 69000 validation: mean-matthews_corrcoef=0.476806 mean-accuracy_score=0.961644 mean-roc_auc_score=0.899067\n",
      "Step 70000 validation: mean-matthews_corrcoef=0.487919 mean-accuracy_score=0.960796 mean-roc_auc_score=0.891984\n",
      "Step 71000 validation: mean-matthews_corrcoef=0.490668 mean-accuracy_score=0.962296 mean-roc_auc_score=0.897359\n",
      "Step 72000 validation: mean-matthews_corrcoef=0.47866 mean-accuracy_score=0.958678 mean-roc_auc_score=0.891445\n",
      "Step 73000 validation: mean-matthews_corrcoef=0.496849 mean-accuracy_score=0.961025 mean-roc_auc_score=0.898796\n",
      "Step 74000 validation: mean-matthews_corrcoef=0.461043 mean-accuracy_score=0.961122 mean-roc_auc_score=0.894623\n",
      "Step 75000 validation: mean-matthews_corrcoef=0.466613 mean-accuracy_score=0.961644 mean-roc_auc_score=0.893592\n",
      "Step 76000 validation: mean-matthews_corrcoef=0.489312 mean-accuracy_score=0.960014 mean-roc_auc_score=0.896476\n",
      "Step 77000 validation: mean-matthews_corrcoef=0.496219 mean-accuracy_score=0.959884 mean-roc_auc_score=0.901295\n",
      "Step 78000 validation: mean-matthews_corrcoef=0.470969 mean-accuracy_score=0.959363 mean-roc_auc_score=0.89257\n",
      "Step 79000 validation: mean-matthews_corrcoef=0.475485 mean-accuracy_score=0.960829 mean-roc_auc_score=0.894511\n",
      "Step 80000 validation: mean-matthews_corrcoef=0.488778 mean-accuracy_score=0.96008 mean-roc_auc_score=0.897051\n",
      "Step 81000 validation: mean-matthews_corrcoef=0.488789 mean-accuracy_score=0.958515 mean-roc_auc_score=0.897193\n",
      "Step 82000 validation: mean-matthews_corrcoef=0.501763 mean-accuracy_score=0.959232 mean-roc_auc_score=0.894923\n",
      "Step 83000 validation: mean-matthews_corrcoef=0.488757 mean-accuracy_score=0.960731 mean-roc_auc_score=0.897536\n",
      "Step 84000 validation: mean-matthews_corrcoef=0.498377 mean-accuracy_score=0.958646 mean-roc_auc_score=0.900052\n",
      "Step 85000 validation: mean-matthews_corrcoef=0.485217 mean-accuracy_score=0.960503 mean-roc_auc_score=0.89584\n",
      "Step 86000 validation: mean-matthews_corrcoef=0.473882 mean-accuracy_score=0.961318 mean-roc_auc_score=0.896189\n",
      "Step 87000 validation: mean-matthews_corrcoef=0.482671 mean-accuracy_score=0.956821 mean-roc_auc_score=0.893686\n",
      "Step 88000 validation: mean-matthews_corrcoef=0.490977 mean-accuracy_score=0.962035 mean-roc_auc_score=0.896793\n",
      "Step 89000 validation: mean-matthews_corrcoef=0.494876 mean-accuracy_score=0.961155 mean-roc_auc_score=0.900871\n",
      "Step 90000 validation: mean-matthews_corrcoef=0.451469 mean-accuracy_score=0.958874 mean-roc_auc_score=0.892974\n",
      "Step 91000 validation: mean-matthews_corrcoef=0.477523 mean-accuracy_score=0.959102 mean-roc_auc_score=0.896642\n",
      "Step 92000 validation: mean-matthews_corrcoef=0.482084 mean-accuracy_score=0.959428 mean-roc_auc_score=0.896895\n",
      "Step 93000 validation: mean-matthews_corrcoef=0.489133 mean-accuracy_score=0.961709 mean-roc_auc_score=0.898843\n",
      "Step 94000 validation: mean-matthews_corrcoef=0.473809 mean-accuracy_score=0.956951 mean-roc_auc_score=0.892884\n",
      "Step 95000 validation: mean-matthews_corrcoef=0.470372 mean-accuracy_score=0.960047 mean-roc_auc_score=0.896082\n"
     ]
    }
   ],
   "source": [
    "save_dir13=f'{get_home_path()}/models/gcn_model_13/callbacks'\n",
    "\n",
    "model13 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[64, 256, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         model_dir=f'{get_home_path()}/models/gcn_model_13')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir13,\n",
    "                                        save_on_minimum=False)\n",
    "\n",
    "hist13 = model13.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b4c2196-99fd-4df4-8455-27f890b89703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.909140121876442, 'mean-accuracy_score': 0.9923948641910938, 'mean-roc_auc_score': 0.998363235694375}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.4833174530782624, 'mean-accuracy_score': 0.9604379847487453, 'mean-roc_auc_score': 0.8920752781498891}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.4723276007506134, 'mean-accuracy_score': 0.9602437514256852, 'mean-roc_auc_score': 0.8915162808121608}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.5157338258031209, 'mean-accuracy_score': 0.9591018705598644, 'mean-roc_auc_score': 0.9039374184599518}\n",
      "Loss? = 0.024915108680725096\n",
      "[[28703   609]\n",
      " [  646   728]]\n",
      "Specificity = 0.9792\n",
      "FPR = 0.0208\n",
      "Recall/TPR = 0.5298\n",
      "Precision = 0.5445\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model13, hist13, save_dir13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8e6d38d-4252-4f36-8c59-43f5bd27bc41",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred13 = [x.flatten() for x in model13.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f99e97c3-3f92-4c44-8b83-7d3ae0859a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values  pred_probs\n",
       "0          0.0    0.007747\n",
       "1          0.0    0.008081\n",
       "2          0.0    0.000207\n",
       "3          0.0    0.000060\n",
       "4          0.0    0.594337"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred13_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred13])})\n",
    "\n",
    "pred13_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfc7c4d1-73b8-433f-8ccf-7960ec5e865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred13_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that Outcome = 1')\n",
    "plt.legend()\n",
    "plt.ylim(0, 2000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5022b-9f6e-4f1b-861f-aed2a8f58540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ca17cc-5a76-46c0-bfeb-c31789b3987a",
   "metadata": {},
   "source": [
    "#### model 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bb60543-3d66-4af3-a3a4-8e8f2ee1c814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_13:0\", shape=(538, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_16:0\", shape=(3182, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_19:0\", shape=(2850, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_22:0\", shape=(136, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_10:0\", shape=(538, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_13:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_12:0\", shape=(3182, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_15:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_14:0\", shape=(2850, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_16:0\", shape=(136, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_13:0\", shape=(538, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_16:0\", shape=(3182, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_19:0\", shape=(2850, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_22:0\", shape=(136, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_10:0\", shape=(538, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_13:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_12:0\", shape=(3182, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_15:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_14:0\", shape=(2850, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_16:0\", shape=(136, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(538, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(3182, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(2850, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(136, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(538, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(3182, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(2850, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(538, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(3182, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(2850, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_13:0\", shape=(527, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_16:0\", shape=(3348, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_19:0\", shape=(2913, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_22:0\", shape=(172, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_10:0\", shape=(527, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_13:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_12:0\", shape=(3348, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_15:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_14:0\", shape=(2913, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_17:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_16:0\", shape=(172, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_13:0\", shape=(527, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_16:0\", shape=(3348, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_19:0\", shape=(2913, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_22:0\", shape=(172, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_10:0\", shape=(527, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_13:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_12:0\", shape=(3348, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_15:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_14:0\", shape=(2913, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_17:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_16:0\", shape=(172, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(527, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(3348, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(2913, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(172, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(527, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(3348, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(2913, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(172, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(527, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(3348, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(2913, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(172, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_10:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_12:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_14:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.112536 mean-accuracy_score=0.955224 mean-roc_auc_score=0.822666\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.176622 mean-accuracy_score=0.955778 mean-roc_auc_score=0.836623\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.134022 mean-accuracy_score=0.955713 mean-roc_auc_score=0.846425\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.259415 mean-accuracy_score=0.957049 mean-roc_auc_score=0.858792\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.344481 mean-accuracy_score=0.95555 mean-roc_auc_score=0.8618\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.290977 mean-accuracy_score=0.957538 mean-roc_auc_score=0.86468\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.260783 mean-accuracy_score=0.957407 mean-roc_auc_score=0.866574\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.319455 mean-accuracy_score=0.959134 mean-roc_auc_score=0.871015\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.355358 mean-accuracy_score=0.95933 mean-roc_auc_score=0.878626\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.333848 mean-accuracy_score=0.959591 mean-roc_auc_score=0.87588\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.36295 mean-accuracy_score=0.957635 mean-roc_auc_score=0.880609\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.316818 mean-accuracy_score=0.9592 mean-roc_auc_score=0.883506\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.402072 mean-accuracy_score=0.959297 mean-roc_auc_score=0.885823\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.393485 mean-accuracy_score=0.958678 mean-roc_auc_score=0.866919\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.359462 mean-accuracy_score=0.960308 mean-roc_auc_score=0.892221\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.336249 mean-accuracy_score=0.960014 mean-roc_auc_score=0.890037\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.400082 mean-accuracy_score=0.960112 mean-roc_auc_score=0.89406\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.368983 mean-accuracy_score=0.960634 mean-roc_auc_score=0.887788\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.431025 mean-accuracy_score=0.961579 mean-roc_auc_score=0.896161\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.314499 mean-accuracy_score=0.95946 mean-roc_auc_score=0.893867\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.443537 mean-accuracy_score=0.960112 mean-roc_auc_score=0.895798\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.44845 mean-accuracy_score=0.962752 mean-roc_auc_score=0.89728\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.381718 mean-accuracy_score=0.961025 mean-roc_auc_score=0.895201\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.387747 mean-accuracy_score=0.961285 mean-roc_auc_score=0.898178\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.44846 mean-accuracy_score=0.961481 mean-roc_auc_score=0.903669\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.442378 mean-accuracy_score=0.962035 mean-roc_auc_score=0.898359\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.447175 mean-accuracy_score=0.962133 mean-roc_auc_score=0.900597\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.439863 mean-accuracy_score=0.961872 mean-roc_auc_score=0.896552\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.437351 mean-accuracy_score=0.963306 mean-roc_auc_score=0.89533\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.44669 mean-accuracy_score=0.963012 mean-roc_auc_score=0.901664\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.474266 mean-accuracy_score=0.960308 mean-roc_auc_score=0.902669\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.43983 mean-accuracy_score=0.962491 mean-roc_auc_score=0.897575\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.495475 mean-accuracy_score=0.961188 mean-roc_auc_score=0.900409\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.436186 mean-accuracy_score=0.9592 mean-roc_auc_score=0.895784\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.508418 mean-accuracy_score=0.958613 mean-roc_auc_score=0.903977\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.464907 mean-accuracy_score=0.96386 mean-roc_auc_score=0.90144\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.458283 mean-accuracy_score=0.962687 mean-roc_auc_score=0.897374\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.475293 mean-accuracy_score=0.958059 mean-roc_auc_score=0.898271\n",
      "Step 39000 validation: mean-matthews_corrcoef=0.50285 mean-accuracy_score=0.960764 mean-roc_auc_score=0.90076\n",
      "Step 40000 validation: mean-matthews_corrcoef=0.471107 mean-accuracy_score=0.963241 mean-roc_auc_score=0.903566\n",
      "Step 41000 validation: mean-matthews_corrcoef=0.487425 mean-accuracy_score=0.963664 mean-roc_auc_score=0.905235\n",
      "Step 42000 validation: mean-matthews_corrcoef=0.482091 mean-accuracy_score=0.964512 mean-roc_auc_score=0.904024\n",
      "Step 43000 validation: mean-matthews_corrcoef=0.473338 mean-accuracy_score=0.963469 mean-roc_auc_score=0.89711\n",
      "Step 44000 validation: mean-matthews_corrcoef=0.473339 mean-accuracy_score=0.960862 mean-roc_auc_score=0.897892\n",
      "Step 45000 validation: mean-matthews_corrcoef=0.457129 mean-accuracy_score=0.962524 mean-roc_auc_score=0.894239\n",
      "Step 46000 validation: mean-matthews_corrcoef=0.489925 mean-accuracy_score=0.963012 mean-roc_auc_score=0.899283\n",
      "Step 47000 validation: mean-matthews_corrcoef=0.476511 mean-accuracy_score=0.961611 mean-roc_auc_score=0.897249\n",
      "Step 48000 validation: mean-matthews_corrcoef=0.458511 mean-accuracy_score=0.963762 mean-roc_auc_score=0.89858\n",
      "Step 49000 validation: mean-matthews_corrcoef=0.459978 mean-accuracy_score=0.962752 mean-roc_auc_score=0.894518\n",
      "Step 50000 validation: mean-matthews_corrcoef=0.499755 mean-accuracy_score=0.963045 mean-roc_auc_score=0.897283\n",
      "Step 51000 validation: mean-matthews_corrcoef=0.477 mean-accuracy_score=0.960471 mean-roc_auc_score=0.897136\n",
      "Step 52000 validation: mean-matthews_corrcoef=0.493116 mean-accuracy_score=0.962458 mean-roc_auc_score=0.900245\n",
      "Step 53000 validation: mean-matthews_corrcoef=0.491742 mean-accuracy_score=0.961742 mean-roc_auc_score=0.900447\n",
      "Step 54000 validation: mean-matthews_corrcoef=0.499678 mean-accuracy_score=0.963273 mean-roc_auc_score=0.901108\n",
      "Step 55000 validation: mean-matthews_corrcoef=0.482573 mean-accuracy_score=0.962165 mean-roc_auc_score=0.897047\n",
      "Step 56000 validation: mean-matthews_corrcoef=0.491976 mean-accuracy_score=0.962296 mean-roc_auc_score=0.899706\n",
      "Step 57000 validation: mean-matthews_corrcoef=0.48558 mean-accuracy_score=0.960112 mean-roc_auc_score=0.893463\n",
      "Step 58000 validation: mean-matthews_corrcoef=0.494267 mean-accuracy_score=0.961448 mean-roc_auc_score=0.898106\n",
      "Step 59000 validation: mean-matthews_corrcoef=0.464151 mean-accuracy_score=0.959721 mean-roc_auc_score=0.894351\n",
      "Step 60000 validation: mean-matthews_corrcoef=0.481163 mean-accuracy_score=0.961253 mean-roc_auc_score=0.896816\n",
      "Step 61000 validation: mean-matthews_corrcoef=0.486146 mean-accuracy_score=0.959917 mean-roc_auc_score=0.895938\n",
      "Step 62000 validation: mean-matthews_corrcoef=0.499164 mean-accuracy_score=0.960764 mean-roc_auc_score=0.900676\n",
      "Step 63000 validation: mean-matthews_corrcoef=0.475715 mean-accuracy_score=0.961057 mean-roc_auc_score=0.89469\n",
      "Step 64000 validation: mean-matthews_corrcoef=0.478832 mean-accuracy_score=0.959917 mean-roc_auc_score=0.893894\n",
      "Step 65000 validation: mean-matthews_corrcoef=0.469841 mean-accuracy_score=0.959982 mean-roc_auc_score=0.89776\n",
      "Step 66000 validation: mean-matthews_corrcoef=0.469947 mean-accuracy_score=0.963078 mean-roc_auc_score=0.899461\n",
      "Step 67000 validation: mean-matthews_corrcoef=0.49606 mean-accuracy_score=0.959297 mean-roc_auc_score=0.899315\n",
      "Step 68000 validation: mean-matthews_corrcoef=0.491053 mean-accuracy_score=0.961057 mean-roc_auc_score=0.896022\n",
      "Step 69000 validation: mean-matthews_corrcoef=0.475645 mean-accuracy_score=0.960601 mean-roc_auc_score=0.895819\n",
      "Step 70000 validation: mean-matthews_corrcoef=0.475533 mean-accuracy_score=0.961155 mean-roc_auc_score=0.893148\n",
      "Step 71000 validation: mean-matthews_corrcoef=0.500678 mean-accuracy_score=0.962654 mean-roc_auc_score=0.898141\n",
      "Step 72000 validation: mean-matthews_corrcoef=0.477448 mean-accuracy_score=0.956234 mean-roc_auc_score=0.891704\n",
      "Step 73000 validation: mean-matthews_corrcoef=0.491181 mean-accuracy_score=0.962133 mean-roc_auc_score=0.895636\n",
      "Step 74000 validation: mean-matthews_corrcoef=0.501654 mean-accuracy_score=0.96034 mean-roc_auc_score=0.89687\n",
      "Step 75000 validation: mean-matthews_corrcoef=0.478015 mean-accuracy_score=0.962067 mean-roc_auc_score=0.898491\n",
      "Step 76000 validation: mean-matthews_corrcoef=0.48961 mean-accuracy_score=0.959688 mean-roc_auc_score=0.896082\n",
      "Step 77000 validation: mean-matthews_corrcoef=0.482536 mean-accuracy_score=0.956071 mean-roc_auc_score=0.897846\n",
      "Step 78000 validation: mean-matthews_corrcoef=0.493636 mean-accuracy_score=0.9592 mean-roc_auc_score=0.900264\n",
      "Step 79000 validation: mean-matthews_corrcoef=0.509029 mean-accuracy_score=0.96034 mean-roc_auc_score=0.902962\n",
      "Step 80000 validation: mean-matthews_corrcoef=0.483055 mean-accuracy_score=0.960275 mean-roc_auc_score=0.892753\n",
      "Step 81000 validation: mean-matthews_corrcoef=0.480519 mean-accuracy_score=0.957147 mean-roc_auc_score=0.894714\n",
      "Step 82000 validation: mean-matthews_corrcoef=0.485501 mean-accuracy_score=0.959037 mean-roc_auc_score=0.895914\n",
      "Step 83000 validation: mean-matthews_corrcoef=0.480539 mean-accuracy_score=0.959363 mean-roc_auc_score=0.896903\n",
      "Step 84000 validation: mean-matthews_corrcoef=0.474963 mean-accuracy_score=0.961285 mean-roc_auc_score=0.894588\n",
      "Step 85000 validation: mean-matthews_corrcoef=0.489454 mean-accuracy_score=0.957635 mean-roc_auc_score=0.897069\n",
      "Step 86000 validation: mean-matthews_corrcoef=0.478193 mean-accuracy_score=0.958515 mean-roc_auc_score=0.893235\n",
      "Step 87000 validation: mean-matthews_corrcoef=0.48838 mean-accuracy_score=0.958255 mean-roc_auc_score=0.895427\n",
      "Step 88000 validation: mean-matthews_corrcoef=0.466928 mean-accuracy_score=0.958548 mean-roc_auc_score=0.890533\n",
      "Step 89000 validation: mean-matthews_corrcoef=0.485727 mean-accuracy_score=0.96135 mean-roc_auc_score=0.89473\n",
      "Step 90000 validation: mean-matthews_corrcoef=0.479759 mean-accuracy_score=0.96021 mean-roc_auc_score=0.895916\n",
      "Step 91000 validation: mean-matthews_corrcoef=0.468692 mean-accuracy_score=0.959884 mean-roc_auc_score=0.893399\n",
      "Step 92000 validation: mean-matthews_corrcoef=0.472511 mean-accuracy_score=0.960601 mean-roc_auc_score=0.892609\n",
      "Step 93000 validation: mean-matthews_corrcoef=0.47773 mean-accuracy_score=0.958939 mean-roc_auc_score=0.893732\n",
      "Step 94000 validation: mean-matthews_corrcoef=0.485662 mean-accuracy_score=0.959297 mean-roc_auc_score=0.893515\n",
      "Step 95000 validation: mean-matthews_corrcoef=0.492238 mean-accuracy_score=0.960699 mean-roc_auc_score=0.895709\n"
     ]
    }
   ],
   "source": [
    "save_dir14=f'{get_home_path()}/models/gcn_model_14/callbacks'\n",
    "\n",
    "model14 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[64, 128, 256, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         model_dir=f'{get_home_path()}/models/gcn_model_14')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir14,\n",
    "                                        save_on_minimum=False)\n",
    "\n",
    "hist14 = model14.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3b2979c-bdac-466b-ba18-c2c6a8b006b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.9070435223658783, 'mean-accuracy_score': 0.992325615498672, 'mean-roc_auc_score': 0.9984876464016141}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.47465749458314266, 'mean-accuracy_score': 0.9614808055790914, 'mean-roc_auc_score': 0.8894597581984992}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.44472971937887906, 'mean-accuracy_score': 0.9596245967347736, 'mean-roc_auc_score': 0.8910045500476188}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.5090293891953639, 'mean-accuracy_score': 0.9603402202959004, 'mean-roc_auc_score': 0.9029619360428067}\n",
      "Loss? = 0.024895613193511964\n",
      "[[28787   525]\n",
      " [  692   682]]\n",
      "Specificity = 0.9821\n",
      "FPR = 0.0179\n",
      "Recall/TPR = 0.4964\n",
      "Precision = 0.565\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model14, hist14, save_dir14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4b236a8-e6a4-47b3-8a5f-d899b134575d",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred14 = [x.flatten() for x in model14.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04b7d137-81c5-4474-a219-be9671feed32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.075752e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.326331e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.694275e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.569930e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.442868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values    pred_probs\n",
       "0          0.0  1.075752e-04\n",
       "1          0.0  6.326331e-07\n",
       "2          0.0  1.694275e-09\n",
       "3          0.0  9.569930e-06\n",
       "4          0.0  3.442868e-01"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred14_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred14])})\n",
    "\n",
    "pred14_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c02f8ed6-73e9-4ce3-80f9-80e0dac09183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred14_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that Outcome = 1')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1800);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3740ab42-9a11-4772-949f-b7643d8c7330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_create_jax_optimizer',\n",
       " '_create_pytorch_optimizer',\n",
       " '_create_tf_optimizer',\n",
       " 'beta1',\n",
       " 'beta2',\n",
       " 'epsilon',\n",
       " 'learning_rate']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model14.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "006b6a8d-a055-48de-b1d8-7311a48e2eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_built',\n",
       " '_checkpoint',\n",
       " '_compute_model',\n",
       " '_create_assignment_map',\n",
       " '_create_gradient_fn',\n",
       " '_create_inputs',\n",
       " '_create_training_ops',\n",
       " '_create_value_map',\n",
       " '_ensure_built',\n",
       " '_global_step',\n",
       " '_gradient_fn_for_vars',\n",
       " '_input_dtypes',\n",
       " '_input_shapes',\n",
       " '_inputs_built',\n",
       " '_label_dtypes',\n",
       " '_log_scalar_to_tensorboard',\n",
       " '_loss_fn',\n",
       " '_loss_outputs',\n",
       " '_other_outputs',\n",
       " '_output_functions',\n",
       " '_predict',\n",
       " '_prediction_outputs',\n",
       " '_prepare_batch',\n",
       " '_summary_writer',\n",
       " '_tf_optimizer',\n",
       " '_training_ops_built',\n",
       " '_variance_outputs',\n",
       " '_weights_dtypes',\n",
       " 'batch_size',\n",
       " 'compute_saliency',\n",
       " 'default_generator',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'fit_on_batch',\n",
       " 'get_checkpoints',\n",
       " 'get_global_step',\n",
       " 'get_model_filename',\n",
       " 'get_num_tasks',\n",
       " 'get_params_filename',\n",
       " 'get_task_type',\n",
       " 'learning_rate',\n",
       " 'load_from_pretrained',\n",
       " 'log_frequency',\n",
       " 'loss',\n",
       " 'mode',\n",
       " 'model',\n",
       " 'model_class',\n",
       " 'model_dir',\n",
       " 'model_dir_is_temp',\n",
       " 'n_classes',\n",
       " 'n_tasks',\n",
       " 'optimizer',\n",
       " 'output_types',\n",
       " 'predict',\n",
       " 'predict_embedding',\n",
       " 'predict_on_batch',\n",
       " 'predict_on_generator',\n",
       " 'predict_uncertainty',\n",
       " 'predict_uncertainty_on_batch',\n",
       " 'reload',\n",
       " 'restore',\n",
       " 'save',\n",
       " 'save_checkpoint',\n",
       " 'tensorboard',\n",
       " 'uncertainty',\n",
       " 'wandb',\n",
       " 'wandb_logger']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1e5a895-2a99-44b4-961a-c620e6def312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024895613193511964"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ddc82a7-5f07-4cff-9f8a-8cc0771f0b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(model14.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9cc4e32a-a2aa-47c6-856f-1f272f155108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 103000 validation: mean-matthews_corrcoef=0.485382 mean-accuracy_score=0.961546 mean-roc_auc_score=0.893409\n",
      "Step 104000 validation: mean-matthews_corrcoef=0.499456 mean-accuracy_score=0.961513 mean-roc_auc_score=0.896373\n",
      "Step 105000 validation: mean-matthews_corrcoef=0.480187 mean-accuracy_score=0.959363 mean-roc_auc_score=0.89578\n",
      "Step 106000 validation: mean-matthews_corrcoef=0.492008 mean-accuracy_score=0.958874 mean-roc_auc_score=0.896586\n",
      "Step 107000 validation: mean-matthews_corrcoef=0.483853 mean-accuracy_score=0.961904 mean-roc_auc_score=0.895791\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist14_2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel14\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/keras_model.py:355\u001b[0m, in \u001b[0;36mKerasModel.fit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    307\u001b[0m         dataset: Dataset,\n\u001b[1;32m    308\u001b[0m         nb_epoch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m         callbacks: Union[Callable, List[Callable]] \u001b[38;5;241m=\u001b[39m [],\n\u001b[1;32m    316\u001b[0m         all_losses: Optional[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    317\u001b[0m   \u001b[38;5;124;03m\"\"\"Train this model on a dataset.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m  Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m  The average loss over the most recent checkpoint interval\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m \"\"\"\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_checkpoints_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/deepchem/models/keras_model.py:444\u001b[0m, in \u001b[0;36mKerasModel.fit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    442\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 444\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mapply_gradient_for_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_global_step\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    447\u001b[0m avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist14_2 = model14.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c4d8a-de13-4dc4-beb7-82df36765448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdcd9db0-ee34-43cf-a61d-1116c8cf8b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_13:0\", shape=(538, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_16:0\", shape=(3182, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_19:0\", shape=(2850, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_22:0\", shape=(136, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_10:0\", shape=(538, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_13:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_12:0\", shape=(3182, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_15:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_14:0\", shape=(2850, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_16:0\", shape=(136, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_13:0\", shape=(538, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_16:0\", shape=(3182, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_19:0\", shape=(2850, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_22:0\", shape=(136, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_10:0\", shape=(538, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_13:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_12:0\", shape=(3182, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_15:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_14:0\", shape=(2850, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_16:0\", shape=(136, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(538, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(3182, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(2850, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(136, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(538, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(3182, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(2850, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(538, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(3182,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(3182, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(2850,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(2850, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_13:0\", shape=(527, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_16:0\", shape=(3348, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_19:0\", shape=(2913, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_22:0\", shape=(172, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_10:0\", shape=(527, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_13:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_12:0\", shape=(3348, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_15:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_14:0\", shape=(2913, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_17:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_16:0\", shape=(172, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_13:0\", shape=(527, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_16:0\", shape=(3348, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_19:0\", shape=(2913, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_22:0\", shape=(172, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_10:0\", shape=(527, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_13:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_12:0\", shape=(3348, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_15:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_14:0\", shape=(2913, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_17:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_16:0\", shape=(172, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(527, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(3348, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(2913, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(172, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(527, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(3348, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(2913, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(172, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(527,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(527, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(3348,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(3348, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(2913,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(2913, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(172,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(172, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_14/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_13/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_10:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_12:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_14:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_13/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_12/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_conv_12/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.112536 mean-accuracy_score=0.955224 mean-roc_auc_score=0.822666\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.176622 mean-accuracy_score=0.955778 mean-roc_auc_score=0.836623\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.134022 mean-accuracy_score=0.955713 mean-roc_auc_score=0.846425\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.259415 mean-accuracy_score=0.957049 mean-roc_auc_score=0.858792\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.344481 mean-accuracy_score=0.95555 mean-roc_auc_score=0.8618\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.290977 mean-accuracy_score=0.957538 mean-roc_auc_score=0.86468\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.260783 mean-accuracy_score=0.957407 mean-roc_auc_score=0.866574\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.319455 mean-accuracy_score=0.959134 mean-roc_auc_score=0.871015\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.355358 mean-accuracy_score=0.95933 mean-roc_auc_score=0.878626\n",
      "Step 10000 validation: mean-matthews_corrcoef=0.333848 mean-accuracy_score=0.959591 mean-roc_auc_score=0.87588\n",
      "Step 11000 validation: mean-matthews_corrcoef=0.36295 mean-accuracy_score=0.957635 mean-roc_auc_score=0.880609\n",
      "Step 12000 validation: mean-matthews_corrcoef=0.316818 mean-accuracy_score=0.9592 mean-roc_auc_score=0.883506\n",
      "Step 13000 validation: mean-matthews_corrcoef=0.402072 mean-accuracy_score=0.959297 mean-roc_auc_score=0.885823\n",
      "Step 14000 validation: mean-matthews_corrcoef=0.393485 mean-accuracy_score=0.958678 mean-roc_auc_score=0.866919\n",
      "Step 15000 validation: mean-matthews_corrcoef=0.359462 mean-accuracy_score=0.960308 mean-roc_auc_score=0.892221\n",
      "Step 16000 validation: mean-matthews_corrcoef=0.336249 mean-accuracy_score=0.960014 mean-roc_auc_score=0.890037\n",
      "Step 17000 validation: mean-matthews_corrcoef=0.400082 mean-accuracy_score=0.960112 mean-roc_auc_score=0.89406\n",
      "Step 18000 validation: mean-matthews_corrcoef=0.368983 mean-accuracy_score=0.960634 mean-roc_auc_score=0.887788\n",
      "Step 19000 validation: mean-matthews_corrcoef=0.431025 mean-accuracy_score=0.961579 mean-roc_auc_score=0.896161\n",
      "Step 20000 validation: mean-matthews_corrcoef=0.314499 mean-accuracy_score=0.95946 mean-roc_auc_score=0.893867\n",
      "Step 21000 validation: mean-matthews_corrcoef=0.443537 mean-accuracy_score=0.960112 mean-roc_auc_score=0.895798\n",
      "Step 22000 validation: mean-matthews_corrcoef=0.44845 mean-accuracy_score=0.962752 mean-roc_auc_score=0.89728\n",
      "Step 23000 validation: mean-matthews_corrcoef=0.381718 mean-accuracy_score=0.961025 mean-roc_auc_score=0.895201\n",
      "Step 24000 validation: mean-matthews_corrcoef=0.387747 mean-accuracy_score=0.961285 mean-roc_auc_score=0.898178\n",
      "Step 25000 validation: mean-matthews_corrcoef=0.44846 mean-accuracy_score=0.961481 mean-roc_auc_score=0.903669\n",
      "Step 26000 validation: mean-matthews_corrcoef=0.442378 mean-accuracy_score=0.962035 mean-roc_auc_score=0.898359\n",
      "Step 27000 validation: mean-matthews_corrcoef=0.447175 mean-accuracy_score=0.962133 mean-roc_auc_score=0.900597\n",
      "Step 28000 validation: mean-matthews_corrcoef=0.439863 mean-accuracy_score=0.961872 mean-roc_auc_score=0.896552\n",
      "Step 29000 validation: mean-matthews_corrcoef=0.437351 mean-accuracy_score=0.963306 mean-roc_auc_score=0.89533\n",
      "Step 30000 validation: mean-matthews_corrcoef=0.44669 mean-accuracy_score=0.963012 mean-roc_auc_score=0.901664\n",
      "Step 31000 validation: mean-matthews_corrcoef=0.474266 mean-accuracy_score=0.960308 mean-roc_auc_score=0.902669\n",
      "Step 32000 validation: mean-matthews_corrcoef=0.43983 mean-accuracy_score=0.962491 mean-roc_auc_score=0.897575\n",
      "Step 33000 validation: mean-matthews_corrcoef=0.495475 mean-accuracy_score=0.961188 mean-roc_auc_score=0.900409\n",
      "Step 34000 validation: mean-matthews_corrcoef=0.436186 mean-accuracy_score=0.9592 mean-roc_auc_score=0.895784\n",
      "Step 35000 validation: mean-matthews_corrcoef=0.508418 mean-accuracy_score=0.958613 mean-roc_auc_score=0.903977\n",
      "Step 36000 validation: mean-matthews_corrcoef=0.464907 mean-accuracy_score=0.96386 mean-roc_auc_score=0.90144\n",
      "Step 37000 validation: mean-matthews_corrcoef=0.458283 mean-accuracy_score=0.962687 mean-roc_auc_score=0.897374\n",
      "Step 38000 validation: mean-matthews_corrcoef=0.475293 mean-accuracy_score=0.958059 mean-roc_auc_score=0.898271\n",
      "Step 39000 validation: mean-matthews_corrcoef=0.50285 mean-accuracy_score=0.960764 mean-roc_auc_score=0.90076\n",
      "Step 40000 validation: mean-matthews_corrcoef=0.471107 mean-accuracy_score=0.963241 mean-roc_auc_score=0.903566\n",
      "Step 41000 validation: mean-matthews_corrcoef=0.487425 mean-accuracy_score=0.963664 mean-roc_auc_score=0.905235\n",
      "Step 42000 validation: mean-matthews_corrcoef=0.482091 mean-accuracy_score=0.964512 mean-roc_auc_score=0.904024\n",
      "Step 43000 validation: mean-matthews_corrcoef=0.473338 mean-accuracy_score=0.963469 mean-roc_auc_score=0.89711\n",
      "Step 44000 validation: mean-matthews_corrcoef=0.473339 mean-accuracy_score=0.960862 mean-roc_auc_score=0.897892\n",
      "Step 45000 validation: mean-matthews_corrcoef=0.457129 mean-accuracy_score=0.962524 mean-roc_auc_score=0.894239\n",
      "Step 46000 validation: mean-matthews_corrcoef=0.489925 mean-accuracy_score=0.963012 mean-roc_auc_score=0.899283\n",
      "Step 47000 validation: mean-matthews_corrcoef=0.476511 mean-accuracy_score=0.961611 mean-roc_auc_score=0.897249\n",
      "Step 48000 validation: mean-matthews_corrcoef=0.458511 mean-accuracy_score=0.963762 mean-roc_auc_score=0.89858\n",
      "Step 49000 validation: mean-matthews_corrcoef=0.459978 mean-accuracy_score=0.962752 mean-roc_auc_score=0.894518\n",
      "Step 50000 validation: mean-matthews_corrcoef=0.499755 mean-accuracy_score=0.963045 mean-roc_auc_score=0.897283\n",
      "Step 51000 validation: mean-matthews_corrcoef=0.477 mean-accuracy_score=0.960471 mean-roc_auc_score=0.897136\n",
      "Step 52000 validation: mean-matthews_corrcoef=0.493116 mean-accuracy_score=0.962458 mean-roc_auc_score=0.900245\n",
      "Step 53000 validation: mean-matthews_corrcoef=0.491742 mean-accuracy_score=0.961742 mean-roc_auc_score=0.900447\n",
      "Step 54000 validation: mean-matthews_corrcoef=0.499678 mean-accuracy_score=0.963273 mean-roc_auc_score=0.901108\n",
      "Step 55000 validation: mean-matthews_corrcoef=0.482573 mean-accuracy_score=0.962165 mean-roc_auc_score=0.897047\n",
      "Step 56000 validation: mean-matthews_corrcoef=0.491976 mean-accuracy_score=0.962296 mean-roc_auc_score=0.899706\n",
      "Step 57000 validation: mean-matthews_corrcoef=0.48558 mean-accuracy_score=0.960112 mean-roc_auc_score=0.893463\n",
      "Step 58000 validation: mean-matthews_corrcoef=0.494267 mean-accuracy_score=0.961448 mean-roc_auc_score=0.898106\n",
      "Step 59000 validation: mean-matthews_corrcoef=0.464151 mean-accuracy_score=0.959721 mean-roc_auc_score=0.894351\n",
      "Step 60000 validation: mean-matthews_corrcoef=0.481163 mean-accuracy_score=0.961253 mean-roc_auc_score=0.896816\n",
      "Step 61000 validation: mean-matthews_corrcoef=0.486146 mean-accuracy_score=0.959917 mean-roc_auc_score=0.895938\n",
      "Step 62000 validation: mean-matthews_corrcoef=0.499164 mean-accuracy_score=0.960764 mean-roc_auc_score=0.900676\n",
      "Step 63000 validation: mean-matthews_corrcoef=0.475715 mean-accuracy_score=0.961057 mean-roc_auc_score=0.89469\n",
      "Step 64000 validation: mean-matthews_corrcoef=0.478832 mean-accuracy_score=0.959917 mean-roc_auc_score=0.893894\n",
      "Step 65000 validation: mean-matthews_corrcoef=0.469841 mean-accuracy_score=0.959982 mean-roc_auc_score=0.89776\n",
      "Step 66000 validation: mean-matthews_corrcoef=0.469947 mean-accuracy_score=0.963078 mean-roc_auc_score=0.899461\n",
      "Step 67000 validation: mean-matthews_corrcoef=0.49606 mean-accuracy_score=0.959297 mean-roc_auc_score=0.899315\n",
      "Step 68000 validation: mean-matthews_corrcoef=0.491053 mean-accuracy_score=0.961057 mean-roc_auc_score=0.896022\n",
      "Step 69000 validation: mean-matthews_corrcoef=0.475645 mean-accuracy_score=0.960601 mean-roc_auc_score=0.895819\n",
      "Step 70000 validation: mean-matthews_corrcoef=0.475533 mean-accuracy_score=0.961155 mean-roc_auc_score=0.893148\n",
      "Step 71000 validation: mean-matthews_corrcoef=0.500678 mean-accuracy_score=0.962654 mean-roc_auc_score=0.898141\n",
      "Step 72000 validation: mean-matthews_corrcoef=0.477448 mean-accuracy_score=0.956234 mean-roc_auc_score=0.891704\n",
      "Step 73000 validation: mean-matthews_corrcoef=0.491181 mean-accuracy_score=0.962133 mean-roc_auc_score=0.895636\n",
      "Step 74000 validation: mean-matthews_corrcoef=0.501654 mean-accuracy_score=0.96034 mean-roc_auc_score=0.89687\n",
      "Step 75000 validation: mean-matthews_corrcoef=0.478015 mean-accuracy_score=0.962067 mean-roc_auc_score=0.898491\n",
      "Step 76000 validation: mean-matthews_corrcoef=0.48961 mean-accuracy_score=0.959688 mean-roc_auc_score=0.896082\n",
      "Step 77000 validation: mean-matthews_corrcoef=0.482536 mean-accuracy_score=0.956071 mean-roc_auc_score=0.897846\n",
      "Step 78000 validation: mean-matthews_corrcoef=0.493636 mean-accuracy_score=0.9592 mean-roc_auc_score=0.900264\n",
      "Step 79000 validation: mean-matthews_corrcoef=0.509029 mean-accuracy_score=0.96034 mean-roc_auc_score=0.902962\n",
      "Step 80000 validation: mean-matthews_corrcoef=0.483055 mean-accuracy_score=0.960275 mean-roc_auc_score=0.892753\n",
      "Step 81000 validation: mean-matthews_corrcoef=0.480519 mean-accuracy_score=0.957147 mean-roc_auc_score=0.894714\n",
      "Step 82000 validation: mean-matthews_corrcoef=0.485501 mean-accuracy_score=0.959037 mean-roc_auc_score=0.895914\n",
      "Step 83000 validation: mean-matthews_corrcoef=0.480539 mean-accuracy_score=0.959363 mean-roc_auc_score=0.896903\n",
      "Step 84000 validation: mean-matthews_corrcoef=0.474963 mean-accuracy_score=0.961285 mean-roc_auc_score=0.894588\n",
      "Step 85000 validation: mean-matthews_corrcoef=0.489454 mean-accuracy_score=0.957635 mean-roc_auc_score=0.897069\n",
      "Step 86000 validation: mean-matthews_corrcoef=0.478193 mean-accuracy_score=0.958515 mean-roc_auc_score=0.893235\n",
      "Step 87000 validation: mean-matthews_corrcoef=0.48838 mean-accuracy_score=0.958255 mean-roc_auc_score=0.895427\n",
      "Step 88000 validation: mean-matthews_corrcoef=0.466928 mean-accuracy_score=0.958548 mean-roc_auc_score=0.890533\n",
      "Step 89000 validation: mean-matthews_corrcoef=0.485727 mean-accuracy_score=0.96135 mean-roc_auc_score=0.89473\n",
      "Step 90000 validation: mean-matthews_corrcoef=0.479759 mean-accuracy_score=0.96021 mean-roc_auc_score=0.895916\n",
      "Step 91000 validation: mean-matthews_corrcoef=0.468692 mean-accuracy_score=0.959884 mean-roc_auc_score=0.893399\n",
      "Step 92000 validation: mean-matthews_corrcoef=0.472511 mean-accuracy_score=0.960601 mean-roc_auc_score=0.892609\n",
      "Step 93000 validation: mean-matthews_corrcoef=0.47773 mean-accuracy_score=0.958939 mean-roc_auc_score=0.893732\n",
      "Step 94000 validation: mean-matthews_corrcoef=0.485662 mean-accuracy_score=0.959297 mean-roc_auc_score=0.893515\n",
      "Step 95000 validation: mean-matthews_corrcoef=0.492238 mean-accuracy_score=0.960699 mean-roc_auc_score=0.895709\n"
     ]
    }
   ],
   "source": [
    "save_dir14=f'{get_home_path()}/models/gcn_model_14/callbacks'\n",
    "\n",
    "model14 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[64, 128, 256, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         model_dir=f'{get_home_path()}/models/gcn_model_14')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=save_dir14,\n",
    "                                        save_on_minimum=False)\n",
    "\n",
    "hist14 = model14.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b0117fd-fd2f-407a-a02a-15dbba3b4049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.9070435223658783, 'mean-accuracy_score': 0.992325615498672, 'mean-roc_auc_score': 0.9984876464016141}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.47465749458314266, 'mean-accuracy_score': 0.9614808055790914, 'mean-roc_auc_score': 0.8894597581984992}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.44472971937887906, 'mean-accuracy_score': 0.9596245967347736, 'mean-roc_auc_score': 0.8910045500476188}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.5090293891953639, 'mean-accuracy_score': 0.9603402202959004, 'mean-roc_auc_score': 0.9029619360428067}\n",
      "Loss? = 0.024895613193511964\n",
      "[[28787   525]\n",
      " [  692   682]]\n",
      "Specificity = 0.9821\n",
      "FPR = 0.0179\n",
      "Recall/TPR = 0.4964\n",
      "Precision = 0.565\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model14, hist14, save_dir14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db6538cf-6fb5-42eb-b93f-e1b8d2b565ea",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred14 = [x.flatten() for x in model14.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "516d72c0-6169-437c-97b7-cfede489d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421059e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.249137e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.676490e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.366851e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.216783e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values    pred_probs\n",
       "0          0.0  1.421059e-05\n",
       "1          0.0  1.249137e-05\n",
       "2          0.0  9.676490e-11\n",
       "3          0.0  3.366851e-05\n",
       "4          0.0  2.216783e-02"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred14_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred14])})\n",
    "\n",
    "pred14_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae57da8d-e715-4796-86ba-ffef1f722a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred14_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that Outcome = 1')\n",
    "plt.legend()\n",
    "plt.ylim(0, 2000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c109edd-9eba-42f1-aa04-34272e57ba91",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8bbc4d9-fdf0-479b-810b-494e6d4026f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fbf64f696a0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "962a4991-160a-4435-b6d6-d721f178d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate15 = dc.models.optimizers.ExponentialDecay(0.0002, 0.9, 1000)\n",
    "save_dir15=f'{get_home_path()}/models/gcn_model_15'\n",
    "\n",
    "model15 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[512, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         learning_rate=learning_rate15,\n",
    "                         model_dir=save_dir15)\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=f'{save_dir15}/callbacks',\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "160db292-1466-494f-8bcc-047e2ee5c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepchem.models.losses.SoftmaxCrossEntropy at 0x7fb6d50ae3a0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model15.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ecaec004-9f26-4759-8458-e779ab98e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 96000 validation: mean-matthews_corrcoef=0.484291 mean-accuracy_score=0.9621 mean-roc_auc_score=0.901314\n",
      "Step 97000 validation: mean-matthews_corrcoef=0.487451 mean-accuracy_score=0.960308 mean-roc_auc_score=0.897593\n",
      "Step 98000 validation: mean-matthews_corrcoef=0.463609 mean-accuracy_score=0.962165 mean-roc_auc_score=0.897568\n",
      "Step 99000 validation: mean-matthews_corrcoef=0.465393 mean-accuracy_score=0.95379 mean-roc_auc_score=0.893987\n",
      "Step 100000 validation: mean-matthews_corrcoef=0.470255 mean-accuracy_score=0.959363 mean-roc_auc_score=0.894683\n",
      "Step 101000 validation: mean-matthews_corrcoef=0.468864 mean-accuracy_score=0.961025 mean-roc_auc_score=0.898388\n",
      "Step 102000 validation: mean-matthews_corrcoef=0.486793 mean-accuracy_score=0.960992 mean-roc_auc_score=0.90297\n",
      "Step 103000 validation: mean-matthews_corrcoef=0.477504 mean-accuracy_score=0.961904 mean-roc_auc_score=0.899286\n",
      "Step 104000 validation: mean-matthews_corrcoef=0.489524 mean-accuracy_score=0.961481 mean-roc_auc_score=0.904547\n",
      "Step 105000 validation: mean-matthews_corrcoef=0.478747 mean-accuracy_score=0.962491 mean-roc_auc_score=0.897346\n",
      "Step 106000 validation: mean-matthews_corrcoef=0.479875 mean-accuracy_score=0.958352 mean-roc_auc_score=0.89785\n",
      "Step 107000 validation: mean-matthews_corrcoef=0.487995 mean-accuracy_score=0.957733 mean-roc_auc_score=0.898226\n",
      "Step 108000 validation: mean-matthews_corrcoef=0.473391 mean-accuracy_score=0.957994 mean-roc_auc_score=0.900066\n",
      "Step 109000 validation: mean-matthews_corrcoef=0.477943 mean-accuracy_score=0.957244 mean-roc_auc_score=0.899914\n",
      "Step 110000 validation: mean-matthews_corrcoef=0.482038 mean-accuracy_score=0.962035 mean-roc_auc_score=0.901909\n",
      "Step 111000 validation: mean-matthews_corrcoef=0.482963 mean-accuracy_score=0.959819 mean-roc_auc_score=0.901376\n",
      "Step 112000 validation: mean-matthews_corrcoef=0.474183 mean-accuracy_score=0.96034 mean-roc_auc_score=0.899623\n",
      "Step 113000 validation: mean-matthews_corrcoef=0.480364 mean-accuracy_score=0.959754 mean-roc_auc_score=0.896288\n",
      "Step 114000 validation: mean-matthews_corrcoef=0.481853 mean-accuracy_score=0.958874 mean-roc_auc_score=0.901854\n",
      "Step 115000 validation: mean-matthews_corrcoef=0.470746 mean-accuracy_score=0.96135 mean-roc_auc_score=0.897836\n",
      "Step 116000 validation: mean-matthews_corrcoef=0.482811 mean-accuracy_score=0.959754 mean-roc_auc_score=0.898067\n",
      "Step 117000 validation: mean-matthews_corrcoef=0.476217 mean-accuracy_score=0.958189 mean-roc_auc_score=0.898479\n",
      "Step 118000 validation: mean-matthews_corrcoef=0.459185 mean-accuracy_score=0.960405 mean-roc_auc_score=0.89741\n",
      "Step 119000 validation: mean-matthews_corrcoef=0.478593 mean-accuracy_score=0.960829 mean-roc_auc_score=0.898799\n",
      "Step 120000 validation: mean-matthews_corrcoef=0.475747 mean-accuracy_score=0.959102 mean-roc_auc_score=0.894354\n",
      "Step 121000 validation: mean-matthews_corrcoef=0.497515 mean-accuracy_score=0.959688 mean-roc_auc_score=0.902485\n",
      "Step 122000 validation: mean-matthews_corrcoef=0.486903 mean-accuracy_score=0.959558 mean-roc_auc_score=0.898641\n",
      "Step 123000 validation: mean-matthews_corrcoef=0.487516 mean-accuracy_score=0.961676 mean-roc_auc_score=0.897866\n",
      "Step 124000 validation: mean-matthews_corrcoef=0.479499 mean-accuracy_score=0.960177 mean-roc_auc_score=0.894376\n",
      "Step 125000 validation: mean-matthews_corrcoef=0.470001 mean-accuracy_score=0.95933 mean-roc_auc_score=0.896988\n",
      "Step 126000 validation: mean-matthews_corrcoef=0.472678 mean-accuracy_score=0.960242 mean-roc_auc_score=0.892364\n",
      "Step 127000 validation: mean-matthews_corrcoef=0.483767 mean-accuracy_score=0.959558 mean-roc_auc_score=0.899391\n",
      "Step 128000 validation: mean-matthews_corrcoef=0.477701 mean-accuracy_score=0.960764 mean-roc_auc_score=0.895638\n",
      "Step 129000 validation: mean-matthews_corrcoef=0.479623 mean-accuracy_score=0.960992 mean-roc_auc_score=0.898957\n",
      "Step 130000 validation: mean-matthews_corrcoef=0.47243 mean-accuracy_score=0.959134 mean-roc_auc_score=0.898841\n",
      "Step 131000 validation: mean-matthews_corrcoef=0.478317 mean-accuracy_score=0.960959 mean-roc_auc_score=0.895139\n",
      "Step 132000 validation: mean-matthews_corrcoef=0.48322 mean-accuracy_score=0.957603 mean-roc_auc_score=0.896024\n",
      "Step 133000 validation: mean-matthews_corrcoef=0.480453 mean-accuracy_score=0.96109 mean-roc_auc_score=0.897981\n",
      "Step 134000 validation: mean-matthews_corrcoef=0.470414 mean-accuracy_score=0.960601 mean-roc_auc_score=0.89575\n"
     ]
    }
   ],
   "source": [
    "hist15 = model15.fit(train_dataset, nb_epoch=20, callbacks=validation, restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a6f44972-dae2-4e6d-ad31-b05d45aeb3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.9207555725826339, 'mean-accuracy_score': 0.9931443794502468, 'mean-roc_auc_score': 0.9987767954381437}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.49751482292778093, 'mean-accuracy_score': 0.9596884572769341, 'mean-roc_auc_score': 0.9024850732549436}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.4706869427390173, 'mean-accuracy_score': 0.9575064359500766, 'mean-roc_auc_score': 0.8960391845161029}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.4743725453287934, 'mean-accuracy_score': 0.957928697125725, 'mean-roc_auc_score': 0.8933988700297318}\n",
      "Loss? = 0.032622498273849485\n",
      "[[28763   549]\n",
      " [  742   632]]\n",
      "Specificity = 0.9813\n",
      "FPR = 0.0187\n",
      "Recall/TPR = 0.46\n",
      "Precision = 0.5351\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model15, hist15, save_dir15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af04693d-be99-44cf-aee6-e1206db1a1fa",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred15 = [x.flatten() for x in model15.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f2a2b521-c541-47bf-b2a7-a416a922783a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values  pred_probs\n",
       "0          0.0    0.000171\n",
       "1          0.0    0.001512\n",
       "2          0.0    0.000003\n",
       "3          0.0    0.000036\n",
       "4          0.0    0.957680"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred15_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred15])})\n",
    "\n",
    "pred15_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "34c10555-b73c-4564-bb59-687d20deb49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred15_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that Outcome = 1')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1800);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98336c08-b175-41f4-8600-55ef7831bb59",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### model 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dda0f5fe-1b87-4e71-89ec-cca7fe6f5be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fbf64f696a0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb68f95d-2f96-4f7b-8a07-9142a6c05344",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate16 = dc.models.optimizers.ExponentialDecay(0.001, 0.8, 1024)\n",
    "save_dir16=f'{get_home_path()}/models/gcn_model_16'\n",
    "\n",
    "model16 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[512, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         learning_rate=learning_rate16,\n",
    "                         model_dir=save_dir16)\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1024,\n",
    "                                        metrics,\n",
    "                                        save_dir=f'{save_dir16}/callbacks',\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "76c83871-1d9c-44db-80b8-b9d9737fc386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1024 validation: mean-matthews_corrcoef=0.156412 mean-accuracy_score=0.955582 mean-roc_auc_score=0.816538\n",
      "Step 2048 validation: mean-matthews_corrcoef=0.105623 mean-accuracy_score=0.955582 mean-roc_auc_score=0.834675\n",
      "Step 3072 validation: mean-matthews_corrcoef=0.24998 mean-accuracy_score=0.95744 mean-roc_auc_score=0.854413\n",
      "Step 4096 validation: mean-matthews_corrcoef=0.244386 mean-accuracy_score=0.957635 mean-roc_auc_score=0.856114\n",
      "Step 5120 validation: mean-matthews_corrcoef=0.313417 mean-accuracy_score=0.954931 mean-roc_auc_score=0.86222\n",
      "Step 6144 validation: mean-matthews_corrcoef=0.195532 mean-accuracy_score=0.956886 mean-roc_auc_score=0.861114\n",
      "Step 7168 validation: mean-matthews_corrcoef=0.360814 mean-accuracy_score=0.958646 mean-roc_auc_score=0.872346\n",
      "Step 8192 validation: mean-matthews_corrcoef=0.243736 mean-accuracy_score=0.957798 mean-roc_auc_score=0.871646\n",
      "Step 9216 validation: mean-matthews_corrcoef=0.289651 mean-accuracy_score=0.958711 mean-roc_auc_score=0.874031\n",
      "Step 10240 validation: mean-matthews_corrcoef=0.306166 mean-accuracy_score=0.958255 mean-roc_auc_score=0.873604\n",
      "Step 11264 validation: mean-matthews_corrcoef=0.357904 mean-accuracy_score=0.959395 mean-roc_auc_score=0.878465\n",
      "Step 12288 validation: mean-matthews_corrcoef=0.412105 mean-accuracy_score=0.95643 mean-roc_auc_score=0.883127\n",
      "Step 13312 validation: mean-matthews_corrcoef=0.307687 mean-accuracy_score=0.958809 mean-roc_auc_score=0.885234\n",
      "Step 14336 validation: mean-matthews_corrcoef=0.398165 mean-accuracy_score=0.960601 mean-roc_auc_score=0.89082\n",
      "Step 15360 validation: mean-matthews_corrcoef=0.394998 mean-accuracy_score=0.96122 mean-roc_auc_score=0.89589\n",
      "Step 16384 validation: mean-matthews_corrcoef=0.29088 mean-accuracy_score=0.959004 mean-roc_auc_score=0.894039\n",
      "Step 17408 validation: mean-matthews_corrcoef=0.347378 mean-accuracy_score=0.960275 mean-roc_auc_score=0.890179\n",
      "Step 18432 validation: mean-matthews_corrcoef=0.366817 mean-accuracy_score=0.960894 mean-roc_auc_score=0.895755\n",
      "Step 19456 validation: mean-matthews_corrcoef=0.457562 mean-accuracy_score=0.955778 mean-roc_auc_score=0.894677\n",
      "Step 20480 validation: mean-matthews_corrcoef=0.441262 mean-accuracy_score=0.960145 mean-roc_auc_score=0.890803\n",
      "Step 21504 validation: mean-matthews_corrcoef=0.42246 mean-accuracy_score=0.961839 mean-roc_auc_score=0.900177\n",
      "Step 22528 validation: mean-matthews_corrcoef=0.43073 mean-accuracy_score=0.961644 mean-roc_auc_score=0.899484\n",
      "Step 23552 validation: mean-matthews_corrcoef=0.43918 mean-accuracy_score=0.961872 mean-roc_auc_score=0.896276\n",
      "Step 24576 validation: mean-matthews_corrcoef=0.46104 mean-accuracy_score=0.960373 mean-roc_auc_score=0.899613\n",
      "Step 25600 validation: mean-matthews_corrcoef=0.472294 mean-accuracy_score=0.960699 mean-roc_auc_score=0.898225\n",
      "Step 26624 validation: mean-matthews_corrcoef=0.450029 mean-accuracy_score=0.962882 mean-roc_auc_score=0.898798\n",
      "Step 27648 validation: mean-matthews_corrcoef=0.44568 mean-accuracy_score=0.961904 mean-roc_auc_score=0.897756\n",
      "Step 28672 validation: mean-matthews_corrcoef=0.428863 mean-accuracy_score=0.962263 mean-roc_auc_score=0.900661\n",
      "Step 29696 validation: mean-matthews_corrcoef=0.431801 mean-accuracy_score=0.963045 mean-roc_auc_score=0.905194\n",
      "Step 30720 validation: mean-matthews_corrcoef=0.478937 mean-accuracy_score=0.960992 mean-roc_auc_score=0.899011\n",
      "Step 31744 validation: mean-matthews_corrcoef=0.45749 mean-accuracy_score=0.963241 mean-roc_auc_score=0.899638\n",
      "Step 32768 validation: mean-matthews_corrcoef=0.487426 mean-accuracy_score=0.960862 mean-roc_auc_score=0.899845\n",
      "Step 33792 validation: mean-matthews_corrcoef=0.467335 mean-accuracy_score=0.962035 mean-roc_auc_score=0.901505\n",
      "Step 34816 validation: mean-matthews_corrcoef=0.462694 mean-accuracy_score=0.961872 mean-roc_auc_score=0.899472\n",
      "Step 35840 validation: mean-matthews_corrcoef=0.444984 mean-accuracy_score=0.961872 mean-roc_auc_score=0.894768\n",
      "Step 36864 validation: mean-matthews_corrcoef=0.456183 mean-accuracy_score=0.962556 mean-roc_auc_score=0.900575\n",
      "Step 37888 validation: mean-matthews_corrcoef=0.484478 mean-accuracy_score=0.961937 mean-roc_auc_score=0.905518\n",
      "Step 38912 validation: mean-matthews_corrcoef=0.488508 mean-accuracy_score=0.961904 mean-roc_auc_score=0.902949\n",
      "Step 39936 validation: mean-matthews_corrcoef=0.447403 mean-accuracy_score=0.962556 mean-roc_auc_score=0.89572\n",
      "Step 40960 validation: mean-matthews_corrcoef=0.467017 mean-accuracy_score=0.963012 mean-roc_auc_score=0.900054\n",
      "Step 41984 validation: mean-matthews_corrcoef=0.489332 mean-accuracy_score=0.963306 mean-roc_auc_score=0.901283\n",
      "Step 43008 validation: mean-matthews_corrcoef=0.47243 mean-accuracy_score=0.959134 mean-roc_auc_score=0.896793\n",
      "Step 44032 validation: mean-matthews_corrcoef=0.475749 mean-accuracy_score=0.961676 mean-roc_auc_score=0.896933\n",
      "Step 45056 validation: mean-matthews_corrcoef=0.453877 mean-accuracy_score=0.9621 mean-roc_auc_score=0.897081\n",
      "Step 46080 validation: mean-matthews_corrcoef=0.476348 mean-accuracy_score=0.954279 mean-roc_auc_score=0.89934\n",
      "Step 47104 validation: mean-matthews_corrcoef=0.486594 mean-accuracy_score=0.959656 mean-roc_auc_score=0.900541\n",
      "Step 48128 validation: mean-matthews_corrcoef=0.497653 mean-accuracy_score=0.958939 mean-roc_auc_score=0.902474\n",
      "Step 49152 validation: mean-matthews_corrcoef=0.465304 mean-accuracy_score=0.962491 mean-roc_auc_score=0.900232\n",
      "Step 50176 validation: mean-matthews_corrcoef=0.485317 mean-accuracy_score=0.961807 mean-roc_auc_score=0.89878\n",
      "Step 51200 validation: mean-matthews_corrcoef=0.440409 mean-accuracy_score=0.962882 mean-roc_auc_score=0.897222\n",
      "Step 52224 validation: mean-matthews_corrcoef=0.473047 mean-accuracy_score=0.96386 mean-roc_auc_score=0.895893\n",
      "Step 53248 validation: mean-matthews_corrcoef=0.475108 mean-accuracy_score=0.955224 mean-roc_auc_score=0.895412\n",
      "Step 54272 validation: mean-matthews_corrcoef=0.47513 mean-accuracy_score=0.959623 mean-roc_auc_score=0.895976\n",
      "Step 55296 validation: mean-matthews_corrcoef=0.48992 mean-accuracy_score=0.962393 mean-roc_auc_score=0.899102\n",
      "Step 56320 validation: mean-matthews_corrcoef=0.490286 mean-accuracy_score=0.960275 mean-roc_auc_score=0.900171\n",
      "Step 57344 validation: mean-matthews_corrcoef=0.476603 mean-accuracy_score=0.961546 mean-roc_auc_score=0.898586\n",
      "Step 58368 validation: mean-matthews_corrcoef=0.464986 mean-accuracy_score=0.962915 mean-roc_auc_score=0.89732\n",
      "Step 59392 validation: mean-matthews_corrcoef=0.464369 mean-accuracy_score=0.962589 mean-roc_auc_score=0.896859\n",
      "Step 60416 validation: mean-matthews_corrcoef=0.494645 mean-accuracy_score=0.962002 mean-roc_auc_score=0.89888\n",
      "Step 61440 validation: mean-matthews_corrcoef=0.488026 mean-accuracy_score=0.961383 mean-roc_auc_score=0.897232\n",
      "Step 62464 validation: mean-matthews_corrcoef=0.483954 mean-accuracy_score=0.963795 mean-roc_auc_score=0.900534\n",
      "Step 63488 validation: mean-matthews_corrcoef=0.487476 mean-accuracy_score=0.961318 mean-roc_auc_score=0.899248\n",
      "Step 64512 validation: mean-matthews_corrcoef=0.491538 mean-accuracy_score=0.961872 mean-roc_auc_score=0.902801\n",
      "Step 65536 validation: mean-matthews_corrcoef=0.468599 mean-accuracy_score=0.96223 mean-roc_auc_score=0.894596\n",
      "Step 66560 validation: mean-matthews_corrcoef=0.473598 mean-accuracy_score=0.962882 mean-roc_auc_score=0.897595\n",
      "Step 67584 validation: mean-matthews_corrcoef=0.457129 mean-accuracy_score=0.962524 mean-roc_auc_score=0.89889\n",
      "Step 68608 validation: mean-matthews_corrcoef=0.472677 mean-accuracy_score=0.962067 mean-roc_auc_score=0.897412\n",
      "Step 69632 validation: mean-matthews_corrcoef=0.450216 mean-accuracy_score=0.962165 mean-roc_auc_score=0.894197\n",
      "Step 70656 validation: mean-matthews_corrcoef=0.490762 mean-accuracy_score=0.962556 mean-roc_auc_score=0.895948\n",
      "Step 71680 validation: mean-matthews_corrcoef=0.480649 mean-accuracy_score=0.960014 mean-roc_auc_score=0.895903\n",
      "Step 72704 validation: mean-matthews_corrcoef=0.483414 mean-accuracy_score=0.960536 mean-roc_auc_score=0.897719\n",
      "Step 73728 validation: mean-matthews_corrcoef=0.497314 mean-accuracy_score=0.960568 mean-roc_auc_score=0.898092\n",
      "Step 74752 validation: mean-matthews_corrcoef=0.462788 mean-accuracy_score=0.961122 mean-roc_auc_score=0.896203\n",
      "Step 75776 validation: mean-matthews_corrcoef=0.495309 mean-accuracy_score=0.957244 mean-roc_auc_score=0.90286\n",
      "Step 76800 validation: mean-matthews_corrcoef=0.474076 mean-accuracy_score=0.960112 mean-roc_auc_score=0.896459\n",
      "Step 77824 validation: mean-matthews_corrcoef=0.481836 mean-accuracy_score=0.960764 mean-roc_auc_score=0.900114\n",
      "Step 78848 validation: mean-matthews_corrcoef=0.46192 mean-accuracy_score=0.957766 mean-roc_auc_score=0.89813\n",
      "Step 79872 validation: mean-matthews_corrcoef=0.496983 mean-accuracy_score=0.960829 mean-roc_auc_score=0.899989\n",
      "Step 80896 validation: mean-matthews_corrcoef=0.478047 mean-accuracy_score=0.960764 mean-roc_auc_score=0.899419\n",
      "Step 81920 validation: mean-matthews_corrcoef=0.477696 mean-accuracy_score=0.960927 mean-roc_auc_score=0.898192\n",
      "Step 82944 validation: mean-matthews_corrcoef=0.467241 mean-accuracy_score=0.959526 mean-roc_auc_score=0.896697\n",
      "Step 83968 validation: mean-matthews_corrcoef=0.481084 mean-accuracy_score=0.963501 mean-roc_auc_score=0.897362\n",
      "Step 84992 validation: mean-matthews_corrcoef=0.471384 mean-accuracy_score=0.961383 mean-roc_auc_score=0.899215\n",
      "Step 86016 validation: mean-matthews_corrcoef=0.481567 mean-accuracy_score=0.959819 mean-roc_auc_score=0.895712\n",
      "Step 87040 validation: mean-matthews_corrcoef=0.486508 mean-accuracy_score=0.960536 mean-roc_auc_score=0.899206\n",
      "Step 88064 validation: mean-matthews_corrcoef=0.473003 mean-accuracy_score=0.961709 mean-roc_auc_score=0.892178\n",
      "Step 89088 validation: mean-matthews_corrcoef=0.476214 mean-accuracy_score=0.956658 mean-roc_auc_score=0.894205\n",
      "Step 90112 validation: mean-matthews_corrcoef=0.472953 mean-accuracy_score=0.961481 mean-roc_auc_score=0.899027\n",
      "Step 91136 validation: mean-matthews_corrcoef=0.470257 mean-accuracy_score=0.961742 mean-roc_auc_score=0.896382\n",
      "Step 92160 validation: mean-matthews_corrcoef=0.472349 mean-accuracy_score=0.95845 mean-roc_auc_score=0.891418\n",
      "Step 93184 validation: mean-matthews_corrcoef=0.495605 mean-accuracy_score=0.95933 mean-roc_auc_score=0.897865\n",
      "Step 94208 validation: mean-matthews_corrcoef=0.479727 mean-accuracy_score=0.960634 mean-roc_auc_score=0.895286\n",
      "Step 95232 validation: mean-matthews_corrcoef=0.487261 mean-accuracy_score=0.96109 mean-roc_auc_score=0.896374\n",
      "Step 96256 validation: mean-matthews_corrcoef=0.485124 mean-accuracy_score=0.961709 mean-roc_auc_score=0.900337\n"
     ]
    }
   ],
   "source": [
    "hist16 = model16.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "78a1f1d3-2e0c-4965-87a1-985d5612c524",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.8927756751796663, 'mean-accuracy_score': 0.9908632460528245, 'mean-roc_auc_score': 0.9976606794241611}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.48610187283927797, 'mean-accuracy_score': 0.959167046861761, 'mean-roc_auc_score': 0.894108869322588}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.4625984316111824, 'mean-accuracy_score': 0.9567569329031838, 'mean-roc_auc_score': 0.8956954195273609}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.4976525550546536, 'mean-accuracy_score': 0.9589389298051229, 'mean-roc_auc_score': 0.9024744400254572}\n",
      "Loss? = 0.03420705506295869\n",
      "[[28748   564]\n",
      " [  696   678]]\n",
      "Specificity = 0.9808\n",
      "FPR = 0.0192\n",
      "Recall/TPR = 0.4934\n",
      "Precision = 0.5459\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model16, hist16, save_dir16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f16aa-ca49-4f4a-936e-2156c09a898f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22e28070-d92e-4a8d-8c8c-a850b87d3f77",
   "metadata": {},
   "source": [
    "#### model 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "03beb05b-d303-41e9-80c6-8c43f95d872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate17 = dc.models.optimizers.ExponentialDecay(0.0001, 0.8, 1024)\n",
    "save_dir17=f'{get_home_path()}/models/gcn_model_17'\n",
    "\n",
    "model17 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[512, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         learning_rate=learning_rate17,\n",
    "                         model_dir=save_dir17)\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1024,\n",
    "                                        metrics,\n",
    "                                        save_dir=f'{save_dir17}/callbacks',\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c8f84049-0c93-4c7e-8a8e-ff34e880b8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_14:0\", shape=(528,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_13:0\", shape=(528, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_17:0\", shape=(3236,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_16:0\", shape=(3236, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_20:0\", shape=(2760,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_19:0\", shape=(2760, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_23:0\", shape=(228,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_22:0\", shape=(228, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_11:0\", shape=(528,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_10:0\", shape=(528, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_13:0\", shape=(3236,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_12:0\", shape=(3236, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_15:0\", shape=(2760,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_14:0\", shape=(2760, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_17:0\", shape=(228,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_16:0\", shape=(228, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_14:0\", shape=(528,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_13:0\", shape=(528, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_17:0\", shape=(3236,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_16:0\", shape=(3236, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_20:0\", shape=(2760,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_19:0\", shape=(2760, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_23:0\", shape=(228,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_22:0\", shape=(228, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_14:0\", shape=(536,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_13:0\", shape=(536, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_17:0\", shape=(3212,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_16:0\", shape=(3212, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_20:0\", shape=(2790,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_19:0\", shape=(2790, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_23:0\", shape=(144,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_22:0\", shape=(144, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_11:0\", shape=(536,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_10:0\", shape=(536, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_13:0\", shape=(3212,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_12:0\", shape=(3212, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_15:0\", shape=(2790,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_14:0\", shape=(2790, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_17:0\", shape=(144,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_16:0\", shape=(144, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_14:0\", shape=(536,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_13:0\", shape=(536, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_17:0\", shape=(3212,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_16:0\", shape=(3212, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_20:0\", shape=(2790,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_19:0\", shape=(2790, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_23:0\", shape=(144,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_22:0\", shape=(144, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_36/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_conv_36/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_16/graph_pool_35/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1024 validation: mean-matthews_corrcoef=0.204588 mean-accuracy_score=0.956593 mean-roc_auc_score=0.838298\n",
      "Step 2048 validation: mean-matthews_corrcoef=0.153404 mean-accuracy_score=0.956006 mean-roc_auc_score=0.849612\n",
      "Step 3072 validation: mean-matthews_corrcoef=0.221073 mean-accuracy_score=0.956299 mean-roc_auc_score=0.856705\n",
      "Step 4096 validation: mean-matthews_corrcoef=0.174981 mean-accuracy_score=0.956136 mean-roc_auc_score=0.861479\n",
      "Step 5120 validation: mean-matthews_corrcoef=0.302515 mean-accuracy_score=0.956821 mean-roc_auc_score=0.864502\n",
      "Step 6144 validation: mean-matthews_corrcoef=0.229166 mean-accuracy_score=0.957407 mean-roc_auc_score=0.868504\n",
      "Step 7168 validation: mean-matthews_corrcoef=0.322477 mean-accuracy_score=0.958711 mean-roc_auc_score=0.881476\n",
      "Step 8192 validation: mean-matthews_corrcoef=0.324755 mean-accuracy_score=0.958678 mean-roc_auc_score=0.880466\n",
      "Step 9216 validation: mean-matthews_corrcoef=0.266704 mean-accuracy_score=0.958189 mean-roc_auc_score=0.879405\n",
      "Step 10240 validation: mean-matthews_corrcoef=0.286893 mean-accuracy_score=0.95858 mean-roc_auc_score=0.883322\n",
      "Step 11264 validation: mean-matthews_corrcoef=0.355471 mean-accuracy_score=0.958678 mean-roc_auc_score=0.883541\n",
      "Step 12288 validation: mean-matthews_corrcoef=0.367915 mean-accuracy_score=0.959591 mean-roc_auc_score=0.88529\n",
      "Step 13312 validation: mean-matthews_corrcoef=0.308263 mean-accuracy_score=0.958939 mean-roc_auc_score=0.887167\n",
      "Step 14336 validation: mean-matthews_corrcoef=0.369624 mean-accuracy_score=0.959819 mean-roc_auc_score=0.89079\n",
      "Step 15360 validation: mean-matthews_corrcoef=0.37546 mean-accuracy_score=0.960112 mean-roc_auc_score=0.892078\n",
      "Step 16384 validation: mean-matthews_corrcoef=0.367396 mean-accuracy_score=0.960601 mean-roc_auc_score=0.890691\n",
      "Step 17408 validation: mean-matthews_corrcoef=0.37819 mean-accuracy_score=0.960862 mean-roc_auc_score=0.890801\n",
      "Step 18432 validation: mean-matthews_corrcoef=0.403951 mean-accuracy_score=0.960112 mean-roc_auc_score=0.891587\n",
      "Step 19456 validation: mean-matthews_corrcoef=0.408908 mean-accuracy_score=0.962002 mean-roc_auc_score=0.89385\n",
      "Step 20480 validation: mean-matthews_corrcoef=0.434927 mean-accuracy_score=0.962198 mean-roc_auc_score=0.892134\n",
      "Step 21504 validation: mean-matthews_corrcoef=0.374351 mean-accuracy_score=0.960927 mean-roc_auc_score=0.901018\n",
      "Step 22528 validation: mean-matthews_corrcoef=0.427352 mean-accuracy_score=0.961025 mean-roc_auc_score=0.898208\n",
      "Step 23552 validation: mean-matthews_corrcoef=0.445202 mean-accuracy_score=0.963175 mean-roc_auc_score=0.898494\n",
      "Step 24576 validation: mean-matthews_corrcoef=0.417604 mean-accuracy_score=0.961904 mean-roc_auc_score=0.900398\n",
      "Step 25600 validation: mean-matthews_corrcoef=0.442217 mean-accuracy_score=0.962393 mean-roc_auc_score=0.899287\n",
      "Step 26624 validation: mean-matthews_corrcoef=0.425608 mean-accuracy_score=0.962035 mean-roc_auc_score=0.899852\n",
      "Step 27648 validation: mean-matthews_corrcoef=0.416032 mean-accuracy_score=0.9621 mean-roc_auc_score=0.90218\n",
      "Step 28672 validation: mean-matthews_corrcoef=0.437466 mean-accuracy_score=0.962133 mean-roc_auc_score=0.899109\n",
      "Step 29696 validation: mean-matthews_corrcoef=0.430182 mean-accuracy_score=0.961774 mean-roc_auc_score=0.899568\n",
      "Step 30720 validation: mean-matthews_corrcoef=0.445326 mean-accuracy_score=0.961872 mean-roc_auc_score=0.900431\n",
      "Step 31744 validation: mean-matthews_corrcoef=0.472388 mean-accuracy_score=0.962002 mean-roc_auc_score=0.902894\n",
      "Step 32768 validation: mean-matthews_corrcoef=0.432287 mean-accuracy_score=0.962198 mean-roc_auc_score=0.901696\n",
      "Step 33792 validation: mean-matthews_corrcoef=0.426387 mean-accuracy_score=0.962296 mean-roc_auc_score=0.901445\n",
      "Step 34816 validation: mean-matthews_corrcoef=0.470508 mean-accuracy_score=0.963012 mean-roc_auc_score=0.903548\n",
      "Step 35840 validation: mean-matthews_corrcoef=0.466159 mean-accuracy_score=0.963078 mean-roc_auc_score=0.902487\n",
      "Step 36864 validation: mean-matthews_corrcoef=0.47029 mean-accuracy_score=0.961709 mean-roc_auc_score=0.90037\n",
      "Step 37888 validation: mean-matthews_corrcoef=0.487662 mean-accuracy_score=0.962361 mean-roc_auc_score=0.90341\n",
      "Step 38912 validation: mean-matthews_corrcoef=0.483497 mean-accuracy_score=0.963697 mean-roc_auc_score=0.90287\n",
      "Step 39936 validation: mean-matthews_corrcoef=0.475291 mean-accuracy_score=0.963925 mean-roc_auc_score=0.904216\n",
      "Step 40960 validation: mean-matthews_corrcoef=0.484162 mean-accuracy_score=0.964055 mean-roc_auc_score=0.903628\n",
      "Step 41984 validation: mean-matthews_corrcoef=0.479547 mean-accuracy_score=0.963697 mean-roc_auc_score=0.900162\n",
      "Step 43008 validation: mean-matthews_corrcoef=0.469133 mean-accuracy_score=0.963827 mean-roc_auc_score=0.901641\n",
      "Step 44032 validation: mean-matthews_corrcoef=0.476434 mean-accuracy_score=0.96197 mean-roc_auc_score=0.90173\n",
      "Step 45056 validation: mean-matthews_corrcoef=0.459328 mean-accuracy_score=0.963241 mean-roc_auc_score=0.9031\n",
      "Step 46080 validation: mean-matthews_corrcoef=0.468642 mean-accuracy_score=0.963045 mean-roc_auc_score=0.905288\n",
      "Step 47104 validation: mean-matthews_corrcoef=0.466289 mean-accuracy_score=0.962491 mean-roc_auc_score=0.903905\n",
      "Step 48128 validation: mean-matthews_corrcoef=0.461269 mean-accuracy_score=0.96298 mean-roc_auc_score=0.902813\n",
      "Step 49152 validation: mean-matthews_corrcoef=0.483115 mean-accuracy_score=0.960959 mean-roc_auc_score=0.9021\n",
      "Step 50176 validation: mean-matthews_corrcoef=0.489573 mean-accuracy_score=0.961644 mean-roc_auc_score=0.905769\n",
      "Step 51200 validation: mean-matthews_corrcoef=0.467477 mean-accuracy_score=0.96285 mean-roc_auc_score=0.904397\n",
      "Step 52224 validation: mean-matthews_corrcoef=0.463284 mean-accuracy_score=0.963566 mean-roc_auc_score=0.904552\n",
      "Step 53248 validation: mean-matthews_corrcoef=0.478479 mean-accuracy_score=0.963045 mean-roc_auc_score=0.906548\n",
      "Step 54272 validation: mean-matthews_corrcoef=0.488807 mean-accuracy_score=0.958418 mean-roc_auc_score=0.900263\n",
      "Step 55296 validation: mean-matthews_corrcoef=0.488339 mean-accuracy_score=0.962947 mean-roc_auc_score=0.904989\n",
      "Step 56320 validation: mean-matthews_corrcoef=0.490922 mean-accuracy_score=0.96285 mean-roc_auc_score=0.903396\n",
      "Step 57344 validation: mean-matthews_corrcoef=0.500146 mean-accuracy_score=0.962915 mean-roc_auc_score=0.903739\n",
      "Step 58368 validation: mean-matthews_corrcoef=0.465655 mean-accuracy_score=0.962035 mean-roc_auc_score=0.90162\n",
      "Step 59392 validation: mean-matthews_corrcoef=0.479538 mean-accuracy_score=0.963208 mean-roc_auc_score=0.903273\n",
      "Step 60416 validation: mean-matthews_corrcoef=0.478491 mean-accuracy_score=0.962328 mean-roc_auc_score=0.902288\n",
      "Step 61440 validation: mean-matthews_corrcoef=0.480359 mean-accuracy_score=0.962556 mean-roc_auc_score=0.906972\n",
      "Step 62464 validation: mean-matthews_corrcoef=0.479913 mean-accuracy_score=0.961383 mean-roc_auc_score=0.902886\n",
      "Step 63488 validation: mean-matthews_corrcoef=0.482263 mean-accuracy_score=0.962915 mean-roc_auc_score=0.902438\n",
      "Step 64512 validation: mean-matthews_corrcoef=0.49241 mean-accuracy_score=0.960373 mean-roc_auc_score=0.900526\n",
      "Step 65536 validation: mean-matthews_corrcoef=0.487957 mean-accuracy_score=0.961611 mean-roc_auc_score=0.904785\n",
      "Step 66560 validation: mean-matthews_corrcoef=0.493398 mean-accuracy_score=0.963208 mean-roc_auc_score=0.903249\n",
      "Step 67584 validation: mean-matthews_corrcoef=0.478432 mean-accuracy_score=0.962947 mean-roc_auc_score=0.903815\n",
      "Step 68608 validation: mean-matthews_corrcoef=0.480456 mean-accuracy_score=0.96034 mean-roc_auc_score=0.899353\n",
      "Step 69632 validation: mean-matthews_corrcoef=0.465322 mean-accuracy_score=0.959688 mean-roc_auc_score=0.898839\n",
      "Step 70656 validation: mean-matthews_corrcoef=0.475464 mean-accuracy_score=0.962654 mean-roc_auc_score=0.901426\n",
      "Step 71680 validation: mean-matthews_corrcoef=0.478458 mean-accuracy_score=0.962393 mean-roc_auc_score=0.905582\n",
      "Step 72704 validation: mean-matthews_corrcoef=0.463198 mean-accuracy_score=0.963175 mean-roc_auc_score=0.903656\n",
      "Step 73728 validation: mean-matthews_corrcoef=0.505445 mean-accuracy_score=0.963045 mean-roc_auc_score=0.906687\n",
      "Step 74752 validation: mean-matthews_corrcoef=0.459303 mean-accuracy_score=0.962328 mean-roc_auc_score=0.899754\n",
      "Step 75776 validation: mean-matthews_corrcoef=0.505256 mean-accuracy_score=0.962882 mean-roc_auc_score=0.901261\n",
      "Step 76800 validation: mean-matthews_corrcoef=0.479403 mean-accuracy_score=0.96298 mean-roc_auc_score=0.899933\n",
      "Step 77824 validation: mean-matthews_corrcoef=0.476513 mean-accuracy_score=0.962328 mean-roc_auc_score=0.902118\n",
      "Step 78848 validation: mean-matthews_corrcoef=0.482874 mean-accuracy_score=0.962198 mean-roc_auc_score=0.905733\n",
      "Step 79872 validation: mean-matthews_corrcoef=0.47296 mean-accuracy_score=0.961253 mean-roc_auc_score=0.90083\n",
      "Step 80896 validation: mean-matthews_corrcoef=0.476299 mean-accuracy_score=0.962133 mean-roc_auc_score=0.900524\n",
      "Step 81920 validation: mean-matthews_corrcoef=0.494664 mean-accuracy_score=0.960177 mean-roc_auc_score=0.901141\n",
      "Step 82944 validation: mean-matthews_corrcoef=0.49224 mean-accuracy_score=0.961644 mean-roc_auc_score=0.90272\n",
      "Step 83968 validation: mean-matthews_corrcoef=0.489239 mean-accuracy_score=0.961644 mean-roc_auc_score=0.897634\n",
      "Step 84992 validation: mean-matthews_corrcoef=0.478448 mean-accuracy_score=0.961448 mean-roc_auc_score=0.900415\n",
      "Step 86016 validation: mean-matthews_corrcoef=0.475834 mean-accuracy_score=0.960242 mean-roc_auc_score=0.89723\n",
      "Step 87040 validation: mean-matthews_corrcoef=0.487094 mean-accuracy_score=0.96197 mean-roc_auc_score=0.899047\n",
      "Step 88064 validation: mean-matthews_corrcoef=0.493513 mean-accuracy_score=0.961676 mean-roc_auc_score=0.898891\n",
      "Step 89088 validation: mean-matthews_corrcoef=0.47717 mean-accuracy_score=0.96298 mean-roc_auc_score=0.901482\n",
      "Step 90112 validation: mean-matthews_corrcoef=0.46864 mean-accuracy_score=0.961155 mean-roc_auc_score=0.897209\n",
      "Step 91136 validation: mean-matthews_corrcoef=0.490909 mean-accuracy_score=0.963338 mean-roc_auc_score=0.901851\n",
      "Step 92160 validation: mean-matthews_corrcoef=0.477813 mean-accuracy_score=0.96122 mean-roc_auc_score=0.899197\n",
      "Step 93184 validation: mean-matthews_corrcoef=0.473005 mean-accuracy_score=0.959623 mean-roc_auc_score=0.898479\n",
      "Step 94208 validation: mean-matthews_corrcoef=0.469596 mean-accuracy_score=0.96223 mean-roc_auc_score=0.897636\n",
      "Step 95232 validation: mean-matthews_corrcoef=0.49931 mean-accuracy_score=0.962426 mean-roc_auc_score=0.898051\n"
     ]
    }
   ],
   "source": [
    "hist17 = model17.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2b3cfd86-cf37-4b8a-a965-ccb6dd4ee753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.8483985164161991, 'mean-accuracy_score': 0.9876044840565069, 'mean-roc_auc_score': 0.995549869080302}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.49007610781698174, 'mean-accuracy_score': 0.961545981880988, 'mean-roc_auc_score': 0.8972737293458364}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.47299340720365723, 'mean-accuracy_score': 0.9608629061165966, 'mean-roc_auc_score': 0.8971972421236217}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.5054448195412395, 'mean-accuracy_score': 0.9630450368246106, 'mean-roc_auc_score': 0.9066868066116365}\n",
      "Loss? = 0.042947678565979\n",
      "[[28948   364]\n",
      " [  770   604]]\n",
      "Specificity = 0.9876\n",
      "FPR = 0.0124\n",
      "Recall/TPR = 0.4396\n",
      "Precision = 0.624\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model17, hist17, save_dir17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d8961-0753-4253-afdb-7a3b44c657d0",
   "metadata": {},
   "source": [
    "#### model 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2a64ed6-ce6d-4b8b-9072-13eb1b41eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate18 = dc.models.optimizers.ExponentialDecay(0.0001, 0.8, 1024)\n",
    "save_dir18=f'{get_home_path()}/models/gcn_model_18'\n",
    "\n",
    "model18 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[64, 256, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         learning_rate=learning_rate18,\n",
    "                         model_dir=f'{get_home_path()}/models/gcn_model_18')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1024,\n",
    "                                        metrics,\n",
    "                                        save_dir=f'{save_dir18}/callbacks',\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b1b9ba57-fadd-4dbf-ac23-97aa8491fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_13:0\", shape=(538, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_17:0\", shape=(3470,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_16:0\", shape=(3470, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_20:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_19:0\", shape=(2898, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_22:0\", shape=(188, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_10:0\", shape=(538, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_13:0\", shape=(3470,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_12:0\", shape=(3470, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_15:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_14:0\", shape=(2898, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_17:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_16:0\", shape=(188, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_13:0\", shape=(538, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_17:0\", shape=(3470,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_16:0\", shape=(3470, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_20:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_19:0\", shape=(2898, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_22:0\", shape=(188, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_11:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_10:0\", shape=(538, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_13:0\", shape=(3470,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_12:0\", shape=(3470, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_15:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_14:0\", shape=(2898, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_17:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_16:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_14:0\", shape=(538,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_13:0\", shape=(538, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_17:0\", shape=(3470,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_16:0\", shape=(3470, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_20:0\", shape=(2898,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_19:0\", shape=(2898, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_22:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_14:0\", shape=(509,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_13:0\", shape=(509, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_17:0\", shape=(3332,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_16:0\", shape=(3332, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_20:0\", shape=(2787,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_19:0\", shape=(2787, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_23:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_22:0\", shape=(168, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_11:0\", shape=(509,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_10:0\", shape=(509, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_13:0\", shape=(3332,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_12:0\", shape=(3332, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_15:0\", shape=(2787,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_14:0\", shape=(2787, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_17:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_16:0\", shape=(168, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_14:0\", shape=(509,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_13:0\", shape=(509, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_17:0\", shape=(3332,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_16:0\", shape=(3332, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_20:0\", shape=(2787,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_19:0\", shape=(2787, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_23:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_22:0\", shape=(168, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_11:0\", shape=(509,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_10:0\", shape=(509, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_13:0\", shape=(3332,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_12:0\", shape=(3332, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_15:0\", shape=(2787,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_14:0\", shape=(2787, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_17:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_16:0\", shape=(168, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_14:0\", shape=(509,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_13:0\", shape=(509, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_17:0\", shape=(3332,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_16:0\", shape=(3332, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_20:0\", shape=(2787,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_19:0\", shape=(2787, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_23:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_22:0\", shape=(168, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_39/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_39/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_38/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_38/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_37/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1024 validation: mean-matthews_corrcoef=0.235187 mean-accuracy_score=0.955908 mean-roc_auc_score=0.839541\n",
      "Step 2048 validation: mean-matthews_corrcoef=0.273997 mean-accuracy_score=0.957049 mean-roc_auc_score=0.860871\n",
      "Step 3072 validation: mean-matthews_corrcoef=0.279093 mean-accuracy_score=0.957831 mean-roc_auc_score=0.872431\n",
      "Step 4096 validation: mean-matthews_corrcoef=0.192551 mean-accuracy_score=0.956625 mean-roc_auc_score=0.870914\n",
      "Step 5120 validation: mean-matthews_corrcoef=0.319881 mean-accuracy_score=0.959134 mean-roc_auc_score=0.879366\n",
      "Step 6144 validation: mean-matthews_corrcoef=0.338821 mean-accuracy_score=0.959721 mean-roc_auc_score=0.884851\n",
      "Step 7168 validation: mean-matthews_corrcoef=0.361393 mean-accuracy_score=0.959134 mean-roc_auc_score=0.879515\n",
      "Step 8192 validation: mean-matthews_corrcoef=0.394698 mean-accuracy_score=0.960992 mean-roc_auc_score=0.88814\n",
      "Step 9216 validation: mean-matthews_corrcoef=0.394254 mean-accuracy_score=0.960373 mean-roc_auc_score=0.886989\n",
      "Step 10240 validation: mean-matthews_corrcoef=0.359926 mean-accuracy_score=0.960471 mean-roc_auc_score=0.892014\n",
      "Step 11264 validation: mean-matthews_corrcoef=0.401678 mean-accuracy_score=0.961057 mean-roc_auc_score=0.891394\n",
      "Step 12288 validation: mean-matthews_corrcoef=0.414099 mean-accuracy_score=0.961611 mean-roc_auc_score=0.894095\n",
      "Step 13312 validation: mean-matthews_corrcoef=0.384497 mean-accuracy_score=0.961025 mean-roc_auc_score=0.890146\n",
      "Step 14336 validation: mean-matthews_corrcoef=0.389223 mean-accuracy_score=0.960959 mean-roc_auc_score=0.89345\n",
      "Step 15360 validation: mean-matthews_corrcoef=0.444494 mean-accuracy_score=0.962556 mean-roc_auc_score=0.896963\n",
      "Step 16384 validation: mean-matthews_corrcoef=0.385236 mean-accuracy_score=0.961611 mean-roc_auc_score=0.898016\n",
      "Step 17408 validation: mean-matthews_corrcoef=0.444817 mean-accuracy_score=0.962556 mean-roc_auc_score=0.899822\n",
      "Step 18432 validation: mean-matthews_corrcoef=0.409916 mean-accuracy_score=0.962133 mean-roc_auc_score=0.894693\n",
      "Step 19456 validation: mean-matthews_corrcoef=0.441197 mean-accuracy_score=0.962524 mean-roc_auc_score=0.900378\n",
      "Step 20480 validation: mean-matthews_corrcoef=0.393276 mean-accuracy_score=0.961807 mean-roc_auc_score=0.899239\n",
      "Step 21504 validation: mean-matthews_corrcoef=0.429838 mean-accuracy_score=0.962263 mean-roc_auc_score=0.895439\n",
      "Step 22528 validation: mean-matthews_corrcoef=0.433764 mean-accuracy_score=0.962817 mean-roc_auc_score=0.901077\n",
      "Step 23552 validation: mean-matthews_corrcoef=0.459559 mean-accuracy_score=0.963599 mean-roc_auc_score=0.902047\n",
      "Step 24576 validation: mean-matthews_corrcoef=0.468287 mean-accuracy_score=0.960959 mean-roc_auc_score=0.902231\n",
      "Step 25600 validation: mean-matthews_corrcoef=0.480982 mean-accuracy_score=0.963958 mean-roc_auc_score=0.904058\n",
      "Step 26624 validation: mean-matthews_corrcoef=0.480488 mean-accuracy_score=0.962296 mean-roc_auc_score=0.901883\n",
      "Step 27648 validation: mean-matthews_corrcoef=0.492151 mean-accuracy_score=0.963012 mean-roc_auc_score=0.904814\n",
      "Step 28672 validation: mean-matthews_corrcoef=0.468926 mean-accuracy_score=0.963762 mean-roc_auc_score=0.903155\n",
      "Step 29696 validation: mean-matthews_corrcoef=0.457794 mean-accuracy_score=0.963436 mean-roc_auc_score=0.902956\n",
      "Step 30720 validation: mean-matthews_corrcoef=0.474223 mean-accuracy_score=0.96285 mean-roc_auc_score=0.899926\n",
      "Step 31744 validation: mean-matthews_corrcoef=0.465433 mean-accuracy_score=0.962719 mean-roc_auc_score=0.901698\n",
      "Step 32768 validation: mean-matthews_corrcoef=0.48216 mean-accuracy_score=0.962263 mean-roc_auc_score=0.90151\n",
      "Step 33792 validation: mean-matthews_corrcoef=0.469063 mean-accuracy_score=0.963599 mean-roc_auc_score=0.907304\n",
      "Step 34816 validation: mean-matthews_corrcoef=0.478621 mean-accuracy_score=0.961807 mean-roc_auc_score=0.902683\n",
      "Step 35840 validation: mean-matthews_corrcoef=0.490873 mean-accuracy_score=0.963078 mean-roc_auc_score=0.905538\n",
      "Step 36864 validation: mean-matthews_corrcoef=0.488684 mean-accuracy_score=0.963925 mean-roc_auc_score=0.904126\n",
      "Step 37888 validation: mean-matthews_corrcoef=0.466133 mean-accuracy_score=0.962784 mean-roc_auc_score=0.903923\n",
      "Step 38912 validation: mean-matthews_corrcoef=0.476777 mean-accuracy_score=0.962784 mean-roc_auc_score=0.903328\n",
      "Step 39936 validation: mean-matthews_corrcoef=0.495391 mean-accuracy_score=0.96399 mean-roc_auc_score=0.904976\n",
      "Step 40960 validation: mean-matthews_corrcoef=0.483118 mean-accuracy_score=0.963371 mean-roc_auc_score=0.900761\n",
      "Step 41984 validation: mean-matthews_corrcoef=0.500077 mean-accuracy_score=0.963795 mean-roc_auc_score=0.904966\n",
      "Step 43008 validation: mean-matthews_corrcoef=0.48068 mean-accuracy_score=0.96298 mean-roc_auc_score=0.903186\n",
      "Step 44032 validation: mean-matthews_corrcoef=0.476917 mean-accuracy_score=0.962198 mean-roc_auc_score=0.903373\n",
      "Step 45056 validation: mean-matthews_corrcoef=0.467609 mean-accuracy_score=0.960601 mean-roc_auc_score=0.901857\n",
      "Step 46080 validation: mean-matthews_corrcoef=0.470115 mean-accuracy_score=0.96386 mean-roc_auc_score=0.904827\n",
      "Step 47104 validation: mean-matthews_corrcoef=0.482112 mean-accuracy_score=0.962328 mean-roc_auc_score=0.903922\n",
      "Step 48128 validation: mean-matthews_corrcoef=0.482352 mean-accuracy_score=0.961774 mean-roc_auc_score=0.903831\n",
      "Step 49152 validation: mean-matthews_corrcoef=0.486282 mean-accuracy_score=0.961611 mean-roc_auc_score=0.90364\n",
      "Step 50176 validation: mean-matthews_corrcoef=0.474578 mean-accuracy_score=0.962915 mean-roc_auc_score=0.902515\n",
      "Step 51200 validation: mean-matthews_corrcoef=0.479215 mean-accuracy_score=0.961872 mean-roc_auc_score=0.902297\n",
      "Step 52224 validation: mean-matthews_corrcoef=0.474694 mean-accuracy_score=0.963078 mean-roc_auc_score=0.905548\n",
      "Step 53248 validation: mean-matthews_corrcoef=0.460953 mean-accuracy_score=0.95946 mean-roc_auc_score=0.9003\n",
      "Step 54272 validation: mean-matthews_corrcoef=0.482062 mean-accuracy_score=0.961742 mean-roc_auc_score=0.902837\n",
      "Step 55296 validation: mean-matthews_corrcoef=0.465764 mean-accuracy_score=0.961481 mean-roc_auc_score=0.901224\n",
      "Step 56320 validation: mean-matthews_corrcoef=0.487097 mean-accuracy_score=0.963208 mean-roc_auc_score=0.903429\n",
      "Step 57344 validation: mean-matthews_corrcoef=0.46887 mean-accuracy_score=0.958711 mean-roc_auc_score=0.900975\n",
      "Step 58368 validation: mean-matthews_corrcoef=0.468659 mean-accuracy_score=0.961644 mean-roc_auc_score=0.902602\n",
      "Step 59392 validation: mean-matthews_corrcoef=0.488817 mean-accuracy_score=0.960438 mean-roc_auc_score=0.89979\n",
      "Step 60416 validation: mean-matthews_corrcoef=0.480252 mean-accuracy_score=0.961383 mean-roc_auc_score=0.901629\n",
      "Step 61440 validation: mean-matthews_corrcoef=0.476216 mean-accuracy_score=0.962263 mean-roc_auc_score=0.900308\n",
      "Step 62464 validation: mean-matthews_corrcoef=0.49004 mean-accuracy_score=0.961057 mean-roc_auc_score=0.901882\n",
      "Step 63488 validation: mean-matthews_corrcoef=0.478833 mean-accuracy_score=0.961644 mean-roc_auc_score=0.900793\n",
      "Step 64512 validation: mean-matthews_corrcoef=0.462196 mean-accuracy_score=0.961611 mean-roc_auc_score=0.900961\n",
      "Step 65536 validation: mean-matthews_corrcoef=0.478093 mean-accuracy_score=0.962491 mean-roc_auc_score=0.900901\n",
      "Step 66560 validation: mean-matthews_corrcoef=0.483022 mean-accuracy_score=0.96135 mean-roc_auc_score=0.89938\n",
      "Step 67584 validation: mean-matthews_corrcoef=0.478174 mean-accuracy_score=0.961904 mean-roc_auc_score=0.900543\n",
      "Step 68608 validation: mean-matthews_corrcoef=0.476006 mean-accuracy_score=0.961742 mean-roc_auc_score=0.9026\n",
      "Step 69632 validation: mean-matthews_corrcoef=0.47709 mean-accuracy_score=0.961057 mean-roc_auc_score=0.901231\n",
      "Step 70656 validation: mean-matthews_corrcoef=0.490066 mean-accuracy_score=0.958548 mean-roc_auc_score=0.899184\n",
      "Step 71680 validation: mean-matthews_corrcoef=0.475968 mean-accuracy_score=0.961774 mean-roc_auc_score=0.897968\n",
      "Step 72704 validation: mean-matthews_corrcoef=0.476769 mean-accuracy_score=0.96197 mean-roc_auc_score=0.899311\n",
      "Step 73728 validation: mean-matthews_corrcoef=0.468123 mean-accuracy_score=0.960862 mean-roc_auc_score=0.902311\n",
      "Step 74752 validation: mean-matthews_corrcoef=0.492401 mean-accuracy_score=0.960503 mean-roc_auc_score=0.900822\n",
      "Step 75776 validation: mean-matthews_corrcoef=0.474533 mean-accuracy_score=0.96034 mean-roc_auc_score=0.898543\n",
      "Step 76800 validation: mean-matthews_corrcoef=0.48056 mean-accuracy_score=0.962198 mean-roc_auc_score=0.901153\n",
      "Step 77824 validation: mean-matthews_corrcoef=0.477862 mean-accuracy_score=0.959428 mean-roc_auc_score=0.89891\n",
      "Step 78848 validation: mean-matthews_corrcoef=0.495403 mean-accuracy_score=0.962165 mean-roc_auc_score=0.901252\n",
      "Step 79872 validation: mean-matthews_corrcoef=0.474932 mean-accuracy_score=0.960764 mean-roc_auc_score=0.900695\n",
      "Step 80896 validation: mean-matthews_corrcoef=0.464591 mean-accuracy_score=0.959819 mean-roc_auc_score=0.90053\n",
      "Step 81920 validation: mean-matthews_corrcoef=0.47491 mean-accuracy_score=0.960471 mean-roc_auc_score=0.898673\n",
      "Step 82944 validation: mean-matthews_corrcoef=0.495 mean-accuracy_score=0.961253 mean-roc_auc_score=0.899982\n",
      "Step 83968 validation: mean-matthews_corrcoef=0.469398 mean-accuracy_score=0.960014 mean-roc_auc_score=0.898742\n",
      "Step 84992 validation: mean-matthews_corrcoef=0.473483 mean-accuracy_score=0.96034 mean-roc_auc_score=0.901333\n",
      "Step 86016 validation: mean-matthews_corrcoef=0.458513 mean-accuracy_score=0.958255 mean-roc_auc_score=0.897337\n",
      "Step 87040 validation: mean-matthews_corrcoef=0.467807 mean-accuracy_score=0.959819 mean-roc_auc_score=0.898791\n",
      "Step 88064 validation: mean-matthews_corrcoef=0.474433 mean-accuracy_score=0.960242 mean-roc_auc_score=0.900548\n",
      "Step 89088 validation: mean-matthews_corrcoef=0.481202 mean-accuracy_score=0.961057 mean-roc_auc_score=0.899512\n",
      "Step 90112 validation: mean-matthews_corrcoef=0.483974 mean-accuracy_score=0.958972 mean-roc_auc_score=0.898145\n",
      "Step 91136 validation: mean-matthews_corrcoef=0.470567 mean-accuracy_score=0.960242 mean-roc_auc_score=0.89882\n",
      "Step 92160 validation: mean-matthews_corrcoef=0.494648 mean-accuracy_score=0.960959 mean-roc_auc_score=0.901538\n",
      "Step 93184 validation: mean-matthews_corrcoef=0.477378 mean-accuracy_score=0.961481 mean-roc_auc_score=0.899876\n",
      "Step 94208 validation: mean-matthews_corrcoef=0.477355 mean-accuracy_score=0.961742 mean-roc_auc_score=0.899443\n",
      "Step 95232 validation: mean-matthews_corrcoef=0.481162 mean-accuracy_score=0.960471 mean-roc_auc_score=0.899918\n"
     ]
    }
   ],
   "source": [
    "hist18 = model18.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1394182d-2099-4573-879c-ab854b2457a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.9336822419012412, 'mean-accuracy_score': 0.9943908559138384, 'mean-roc_auc_score': 0.9991360995012725}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.47689518696611505, 'mean-accuracy_score': 0.9596232809750375, 'mean-roc_auc_score': 0.8967864878307685}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.4639100959675954, 'mean-accuracy_score': 0.959559422556783, 'mean-roc_auc_score': 0.895078024261657}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.5000765849173642, 'mean-accuracy_score': 0.9637945642964219, 'mean-roc_auc_score': 0.9049660484024109}\n",
      "Loss? = 0.026622450351715087\n",
      "[[29011   301]\n",
      " [  810   564]]\n",
      "Specificity = 0.9897\n",
      "FPR = 0.0103\n",
      "Recall/TPR = 0.4105\n",
      "Precision = 0.652\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model18, hist18, save_dir18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8b751-0456-43d5-b1d2-b3dd894e2118",
   "metadata": {},
   "source": [
    "#### Model 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa473c3-a5bb-474c-836b-b81c4754e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. 3 GCN layers (1024, 2048); 1-layer FNN (256); 50 epochs; ExponentialDecay(0.001, 0.7, 1024) learning rate:  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a608591-eb9f-4adc-9bc7-7db04cbabb49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m learning_rate19 \u001b[38;5;241m=\u001b[39m \u001b[43mdc\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mExponentialDecay(\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m      2\u001b[0m save_dir19\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_home_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/models/gcn_model_19\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m model19 \u001b[38;5;241m=\u001b[39m GraphConvModel(\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      5\u001b[0m                          dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m      6\u001b[0m                          graph_conv_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m2048\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                          learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate19,\n\u001b[1;32m     11\u001b[0m                          model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_home_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/models/gcn_model_19\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate19 = dc.models.optimizers.ExponentialDecay(0.001, 0.7, 1024)\n",
    "save_dir19=f'{get_home_path()}/models/gcn_model_19'\n",
    "\n",
    "model19 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[1024, 2048],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         learning_rate=learning_rate19,\n",
    "                         model_dir=f'{get_home_path()}/models/gcn_model_19')\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1024,\n",
    "                                        metrics,\n",
    "                                        save_dir=f'{save_dir19}/callbacks',\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d0e6e-cc38-4f36-b651-765e8862d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_14:0\", shape=(579,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_13:0\", shape=(579, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_17:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_16:0\", shape=(3272, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_20:0\", shape=(2865,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_19:0\", shape=(2865, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_23:0\", shape=(192,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_22:0\", shape=(192, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_11:0\", shape=(579,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_10:0\", shape=(579, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_13:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_12:0\", shape=(3272, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_15:0\", shape=(2865,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_14:0\", shape=(2865, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_17:0\", shape=(192,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_16:0\", shape=(192, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_18:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_20:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_22:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_24:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_26:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_28:0\", shape=(0, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_14:0\", shape=(579,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_13:0\", shape=(579, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_17:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_16:0\", shape=(3272, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_20:0\", shape=(2865,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_19:0\", shape=(2865, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_23:0\", shape=(192,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_22:0\", shape=(192, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_14:0\", shape=(539,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_13:0\", shape=(539, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_17:0\", shape=(3386,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_16:0\", shape=(3386, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_20:0\", shape=(2967,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_19:0\", shape=(2967, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_23:0\", shape=(164,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_22:0\", shape=(164, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_11:0\", shape=(539,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_10:0\", shape=(539, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_13:0\", shape=(3386,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_12:0\", shape=(3386, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_15:0\", shape=(2967,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_14:0\", shape=(2967, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_17:0\", shape=(164,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_16:0\", shape=(164, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_14:0\", shape=(539,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_13:0\", shape=(539, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_17:0\", shape=(3386,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_16:0\", shape=(3386, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_20:0\", shape=(2967,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_19:0\", shape=(2967, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_23:0\", shape=(164,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_22:0\", shape=(164, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_13:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_16:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_19:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Reshape_22:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_41/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_10:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_12:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_14:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_conv_41/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_18/graph_pool_40/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1024 validation: mean-matthews_corrcoef=0.146067 mean-accuracy_score=0.955713 mean-roc_auc_score=0.820403\n",
      "Step 2048 validation: mean-matthews_corrcoef=0.293016 mean-accuracy_score=0.95304 mean-roc_auc_score=0.836766\n",
      "Step 3072 validation: mean-matthews_corrcoef=0.199936 mean-accuracy_score=0.956951 mean-roc_auc_score=0.846428\n",
      "Step 4096 validation: mean-matthews_corrcoef=0.148367 mean-accuracy_score=0.954768 mean-roc_auc_score=0.83563\n",
      "Step 5120 validation: mean-matthews_corrcoef=0.252259 mean-accuracy_score=0.95744 mean-roc_auc_score=0.866396\n",
      "Step 6144 validation: mean-matthews_corrcoef=0.2774 mean-accuracy_score=0.958026 mean-roc_auc_score=0.860492\n",
      "Step 7168 validation: mean-matthews_corrcoef=0.305461 mean-accuracy_score=0.958809 mean-roc_auc_score=0.855304\n",
      "Step 8192 validation: mean-matthews_corrcoef=0.326763 mean-accuracy_score=0.959134 mean-roc_auc_score=0.871506\n",
      "Step 9216 validation: mean-matthews_corrcoef=0.296153 mean-accuracy_score=0.958841 mean-roc_auc_score=0.868155\n",
      "Step 10240 validation: mean-matthews_corrcoef=0.260891 mean-accuracy_score=0.958059 mean-roc_auc_score=0.865012\n",
      "Step 11264 validation: mean-matthews_corrcoef=0.365382 mean-accuracy_score=0.958385 mean-roc_auc_score=0.876019\n",
      "Step 12288 validation: mean-matthews_corrcoef=0.318319 mean-accuracy_score=0.959623 mean-roc_auc_score=0.886851\n",
      "Step 13312 validation: mean-matthews_corrcoef=0.2729 mean-accuracy_score=0.958548 mean-roc_auc_score=0.886322\n",
      "Step 14336 validation: mean-matthews_corrcoef=0.386358 mean-accuracy_score=0.960699 mean-roc_auc_score=0.89042\n",
      "Step 15360 validation: mean-matthews_corrcoef=0.356271 mean-accuracy_score=0.959493 mean-roc_auc_score=0.890156\n",
      "Step 16384 validation: mean-matthews_corrcoef=0.431344 mean-accuracy_score=0.957016 mean-roc_auc_score=0.884154\n",
      "Step 17408 validation: mean-matthews_corrcoef=0.414052 mean-accuracy_score=0.958124 mean-roc_auc_score=0.889251\n",
      "Step 18432 validation: mean-matthews_corrcoef=0.363955 mean-accuracy_score=0.960894 mean-roc_auc_score=0.89763\n",
      "Step 19456 validation: mean-matthews_corrcoef=0.395572 mean-accuracy_score=0.961285 mean-roc_auc_score=0.89518\n",
      "Step 20480 validation: mean-matthews_corrcoef=0.419344 mean-accuracy_score=0.962035 mean-roc_auc_score=0.892309\n",
      "Step 21504 validation: mean-matthews_corrcoef=0.388108 mean-accuracy_score=0.961742 mean-roc_auc_score=0.894094\n",
      "Step 22528 validation: mean-matthews_corrcoef=0.422523 mean-accuracy_score=0.962361 mean-roc_auc_score=0.896978\n",
      "Step 23552 validation: mean-matthews_corrcoef=0.459692 mean-accuracy_score=0.96109 mean-roc_auc_score=0.899067\n",
      "Step 24576 validation: mean-matthews_corrcoef=0.394529 mean-accuracy_score=0.961774 mean-roc_auc_score=0.896908\n",
      "Step 25600 validation: mean-matthews_corrcoef=0.431977 mean-accuracy_score=0.961285 mean-roc_auc_score=0.897229\n",
      "Step 26624 validation: mean-matthews_corrcoef=0.461819 mean-accuracy_score=0.960503 mean-roc_auc_score=0.902582\n",
      "Step 27648 validation: mean-matthews_corrcoef=0.443424 mean-accuracy_score=0.961122 mean-roc_auc_score=0.900848\n",
      "Step 28672 validation: mean-matthews_corrcoef=0.471212 mean-accuracy_score=0.962491 mean-roc_auc_score=0.899053\n",
      "Step 29696 validation: mean-matthews_corrcoef=0.473532 mean-accuracy_score=0.962361 mean-roc_auc_score=0.899105\n",
      "Step 30720 validation: mean-matthews_corrcoef=0.462432 mean-accuracy_score=0.963664 mean-roc_auc_score=0.905717\n",
      "Step 31744 validation: mean-matthews_corrcoef=0.462482 mean-accuracy_score=0.963273 mean-roc_auc_score=0.896438\n",
      "Step 32768 validation: mean-matthews_corrcoef=0.434938 mean-accuracy_score=0.963306 mean-roc_auc_score=0.897401\n",
      "Step 33792 validation: mean-matthews_corrcoef=0.471329 mean-accuracy_score=0.963534 mean-roc_auc_score=0.902605\n",
      "Step 34816 validation: mean-matthews_corrcoef=0.48378 mean-accuracy_score=0.962296 mean-roc_auc_score=0.901025\n",
      "Step 35840 validation: mean-matthews_corrcoef=0.450826 mean-accuracy_score=0.963241 mean-roc_auc_score=0.895031\n",
      "Step 36864 validation: mean-matthews_corrcoef=0.498644 mean-accuracy_score=0.959656 mean-roc_auc_score=0.903948\n",
      "Step 39936 validation: mean-matthews_corrcoef=0.454329 mean-accuracy_score=0.962328 mean-roc_auc_score=0.892651\n",
      "Step 40960 validation: mean-matthews_corrcoef=0.476229 mean-accuracy_score=0.963338 mean-roc_auc_score=0.895953\n",
      "Step 41984 validation: mean-matthews_corrcoef=0.47654 mean-accuracy_score=0.963338 mean-roc_auc_score=0.895334\n",
      "Step 43008 validation: mean-matthews_corrcoef=0.475525 mean-accuracy_score=0.963273 mean-roc_auc_score=0.898486\n",
      "Step 44032 validation: mean-matthews_corrcoef=0.50197 mean-accuracy_score=0.961579 mean-roc_auc_score=0.898728\n",
      "Step 45056 validation: mean-matthews_corrcoef=0.466547 mean-accuracy_score=0.962882 mean-roc_auc_score=0.893172\n",
      "Step 46080 validation: mean-matthews_corrcoef=0.485895 mean-accuracy_score=0.961644 mean-roc_auc_score=0.897867\n",
      "Step 47104 validation: mean-matthews_corrcoef=0.478104 mean-accuracy_score=0.963566 mean-roc_auc_score=0.900692\n",
      "Step 48128 validation: mean-matthews_corrcoef=0.486325 mean-accuracy_score=0.959102 mean-roc_auc_score=0.898456\n",
      "Step 49152 validation: mean-matthews_corrcoef=0.504689 mean-accuracy_score=0.961383 mean-roc_auc_score=0.901369\n",
      "Step 50176 validation: mean-matthews_corrcoef=0.50751 mean-accuracy_score=0.961025 mean-roc_auc_score=0.898052\n",
      "Step 51200 validation: mean-matthews_corrcoef=0.470518 mean-accuracy_score=0.963697 mean-roc_auc_score=0.899173\n",
      "Step 52224 validation: mean-matthews_corrcoef=0.490463 mean-accuracy_score=0.962524 mean-roc_auc_score=0.899714\n",
      "Step 53248 validation: mean-matthews_corrcoef=0.488807 mean-accuracy_score=0.958418 mean-roc_auc_score=0.8977\n",
      "Step 54272 validation: mean-matthews_corrcoef=0.488254 mean-accuracy_score=0.958287 mean-roc_auc_score=0.897516\n",
      "Step 55296 validation: mean-matthews_corrcoef=0.455059 mean-accuracy_score=0.960894 mean-roc_auc_score=0.889158\n",
      "Step 56320 validation: mean-matthews_corrcoef=0.492018 mean-accuracy_score=0.959167 mean-roc_auc_score=0.896618\n",
      "Step 57344 validation: mean-matthews_corrcoef=0.489408 mean-accuracy_score=0.959982 mean-roc_auc_score=0.894625\n",
      "Step 58368 validation: mean-matthews_corrcoef=0.468596 mean-accuracy_score=0.959102 mean-roc_auc_score=0.891502\n",
      "Step 59392 validation: mean-matthews_corrcoef=0.488541 mean-accuracy_score=0.963827 mean-roc_auc_score=0.900579\n",
      "Step 60416 validation: mean-matthews_corrcoef=0.483616 mean-accuracy_score=0.958874 mean-roc_auc_score=0.898595\n",
      "Step 61440 validation: mean-matthews_corrcoef=0.490868 mean-accuracy_score=0.960568 mean-roc_auc_score=0.895106\n",
      "Step 62464 validation: mean-matthews_corrcoef=0.450113 mean-accuracy_score=0.962915 mean-roc_auc_score=0.898555\n",
      "Step 63488 validation: mean-matthews_corrcoef=0.488124 mean-accuracy_score=0.961513 mean-roc_auc_score=0.894873\n",
      "Step 64512 validation: mean-matthews_corrcoef=0.486438 mean-accuracy_score=0.962263 mean-roc_auc_score=0.898386\n",
      "Step 65536 validation: mean-matthews_corrcoef=0.492669 mean-accuracy_score=0.962002 mean-roc_auc_score=0.898407\n",
      "Step 66560 validation: mean-matthews_corrcoef=0.482146 mean-accuracy_score=0.955191 mean-roc_auc_score=0.893487\n"
     ]
    }
   ],
   "source": [
    "hist19 = model19.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00afc72c-6742-45c7-b0a5-8b8d291be512",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model19' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist19 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel19\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_dataset, nb_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39mvalidation, restore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model19' is not defined"
     ]
    }
   ],
   "source": [
    "hist19 = model19.fit(train_dataset, nb_epoch=5, callbacks=validation, restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d280d8-8e14-4241-bb98-d14c610a25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model19, hist19, save_dir19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773ff96-c544-4842-82ee-42cf09873052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd78799-d597-4ff4-aeec-b3a4ba98de3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b69c533-29c0-4fb2-bfb8-3d916de3e206",
   "metadata": {},
   "source": [
    "## Best model (# 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb93fc2-8822-4157-8e54-17e6ed33a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate17 = dc.models.optimizers.ExponentialDecay(0.0001, 0.8, 1024)\n",
    "save_dir17=f'{get_home_path()}/models/gcn_model_17'\n",
    "\n",
    "model17 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[512, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         learning_rate=learning_rate17,\n",
    "                         model_dir=save_dir17)\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1024,\n",
    "                                        metrics,\n",
    "                                        save_dir=f'{save_dir17}/callbacks',\n",
    "                                        save_on_minimum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca3dcc46-be02-420b-8472-e0f628fdfc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 01:23:39.118488: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "save_dir13=f'{get_home_path()}/models/gcn_model_13'\n",
    "\n",
    "model13 = GraphConvModel(1, batch_size=128,\n",
    "                         dropout=0.0,\n",
    "                         graph_conv_layers=[64, 256, 1024],\n",
    "                         dense_layer_size=256,\n",
    "                         mode='classification',\n",
    "                         tensorboard=True,\n",
    "                         model_dir=save_dir13)\n",
    "validation=dc.models.ValidationCallback(valid_dataset,\n",
    "                                        1000,\n",
    "                                        metrics,\n",
    "                                        save_dir=f'{save_dir13}/callbacks',\n",
    "                                        save_on_minimum=False)\n",
    "\n",
    "# hist13 = model13.fit(train_dataset, nb_epoch=50, callbacks=validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9d82bfb-e074-4e58-baf9-56d0ab5d6545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_14:0\", shape=(554,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_13:0\", shape=(554, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_17:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_16:0\", shape=(3272, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_20:0\", shape=(2868,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_19:0\", shape=(2868, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_23:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_22:0\", shape=(152, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_11:0\", shape=(554,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_10:0\", shape=(554, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_13:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_12:0\", shape=(3272, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_15:0\", shape=(2868,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_14:0\", shape=(2868, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_17:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_16:0\", shape=(152, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(554,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(554, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(3272, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(2868,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(2868, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(152, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(554,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(554, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(3272, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(2868,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(2868, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(152, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(554,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(554, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(3272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(3272, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(2868,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(2868, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(152,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(152, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_14:0\", shape=(549,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_13:0\", shape=(549, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_17:0\", shape=(3258,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_16:0\", shape=(3258, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_20:0\", shape=(2955,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_19:0\", shape=(2955, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_23:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_22:0\", shape=(168, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_11:0\", shape=(549,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_10:0\", shape=(549, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_13:0\", shape=(3258,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_12:0\", shape=(3258, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_15:0\", shape=(2955,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_14:0\", shape=(2955, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_17:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_16:0\", shape=(168, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(549,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(549, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(3258,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(3258, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(2955,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(2955, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(168, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(549,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(549, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(3258,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(3258, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(2955,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(2955, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(168, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(549,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(549, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(3258,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(3258, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(2955,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(2955, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(168,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(168, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_13:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_16:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_19:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Reshape_22:0\", shape=(None, 1024), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_2/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: mean-matthews_corrcoef=0.772512 mean-accuracy_score=0.98149 mean-roc_auc_score=0.975982\n",
      "Step 2000 validation: mean-matthews_corrcoef=0.762117 mean-accuracy_score=0.979665 mean-roc_auc_score=0.97507\n",
      "Step 3000 validation: mean-matthews_corrcoef=0.751655 mean-accuracy_score=0.979893 mean-roc_auc_score=0.974703\n",
      "Step 4000 validation: mean-matthews_corrcoef=0.747432 mean-accuracy_score=0.980154 mean-roc_auc_score=0.97714\n",
      "Step 5000 validation: mean-matthews_corrcoef=0.739306 mean-accuracy_score=0.978459 mean-roc_auc_score=0.975169\n",
      "Step 6000 validation: mean-matthews_corrcoef=0.738351 mean-accuracy_score=0.978394 mean-roc_auc_score=0.975594\n",
      "Step 7000 validation: mean-matthews_corrcoef=0.73096 mean-accuracy_score=0.978003 mean-roc_auc_score=0.973294\n",
      "Step 8000 validation: mean-matthews_corrcoef=0.723854 mean-accuracy_score=0.976667 mean-roc_auc_score=0.9737\n",
      "Step 9000 validation: mean-matthews_corrcoef=0.712892 mean-accuracy_score=0.976374 mean-roc_auc_score=0.97198\n"
     ]
    }
   ],
   "source": [
    "hist13_best = model13.fit(train_dataset, nb_epoch=5, callbacks=validation, restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9176d62-e8c3-4084-be9d-45c100874864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'mean-matthews_corrcoef': 0.8825508832528524, 'mean-accuracy_score': 0.9903581379433953, 'mean-roc_auc_score': 0.9971828569919132}\n",
      "Validation set score: {'mean-matthews_corrcoef': 0.7016626595445933, 'mean-accuracy_score': 0.9764061787134198, 'mean-roc_auc_score': 0.9717915629787126}\n",
      "Test set score: {'mean-matthews_corrcoef': 0.6971947796427883, 'mean-accuracy_score': 0.9764721217453645, 'mean-roc_auc_score': 0.96960797085872}\n",
      "Best validation set score: {'mean-matthews_corrcoef': 0.7725118931351501, 'mean-accuracy_score': 0.981489930261357, 'mean-roc_auc_score': 0.9759823837741461}\n",
      "Loss? = 0.03768966727786594\n",
      "[[29108   204]\n",
      " [  364  1010]]\n",
      "Specificity = 0.993\n",
      "FPR = 0.007\n",
      "Recall/TPR = 0.7351\n",
      "Precision = 0.832\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model13, hist13_best, save_dir13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b796125-192a-4225-9078-a271d805df11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9.5111984e-01, 4.8880164e-02]],\n",
       "\n",
       "       [[1.0000000e+00, 4.7359467e-11]],\n",
       "\n",
       "       [[1.0000000e+00, 7.4841120e-09]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[9.9971813e-01, 2.8183195e-04]],\n",
       "\n",
       "       [[9.9991405e-01, 8.5994427e-05]],\n",
       "\n",
       "       [[9.8682678e-01, 1.3173239e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13.predict(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71f9bb9a-a3d7-49c4-869a-48f6dea36f5c",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred13 = [x.flatten() for x in model13.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b37fca8-ea15-4aa1-8fb9-399c16f8f3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.888016e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.735947e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.484112e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.485819e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.288217e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_values    pred_probs\n",
       "0          0.0  4.888016e-02\n",
       "1          0.0  4.735947e-11\n",
       "2          0.0  7.484112e-09\n",
       "3          0.0  1.485819e-05\n",
       "4          0.0  1.288217e-02"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred13_df = pd.DataFrame({'true_values': valid_dataset.y.flatten(),\n",
    "                        'pred_probs': np.array([x[1] for x in pred13])})\n",
    "\n",
    "pred13_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7354ca0f-14d9-46d0-bbbc-42e39fbab5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajayi/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "\n",
    "# plot distributions of predicted probabilities by actual values\n",
    "for group in pred13_df.groupby('true_values'):\n",
    "    sns.distplot(group[1], kde = False, bins = 20, label = f'Actual Outcome = {group[0]}')\n",
    "\n",
    "#Add cutoff line\n",
    "plt.axvline(0.5, color = 'black')\n",
    "\n",
    "plt.xlabel('Predicted Probability that molecule is active')\n",
    "plt.legend(labels=herg_df.label.unique())\n",
    "plt.ylim(0, 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6675e6a5-23d1-4d2e-9993-52f3f5555a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29108   204]\n",
      " [  364  1010]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(valid_dataset.y, [round(x[1]) for x in pred13])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4ed42e4-ff21-411d-91a3-eb2d57f62d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.993\n",
      "FPR = 0.007\n",
      "Recall/TPR = 0.7351\n",
      "Precision = 0.832\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# specificity\n",
    "print(f'Specificity = {round(tn/(tn+fp), 4)}')\n",
    "\n",
    "# 1- specificity\n",
    "print(f'FPR = {round(fp/(tn+fp), 4)}')\n",
    "\n",
    "# sensitivity\n",
    "print(f'Recall/TPR = {round(tp/(tp+fn), 4)}')\n",
    "\n",
    "print(f'Precision = {round(tp/(tp+fp), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5377957a-e39b-4381-a8db-eb75c374ed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdb4dff9a30>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(cm, display_labels=herg_df.label.unique()).plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d0ba2c7-fd98-4c05-8a0e-165873ee9adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30686, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7428fdae-a5fc-4b9e-ac8f-959b1269cf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30686, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([x for x in np.array(pred13)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36d7d7bf-058d-48d2-9551-79cd5fbbefdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30686, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([x.flatten() for x in np.array(pred13)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1af38115-2cca-4b24-a9cb-3a3c9d1ee93f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (30686, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mRocCurveDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred13\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/sklearn/metrics/_plot/roc_curve.py:333\u001b[0m, in \u001b[0;36mRocCurveDisplay.from_predictions\u001b[0;34m(cls, y_true, y_pred, sample_weight, drop_intermediate, pos_label, name, ax, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"Plot ROC curve given the true and predicted values.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <visualizations>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m>>> plt.show()\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m check_matplotlib_support(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.from_predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_intermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_intermediate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n\u001b[1;32m    342\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:962\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    874\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    875\u001b[0m ):\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    960\u001b[0m \n\u001b[1;32m    961\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 962\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:735\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    733\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    734\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m--> 735\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m assert_all_finite(y_true)\n\u001b[1;32m    737\u001b[0m assert_all_finite(y_score)\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/sklearn/utils/validation.py:1038\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1030\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1040\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (30686, 2) instead."
     ]
    }
   ],
   "source": [
    "RocCurveDisplay.from_predictions(valid_dataset.y, pred13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19d29c-8162-4480-a049-52fdd62f025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay(round(fp/(tn+fp), 4), round(tp/(tp+fn), 4), dc.metrics.roc_auc_score, np.mean, mode='classification') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae5ef4a1-0fe0-45d0-be2b-6b2011d78520",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred13\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2110\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[1;32m   1999\u001b[0m     y_true,\n\u001b[1;32m   2000\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2008\u001b[0m ):\n\u001b[1;32m   2009\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m \n\u001b[1;32m   2011\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2110\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2113\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone_cf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "classification_report(valid_dataset.y, pred13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a81b1971-b87c-4185-ba7e-3f2bbcdfeeb8",
   "metadata": {
    "id": "66696e41-24a0-4580-87cc-7b48b22ee620"
   },
   "outputs": [],
   "source": [
    "pred13_df2 = pd.DataFrame(pred13,columns=[\"neg\",\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e78a0803-236f-4f38-b7a2-75d27cc07639",
   "metadata": {
    "id": "be31be36-cb52-4632-bb04-0200ec69e9b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred13_df2[\"active\"] = [int(x) for x in valid_dataset.y]\n",
    "pred13_df2[\"SMILES\"] = valid_dataset.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0f2f6aa-da58-4c3d-bf6b-0e521730b7df",
   "metadata": {
    "id": "c7c53979-d386-40a5-93f3-fd9f03680dd4",
    "outputId": "47d3774c-26da-444c-8a70-938f5de226ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>active</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10865</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.572159e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>COc1cc(C(C)=O)ccc1COc1ccc(C(=O)OCC(=O)NC2CCS(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30315</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.931368e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>COCC(=O)N1CCC(Oc2ccc(C(=O)N3CCCCC3COC)cc2)CC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>0.999997</td>\n",
       "      <td>2.689592e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1CCCC(c2ccccc2)N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>9.061893e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(=O)c1nn(-c2cccc(C(F)(F)F)c2)c(=O)[nH]c1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>0.992597</td>\n",
       "      <td>7.403372e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>CCS(=O)(=O)N1Cc2ccccc2CC1C(=O)Nc1nnc(SCc2ccc(C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            neg           pos  active  \\\n",
       "10865  1.000000  3.572159e-08       0   \n",
       "30315  1.000000  2.931368e-09       0   \n",
       "19325  0.999997  2.689592e-06       0   \n",
       "1653   0.999999  9.061893e-07       0   \n",
       "5793   0.992597  7.403372e-03       0   \n",
       "\n",
       "                                                  SMILES  \n",
       "10865  COc1cc(C(C)=O)ccc1COc1ccc(C(=O)OCC(=O)NC2CCS(=...  \n",
       "30315      COCC(=O)N1CCC(Oc2ccc(C(=O)N3CCCCC3COC)cc2)CC1  \n",
       "19325                               O=C1CCCC(c2ccccc2)N1  \n",
       "1653        CC(=O)c1nn(-c2cccc(C(F)(F)F)c2)c(=O)[nH]c1=O  \n",
       "5793   CCS(=O)(=O)N1Cc2ccccc2CC1C(=O)Nc1nnc(SCc2ccc(C...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred13_df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9145177a-0369-4505-914c-9e08b3215070",
   "metadata": {
    "id": "b3e9e4c4-6d7d-4417-ac7b-d765ed990ad0",
    "outputId": "42439c64-3e6f-4217-d22e-c54a2dc0c777"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predicted probabilities for active and inactives\n",
    "sns.boxplot(x=pred13_df2.active, y=pred13_df2.pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "282837c2-d698-4795-863a-d65a6f643ee4",
   "metadata": {
    "id": "29960825-ce31-4a69-82a0-82aefe8ac9d9"
   },
   "outputs": [],
   "source": [
    "# put false negatives in a new dataframe\n",
    "false_negative_df13 = pred13_df2.query(\"active == 1 & pos < 0.2\").copy()\n",
    "PandasTools.AddMoleculeColumnToFrame(false_negative_df13, 'SMILES', 'Mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "361b65c8-1a47-41d4-9770-541f86b81e9a",
   "metadata": {
    "id": "7f1abbdc-317c-478d-893e-4b25120bd4a0",
    "outputId": "3a23ced3-e1f5-45a1-d4bb-6de209e2cf21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>active</th>\n",
       "      <th>Mol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>0.006739</td>\n",
       "      <td>1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25659</th>\n",
       "      <td>0.051656</td>\n",
       "      <td>1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22315</th>\n",
       "      <td>0.178960</td>\n",
       "      <td>1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(false_negative_df13.loc[:, ['pos', 'active', 'Mol']].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fdd58768-a802-408a-bb53-06098fb19d2d",
   "metadata": {
    "id": "c27fce5b-fe58-41cf-94ba-9aeb56903ba8"
   },
   "outputs": [],
   "source": [
    "false_positive_df13 = pred13_df2.query(\"active == 0 & pos > 0.8\").copy()\n",
    "PandasTools.AddMoleculeColumnToFrame(false_positive_df13, 'SMILES', 'Mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "98c9394b-88c3-4c20-af27-1be4c1770d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>active</th>\n",
       "      <th>Mol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9364</th>\n",
       "      <td>0.997684</td>\n",
       "      <td>0</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>0.986256</td>\n",
       "      <td>0</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>0.978238</td>\n",
       "      <td>0</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(false_positive_df13.loc[:, ['pos', 'active', 'Mol']].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb09748-9bf3-48ef-a7da-884d4b9f5e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db9d679e-cf8c-47f4-b893-c7aab4d7bc71",
   "metadata": {},
   "source": [
    "### explore model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e87df-d2e1-4288-8d48-0e5e96e5e8bc",
   "metadata": {
    "id": "86EBR3HU3St5"
   },
   "source": [
    "Previous results (MCC):  \n",
    "[0.4502412189462288]  \n",
    "[0.4128819211180105]  \n",
    "[0.4502412189462288, 0.4965585838893341]  \n",
    "[0.4128819211180105, 0.4654923820863219]  \n",
    "[0.4502412189462288, 0.4965585838893341, 0.5585299037933114]  \n",
    "[0.4128819211180105, 0.4654923820863219, 0.45430324072314515]  \n",
    "[0.4502412189462288, 0.4965585838893341, 0.5585299037933114, 0.6192709501522672]  \n",
    "[0.4128819211180105, 0.4654923820863219, 0.45430324072314515, 0.5214770300289555]  \n",
    "[0.4502412189462288, 0.4965585838893341, 0.5585299037933114, 0.6192709501522672, 0.5843172323482354]  \n",
    "[0.4128819211180105, 0.4654923820863219, 0.45430324072314515, 0.5214770300289555, 0.49755690080208853]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa83f0e-f7ff-43ad-8cde-3b35b37e9ee4",
   "metadata": {
    "id": "aaa83f0e-f7ff-43ad-8cde-3b35b37e9ee4",
    "outputId": "cc368dab-1d57-45a9-e2cb-35d20df88726"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPnUlEQVR4nO3dW4xdV33H8e8v4wYmtwK1E8Tk4rTjKiqIUDBpI6BKVILSCClFiiCiVdWXRgFlMEJIpTzQ0ocIxEutSSB1o5SHlrpVStK0Mgm0IoSiInyJE+xc1COTiydp4gSaxImbYPPvw2zD0XjsOb6M93j5+5GOZu+119rnf0ZrfmedPefMpKqQJLXrlL4LkCQtLoNekhpn0EtS4wx6SWqcQS9JjVvWdwHzWb58ea1cubLvMiTphLF58+bnqmrFfMeWZNCvXLmSTZs29V2GJJ0wkjx+sGNeupGkxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXFL8n30LZienmYwGPRaw8zMDAATExO91gEwOTnJ1NRU32VIJyWDvmF79uzpuwRJS4BBv0iWwup1zZo1AKxdu7bnSiT1yWv0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxIwV9kiuTPJpkkOQzB+lzWZKtSbYn+c7hjJUkLZ4F/x59kjHgZuAKYCewMcldVfXQUJ83AF8GrqyqJ5KcPepYSdLiGmVFfwkwqKodVfUasB64ek6fjwJfr6onAKrq2cMYK0laRKME/QTw5ND+zq5t2K8Db0xyb5LNSf7oMMYCkOS6JJuSbNq1a9do1UuSFjTKvxLMPG01z3neBfwuMA78V5Lvjzh2trFqHbAOYPXq1fP2kSQdvlGCfidw3tD+ucBT8/R5rqpeBl5Och9w8YhjJUmLaJRLNxuBVUkuTHIqcC1w15w+/wK8L8myJKcBvwU8POJYSdIiWnBFX1V7k9wA3AOMAbdV1fYk13fHb6mqh5PcDTwI/Ay4taq2Acw3dpEeiyRpHqNcuqGqNgAb5rTdMmf/S8CXRhkrSTp+/GSsJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEjfWDqRDI9Pc1gMOi7jCVh//dhzZo1PVeyNExOTjI1NdV3GdJx11zQDwYDtm57mH2nvanvUnp3ymuzfwR0845neq6kf2Ov/LjvEqTeNBf0APtOexN7Lrqq7zK0hIw/4l/h0MnLa/SS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjVvWdwHH2szMDGOvvMD4Ixv6LkVLyNgrzzMzs7fvMqReuKKXpMY1t6KfmJjgf15dxp6Lruq7FC0h449sYGLinL7LkHrhil6SGmfQS1LjDHpJatxIQZ/kyiSPJhkk+cw8xy9L8kKSrd3tc0PHHkvyw65907EsXpK0sAV/GZtkDLgZuALYCWxMcldVPTSn63er6oMHOc3lVfXc0ZUqSToSo6zoLwEGVbWjql4D1gNXL25ZkqRjZZSgnwCeHNrf2bXNdWmSB5J8I8lbh9oL+GaSzUmuO4paJUlHYJT30WeetpqzvwW4oKp2J7kKuBNY1R17T1U9leRs4FtJHqmq+w64k9kngesAzj///FHrlyQtYJQV/U7gvKH9c4GnhjtU1YtVtbvb3gD8UpLl3f5T3ddngTuYvRR0gKpaV1Wrq2r1ihUrDvuBSJLmN0rQbwRWJbkwyanAtcBdwx2SvDlJuu1LuvM+n+T0JGd27acDHwC2HcsHIEk6tAUv3VTV3iQ3APcAY8BtVbU9yfXd8VuAa4CPJdkL7AGurapKcg5wR/ccsAz4WlXdvUiPRZI0j5H+1k13OWbDnLZbhrZvAm6aZ9wO4OKjrFGSdBT8ZKwkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS45b1XYCk42t6eprBYNB3GczMzAAwMTHRax2Tk5NMTU31WsNiM+gl9WLPnj19l3DSMOilk8xSWb2uWbMGgLVr1/ZcSfu8Ri9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjRgr6JFcmeTTJIMln5jl+WZIXkmztbp8bdawkaXEt+I9HkowBNwNXADuBjUnuqqqH5nT9blV98AjHSpIWySgr+kuAQVXtqKrXgPXA1SOe/2jGSpKOgVGCfgJ4cmh/Z9c216VJHkjyjSRvPcyxJLkuyaYkm3bt2jVCWZKkUYwS9JmnrebsbwEuqKqLgWngzsMYO9tYta6qVlfV6hUrVoxQliRpFKP8c/CdwHlD++cCTw13qKoXh7Y3JPlykuWjjJVOJtPT0wwGg77LWBL2fx/2/5Pwk93k5OSi/eP2UYJ+I7AqyYXADHAt8NHhDkneDDxTVZXkEmZfKTwP/O9CYxfD2Cs/ZvyRDYt9N0veKf83+/z7s9ef1XMl/Rt75cfAOX2XwWAw4L+338/5Z+zru5TenfrT2QsKrz6+qedK+vfE7rFFPf+CQV9Ve5PcANwDjAG3VdX2JNd3x28BrgE+lmQvsAe4tqoKmHfsIj0WYPZZUbMGg5cAmPzV/gOuf+csmblx/hn7+Ow7X1y4o04aN25Z3MXYKCt6qmoDsGFO2y1D2zcBN406djEt1kufE9H+l8Rr167tuRJJffKTsZLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS45b1XYB0MpmZmeHll8a4cctZfZeiJeTxl8Y4fWZm0c7vil6SGueKXjqOJiYmeHXv03z2nS/2XYqWkBu3nMXrJiYW7fyu6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapzvo5eOsyd2+8lYgGdemV1nnnPaz3qupH9P7B5j1SKe36CXjqPJycm+S1gyXhsMAHjdBX5PVrG4c2OkoE9yJbAWGANuraovHKTfu4HvAx+pqtu7tseAl4B9wN6qWn0M6pZOSFNTU32XsGSsWbMGgLVr1/ZcSfsWDPokY8DNwBXATmBjkruq6qF5+n0RuGee01xeVc8dg3olSYdplBX9JcCgqnYAJFkPXA08NKffFPDPwLuPaYUnqOnpaQbdS9O+7L///SunPk1OTrqalXoyyrtuJoAnh/Z3dm0/l2QC+BBwyzzjC/hmks1JrjvYnSS5LsmmJJt27do1QllayPj4OOPj432XIalno6zoM09bzdn/K+BPq2pfckD391TVU0nOBr6V5JGquu+AE1atA9YBrF69eu75TziuXiUtFaME/U7gvKH9c4Gn5vRZDazvQn45cFWSvVV1Z1U9BVBVzya5g9lLQQcEvSRpcYxy6WYjsCrJhUlOBa4F7hruUFUXVtXKqloJ3A58vKruTHJ6kjMBkpwOfADYdkwfgSTpkBZc0VfV3iQ3MPtumjHgtqranuT67vh81+X3Owe4o1vpLwO+VlV3H33ZkqRRjfQ++qraAGyY0zZvwFfVHw9t7wAuPor6JElHyb91I0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUuGV9FyDp+JqenmYwGPRdxs9rWLNmTa91TE5OMjU11WsNi82gl9SL8fHxvks4aRj00kmm9dWrDuQ1eklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjUlV913CAJLuAx/uuoxHLgef6LkI6COfnsXNBVa2Y78CSDHodO0k2VdXqvuuQ5uP8PD68dCNJjTPoJalxBn371vVdgHQIzs/jwGv0ktQ4V/SS1DiDXpIaZ9AvQUnekOTjRzBuQ5I3LNDnL5O8/4iLkw4iye7u61uS3H6QPvcmOeTbKZN8MslpQ/sLzmsdmtfol6AkK4F/q6q3zWkfq6p9/VQlHVqS3VV1xgJ97gU+XVWbDtHnMWB1VflBqmPEFf3S9AXg15JsTbIxybeTfA34IUCSO5NsTrI9yXX7ByV5LMnyJCuTPJzkb7o+30wy3vX5apJrhvp/PsmWJD9MclHXviLJt7r2v07yeJLlx//boD4l+eLwK8skf5Hkz5P8x9CcuXqecSuTbOu2x5OsT/Jgkn8Exof6fSXJpm6Ofr5r+wTwFuDbSb7dtT22f/4l+VSSbd3tk0P3N+98V6eqvC2xG7AS2NZtXwa8DFw4dPxN3ddxYBvwK93+Y8x+pHwlsBd4R9f+T8AfdttfBa4Z6j/VbX8cuLXbvgn4s277SqCA5X1/X7wd93n4m8B3hvYfAs4Hzur2lwMDfnFlYHf3dXj+fgq4rdt+ezcvV3f7++fxGHAv8PZu/7Hh+TY0r9/F7GLndOAMYHtX40Hnu7fZmyv6E8MPqupHQ/ufSPIA8H3gPGDVPGN+VFVbu+3NzP4wzOfr8/R5L7AeoKruBn5ypIXrxFVV9wNnd9fcL2Z2HjwN3JjkQeDfgQngnEOc5neAv+vO9yDw4NCxDyfZAtwPvBX4jQVKei9wR1W9XFW7mZ277+uOjTrfT0rL+i5AI3l5/0aSy4D3A5dW1SvdNc/XzzPm1aHtfQy9ZD5Iv338Yj7kKGpVW24HrgHezOyT/x8AK4B3VdVPu+vp882/YQf8IjDJhcCngXdX1U+SfHWE8xxqXo46309KruiXppeAMw9y7JeBn3QhfxHw24tw//8JfBggyQeANy7CfejEsB64ltmwv53Z+fdsF/KXAxcsMP4+Zp8cSPI2Zi/fAJzF7ALmhSTnAL83NOZg8/8+4PeTnJbkdOBDwHeP6FGdZFzRL0FV9XyS73W/0NoDPDN0+G7g+u6l86PMXr451j4P/EOSjwDfYfbl+kuLcD9a4qpqe5IzgZmqejrJ3wP/mmQTsBV4ZIFTfAX4226+bgV+0J33gST3M3udfQfwvaEx64BvJHm6qi4fqmVLt/L/Qdd0a1Xd371LTYfg2yt1gCSvA/ZV1d4klwJfqap39FyWpCPkil7zOR/4pySnAK8Bf9JzPZKOgit6SWqcv4yVpMYZ9JLUOINekhpn0EtS4wx6SWrc/wMjq8I+YhtzSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## training vs validation MCC scores\n",
    "sns.boxplot(x = [\"training\"] * cv_folds + [\"validation\"] * cv_folds, y = training_score_list + validation_score_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123f29e-cd8c-463a-aae9-b5480124d55d",
   "metadata": {
    "id": "4123f29e-cd8c-463a-aae9-b5480124d55d"
   },
   "outputs": [],
   "source": [
    "pred = [x.flatten() for x in model.predict(valid_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66696e41-24a0-4580-87cc-7b48b22ee620",
   "metadata": {
    "id": "66696e41-24a0-4580-87cc-7b48b22ee620"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred,columns=[\"neg\",\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31be36-cb52-4632-bb04-0200ec69e9b5",
   "metadata": {
    "id": "be31be36-cb52-4632-bb04-0200ec69e9b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df[\"active\"] = [int(x) for x in valid_dataset.y]\n",
    "pred_df[\"SMILES\"] = valid_dataset.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c53979-d386-40a5-93f3-fd9f03680dd4",
   "metadata": {
    "id": "c7c53979-d386-40a5-93f3-fd9f03680dd4",
    "outputId": "47d3774c-26da-444c-8a70-938f5de226ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>active</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10191</th>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0</td>\n",
       "      <td>CC1=C(C(=O)OCc2ccccc2)C(c2cccnc2)n2ncnc2N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0</td>\n",
       "      <td>CN(Cc1cccs1)C(=O)CNC(=O)c1ccco1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0.952261</td>\n",
       "      <td>0.047739</td>\n",
       "      <td>1</td>\n",
       "      <td>N#C/C(=C\\c1cccc([N+](=O)[O-])c1)C(=O)NCc1cccnc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>1</td>\n",
       "      <td>CCOc1ccc(C(=O)NCCCN(CC)CC)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14071</th>\n",
       "      <td>0.995364</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0</td>\n",
       "      <td>CCCCCCCN(C(=O)CCl)c1cccc(C)c1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            neg       pos  active  \\\n",
       "10191  0.998757  0.001243       0   \n",
       "2610   0.999847  0.000153       0   \n",
       "3003   0.952261  0.047739       1   \n",
       "788    0.982654  0.017346       1   \n",
       "14071  0.995364  0.004636       0   \n",
       "\n",
       "                                                SMILES  \n",
       "10191       CC1=C(C(=O)OCc2ccccc2)C(c2cccnc2)n2ncnc2N1  \n",
       "2610                   CN(Cc1cccs1)C(=O)CNC(=O)c1ccco1  \n",
       "3003   N#C/C(=C\\c1cccc([N+](=O)[O-])c1)C(=O)NCc1cccnc1  \n",
       "788                      CCOc1ccc(C(=O)NCCCN(CC)CC)cc1  \n",
       "14071                    CCCCCCCN(C(=O)CCl)c1cccc(C)c1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9e4c4-6d7d-4417-ac7b-d765ed990ad0",
   "metadata": {
    "id": "b3e9e4c4-6d7d-4417-ac7b-d765ed990ad0",
    "outputId": "42439c64-3e6f-4217-d22e-c54a2dc0c777"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predicted probabilities for active and inactives\n",
    "sns.boxplot(x=pred_df.active, y=pred_df.pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29960825-ce31-4a69-82a0-82aefe8ac9d9",
   "metadata": {
    "id": "29960825-ce31-4a69-82a0-82aefe8ac9d9"
   },
   "outputs": [],
   "source": [
    "# put false negatives in a new dataframe\n",
    "false_negative_df = pred_df.query(\"active == 1 & pos < 0.5\").copy()\n",
    "PandasTools.AddMoleculeColumnToFrame(false_negative_df, 'SMILES', 'Mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa6daf-12e4-4325-b7c1-df66b17cfc47",
   "metadata": {
    "id": "81aa6daf-12e4-4325-b7c1-df66b17cfc47",
    "outputId": "5cf3b556-300d-48df-cdef-94b1bf0e6ddd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepchem.data.datasets.DiskDataset"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1abbdc-317c-478d-893e-4b25120bd4a0",
   "metadata": {
    "id": "7f1abbdc-317c-478d-893e-4b25120bd4a0",
    "outputId": "3a23ced3-e1f5-45a1-d4bb-6de209e2cf21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>active</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Mol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.347973</td>\n",
       "      <td>1</td>\n",
       "      <td>COc1ccc(CNCCC(c2ccccc2)C2CCOC(C)(C)C2)cc1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21014</th>\n",
       "      <td>0.920934</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>1</td>\n",
       "      <td>c1ccc(C(c2ccccc2)c2noc(CN3CCN(CC4CC4)CC3)n2)cc1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>0.622856</td>\n",
       "      <td>0.377144</td>\n",
       "      <td>1</td>\n",
       "      <td>COc1cc(CN2CCC(CCC(=O)NC3CC3)CC2)cc(Cl)c1OC</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11702</th>\n",
       "      <td>0.559105</td>\n",
       "      <td>0.440895</td>\n",
       "      <td>1</td>\n",
       "      <td>O=C(CN1CCN(Cc2ccc(Cl)cc2)CC1)N/N=C/c1ccncc1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18031</th>\n",
       "      <td>0.692768</td>\n",
       "      <td>0.307232</td>\n",
       "      <td>1</td>\n",
       "      <td>C=CCN(c1ccccc1)S(=O)(=O)c1cccc(C(=O)NC2CCN(Cc3...</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(false_negative_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27fce5b-fe58-41cf-94ba-9aeb56903ba8",
   "metadata": {
    "id": "c27fce5b-fe58-41cf-94ba-9aeb56903ba8"
   },
   "outputs": [],
   "source": [
    "false_positive_df = pred_df.query(\"active == 0 & pos > 0.5\").copy()\n",
    "PandasTools.AddMoleculeColumnToFrame(false_positive_df, 'SMILES', 'Mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c6883-44f8-4d60-a17d-c1d421646137",
   "metadata": {
    "id": "246c6883-44f8-4d60-a17d-c1d421646137",
    "outputId": "ac8a26b0-7b88-400d-8148-2aaecc245b34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>active</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Mol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23687</th>\n",
       "      <td>0.058787</td>\n",
       "      <td>0.941213</td>\n",
       "      <td>0</td>\n",
       "      <td>CCc1ccccc1NC(=O)CN1CCN(CC(=O)NCc2ccc(Cl)cc2)CC1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>0.207830</td>\n",
       "      <td>0.792170</td>\n",
       "      <td>0</td>\n",
       "      <td>COc1ccc(F)cc1C(=O)C1CCCN(Cc2cn(C)c3ccccc23)C1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>0.429260</td>\n",
       "      <td>0.570740</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.OC(COc1c(F)cc(Br)cc1F)CN1CCN(c2ccc(F)cc2)CC1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21501</th>\n",
       "      <td>0.193804</td>\n",
       "      <td>0.806196</td>\n",
       "      <td>0</td>\n",
       "      <td>CCc1ccc(NC(=O)CSc2nc(=O)n(CCN(C)C)c3c2CCCC3)cc1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9692</th>\n",
       "      <td>0.467457</td>\n",
       "      <td>0.532543</td>\n",
       "      <td>0</td>\n",
       "      <td>O=c1c2ccccc2nc(-c2ccccc2)n1CCCn1ccnc1</td>\n",
       "      <td style=\"text-align: center;\"><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(false_positive_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a98d7-5e7c-4aea-896a-c1b2b95193c3",
   "metadata": {
    "id": "ec0a98d7-5e7c-4aea-896a-c1b2b95193c3"
   },
   "outputs": [],
   "source": [
    "false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61e0db-7e3e-45a4-87e5-98babbbe57d6",
   "metadata": {
    "id": "7a61e0db-7e3e-45a4-87e5-98babbbe57d6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fa22002-6aea-4817-8e9d-76f29005c617",
   "metadata": {
    "id": "abc33f7f-62fa-457f-9649-42ea20a54ba5"
   },
   "source": [
    "### Create Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ca0f6-8104-41ac-850b-969893d3e159",
   "metadata": {
    "id": "a56ca0f6-8104-41ac-850b-969893d3e159"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd89cf-70b6-49e5-93eb-930983b8ac0b",
   "metadata": {
    "id": "01fd89cf-70b6-49e5-93eb-930983b8ac0b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b3088-dad7-48d6-9b61-d8510a9f9da2",
   "metadata": {
    "id": "7f3b3088-dad7-48d6-9b61-d8510a9f9da2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b68e4-fc39-4e8a-960f-11a78bdb7d77",
   "metadata": {
    "id": "df7b68e4-fc39-4e8a-960f-11a78bdb7d77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd7b45-877c-4186-82b0-4355b91905e0",
   "metadata": {
    "id": "a0dd7b45-877c-4186-82b0-4355b91905e0"
   },
   "outputs": [],
   "source": [
    "def conv_net():\n",
    "  K.clear_session()\n",
    "  weights = 'imagenet'\n",
    "  inputs = Input(shape=(128, 128, 3))\n",
    "\n",
    "  base_model = ResNet50(include_top=False, weights=weights, input_shape=(128, 128, 3))\n",
    "\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  x = Conv2D(32, (5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=(128, 128, 3))(inputs)\n",
    "  x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)\n",
    "\n",
    "  x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)\n",
    "\n",
    "  x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)\n",
    "\n",
    "  x = Flatten()(x)\n",
    "\n",
    "  base_resnet = base_model(inputs)\n",
    "  base_resnet = Flatten()(base_resnet)\n",
    "\n",
    "  concated_layers = Concatenate()([x, base_resnet])\n",
    "\n",
    "  concated_layers = Dense(2024, activation='relu')(concated_layers)\n",
    "  concated_layers = Dense(524, activation='relu')(concated_layers)\n",
    "  concated_layers = Dense(124, activation='relu')(concated_layers)\n",
    "  output = Dense(4, activation='relu')(concated_layers)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=output)\n",
    "  return model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_initial_nn_model.ipynb",
   "provenance": [
    {
     "file_id": "1r8RGaNnYB9YvsKadkIcAz5h3xMMXHtbE",
     "timestamp": 1651597718194
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:capstone_cf]",
   "language": "python",
   "name": "conda-env-capstone_cf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
